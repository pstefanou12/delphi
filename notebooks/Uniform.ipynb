{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "from cox.readers import CollectionReader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import numpy as np\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions import Uniform\n",
    "from torch.utils.data import DataLoader\n",
    "from delphi.stats.truncated_regression import truncated_regression\n",
    "from delphi.utils.datasets import TruncatedRegressionDataset\n",
    "from delphi.oracle import Left, Interval\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /home/pstefanou/Uniform/34ad26eb-0618-4c14-9307-47613f6a5126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cox.store.Table at 0x7f5e770be5f8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STORE_PATH = '/home/pstefanou/Uniform'\n",
    "STORE_TABLE_NAME = 'uniform'\n",
    "\n",
    "store = Store(STORE_PATH)\n",
    "\n",
    "store.add_table(STORE_TABLE_NAME, { \n",
    "    'known_param_mse': float,\n",
    "    'unknown_param_mse': float, \n",
    "    'ols_param_mse': float,\n",
    "    'alpha': float, \n",
    "    'var': float, \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Loss 0.1568 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.28it/s]\n",
      "Epoch:2 | Loss 0.1658 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.93it/s]\n",
      "Epoch:3 | Loss 0.1726 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.71it/s]\n",
      "Epoch:4 | Loss 0.1781 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.23it/s]\n",
      "Epoch:5 | Loss 0.1798 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.79it/s]\n",
      "Epoch:6 | Loss 0.1838 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.36it/s]\n",
      "Epoch:7 | Loss 0.1843 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.45it/s]\n",
      "Epoch:8 | Loss 0.1889 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.96it/s]\n",
      "Epoch:9 | Loss 0.1871 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.61it/s]\n",
      "Epoch:10 | Loss 0.1863 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.28it/s]\n",
      "Epoch:11 | Loss 0.1859 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.91it/s]\n",
      "Epoch:12 | Loss 0.1833 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.08it/s]\n",
      "Epoch:13 | Loss 0.1884 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 33.82it/s]\n",
      "Epoch:14 | Loss 0.1860 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.95it/s]\n",
      "Epoch:15 | Loss 0.1855 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.57it/s]\n",
      "Epoch:16 | Loss 0.1844 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.08it/s]\n",
      "Epoch:17 | Loss 0.1845 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.20it/s]\n",
      "Epoch:18 | Loss 0.1846 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.39it/s]\n",
      "Epoch:19 | Loss 0.1845 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.17it/s]\n",
      "Epoch:20 | Loss 0.1855 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.16it/s]\n",
      "Epoch:21 | Loss 0.1882 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.00it/s]\n",
      "Epoch:22 | Loss 0.1800 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.20it/s]\n",
      "Epoch:23 | Loss 0.1850 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 35.74it/s]\n",
      "Epoch:24 | Loss 0.1848 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.67it/s]\n",
      "Epoch:25 | Loss 0.1839 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:07<00:00, 34.41it/s]\n",
      "Epoch:1 | Loss 0.1568 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 74.78it/s]\n",
      "Epoch:2 | Loss 0.1582 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 77.74it/s]\n",
      "Epoch:3 | Loss 0.1653 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 72.35it/s]\n",
      "Epoch:4 | Loss 0.1702 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 72.73it/s]\n",
      "Epoch:5 | Loss 0.1755 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 76.32it/s]\n",
      "Epoch:6 | Loss 0.1784 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 70.13it/s]\n",
      "Epoch:7 | Loss 0.1860 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 72.62it/s]\n",
      "Epoch:8 | Loss 0.1880 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 80.54it/s]\n",
      "Epoch:9 | Loss 0.1932 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 72.59it/s]\n",
      "Epoch:10 | Loss 0.2005 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 72.83it/s]\n",
      "Epoch:11 | Loss 0.2080 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 76.56it/s]\n",
      "Epoch:12 | Loss 0.2090 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 71.19it/s]\n",
      "Epoch:13 | Loss 0.2105 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 79.28it/s]\n",
      "Epoch:14 | Loss 0.2189 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 72.91it/s]\n",
      "Epoch:15 | Loss 0.2221 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 73.22it/s]\n",
      "Epoch:16 | Loss 0.2275 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 74.32it/s]\n",
      "Epoch:17 | Loss 0.2358 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 74.44it/s]\n",
      "Epoch:18 | Loss 0.2407 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 77.37it/s]\n",
      "Epoch:19 | Loss 0.2281 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 78.76it/s]\n",
      "Epoch:20 | Loss 0.2357 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 75.21it/s]\n",
      "Epoch:21 | Loss 0.2428 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 70.98it/s]\n",
      "Epoch:22 | Loss 0.2621 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 74.82it/s]\n",
      "Epoch:23 | Loss 0.2625 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 77.05it/s]\n",
      "Epoch:24 | Loss 0.2539 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 73.93it/s]\n",
      "Epoch:25 | Loss 0.2563 | Train1 0.450 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 258/258 [00:03<00:00, 75.49it/s]\n",
      "Epoch:1 | Loss 0.2957 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.54it/s]\n",
      "Epoch:2 | Loss 0.3113 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.78it/s]\n",
      "Epoch:3 | Loss 0.3323 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.48it/s]\n",
      "Epoch:4 | Loss 0.3313 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:07<00:00, 33.99it/s]\n",
      "Epoch:5 | Loss 0.3387 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.64it/s]\n",
      "Epoch:6 | Loss 0.3401 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.81it/s]\n",
      "Epoch:7 | Loss 0.3404 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.57it/s]\n",
      "Epoch:8 | Loss 0.3502 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.64it/s]\n",
      "Epoch:9 | Loss 0.3441 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.16it/s]\n",
      "Epoch:10 | Loss 0.3403 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.26it/s]\n",
      "Epoch:11 | Loss 0.3432 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.80it/s]\n",
      "Epoch:12 | Loss 0.3425 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.56it/s]\n",
      "Epoch:13 | Loss 0.3484 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.98it/s]\n",
      "Epoch:14 | Loss 0.3428 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.85it/s]\n",
      "Epoch:15 | Loss 0.3453 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.36it/s]\n",
      "Epoch:16 | Loss 0.3410 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:17 | Loss 0.3385 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.03it/s]\n",
      "Epoch:18 | Loss 0.3403 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.37it/s]\n",
      "Epoch:19 | Loss 0.3426 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.80it/s]\n",
      "Epoch:20 | Loss 0.3381 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.39it/s]\n",
      "Epoch:21 | Loss 0.3475 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.62it/s]\n",
      "Epoch:22 | Loss 0.3343 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.37it/s]\n",
      "Epoch:23 | Loss 0.3431 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 35.34it/s]\n",
      "Epoch:24 | Loss 0.3378 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.84it/s]\n",
      "Epoch:25 | Loss 0.3408 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:06<00:00, 34.94it/s]\n",
      "Epoch:1 | Loss 0.2957 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 72.04it/s]\n",
      "Epoch:2 | Loss 0.3095 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 75.05it/s]\n",
      "Epoch:3 | Loss 0.3277 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 76.06it/s]\n",
      "Epoch:4 | Loss 0.3281 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 76.39it/s]\n",
      "Epoch:5 | Loss 0.3487 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 72.88it/s]\n",
      "Epoch:6 | Loss 0.3574 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 71.50it/s]\n",
      "Epoch:7 | Loss 0.4018 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 73.70it/s]\n",
      "Epoch:8 | Loss 0.4426 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 77.71it/s]\n",
      "Epoch:9 | Loss 0.4809 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 76.52it/s]\n",
      "Epoch:10 | Loss 0.5552 | Train1 0.355 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 79.20it/s]\n",
      "Epoch:11 | Loss 0.6370 | Train1 0.353 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 74.42it/s]\n",
      "Epoch:12 | Loss 0.6977 | Train1 0.353 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 72.86it/s]\n",
      "Epoch:13 | Loss 0.8249 | Train1 0.347 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 75.39it/s]\n",
      "Epoch:14 | Loss 0.8657 | Train1 0.343 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 77.38it/s]\n",
      "Epoch:15 | Loss 0.8945 | Train1 0.342 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 78.05it/s]\n",
      "Epoch:16 | Loss 1.0021 | Train1 0.327 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 76.91it/s]\n",
      "Epoch:17 | Loss 1.0531 | Train1 0.320 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 76.58it/s]\n",
      "Epoch:18 | Loss 1.1374 | Train1 0.313 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 74.26it/s]\n",
      "Epoch:19 | Loss 1.1965 | Train1 0.299 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 77.24it/s]\n",
      "Epoch:20 | Loss 1.1766 | Train1 0.303 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 72.20it/s]\n",
      "Epoch:21 | Loss 1.3110 | Train1 0.286 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 73.53it/s]\n",
      "Epoch:22 | Loss 1.2710 | Train1 0.288 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 76.92it/s]\n",
      "Epoch:23 | Loss 1.3663 | Train1 0.276 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 74.74it/s]\n",
      "Epoch:24 | Loss 1.3583 | Train1 0.274 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 74.10it/s]\n",
      "Epoch:25 | Loss 1.3550 | Train1 0.274 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 239/239 [00:03<00:00, 75.12it/s]\n",
      "Epoch:1 | Loss 0.4021 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.82it/s]\n",
      "Epoch:2 | Loss 0.4254 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.84it/s]\n",
      "Epoch:3 | Loss 0.4460 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.16it/s]\n",
      "Epoch:4 | Loss 0.4498 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.71it/s]\n",
      "Epoch:5 | Loss 0.4525 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.06it/s]\n",
      "Epoch:6 | Loss 0.4516 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.92it/s]\n",
      "Epoch:7 | Loss 0.4593 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.24it/s]\n",
      "Epoch:8 | Loss 0.4580 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.62it/s]\n",
      "Epoch:9 | Loss 0.4549 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.04it/s]\n",
      "Epoch:10 | Loss 0.4595 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.79it/s]\n",
      "Epoch:11 | Loss 0.4592 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 36.17it/s]\n",
      "Epoch:12 | Loss 0.4583 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.57it/s]\n",
      "Epoch:13 | Loss 0.4488 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.39it/s]\n",
      "Epoch:14 | Loss 0.4609 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.10it/s]\n",
      "Epoch:15 | Loss 0.4573 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.28it/s]\n",
      "Epoch:16 | Loss 0.4530 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.18it/s]\n",
      "Epoch:17 | Loss 0.4577 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.27it/s]\n",
      "Epoch:18 | Loss 0.4515 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.18it/s]\n",
      "Epoch:19 | Loss 0.4528 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.22it/s]\n",
      "Epoch:20 | Loss 0.4534 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.45it/s]\n",
      "Epoch:21 | Loss 0.4505 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.65it/s]\n",
      "Epoch:22 | Loss 0.4504 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 35.34it/s]\n",
      "Epoch:23 | Loss 0.4561 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.28it/s]\n",
      "Epoch:24 | Loss 0.4481 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 34.28it/s]\n",
      "Epoch:25 | Loss 0.4557 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:07<00:00, 33.56it/s]\n",
      "Epoch:1 | Loss 0.4021 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 72.24it/s]\n",
      "Epoch:2 | Loss 0.4216 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 76.02it/s]\n",
      "Epoch:3 | Loss 0.4392 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 74.46it/s]\n",
      "Epoch:4 | Loss 0.4571 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 72.63it/s]\n",
      "Epoch:5 | Loss 0.5057 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 70.79it/s]\n",
      "Epoch:6 | Loss 0.5744 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 75.33it/s]\n",
      "Epoch:7 | Loss 0.6902 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 78.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:8 | Loss 0.7874 | Train1 0.308 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 74.95it/s]\n",
      "Epoch:9 | Loss 1.0037 | Train1 0.303 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 75.32it/s]\n",
      "Epoch:10 | Loss 1.3089 | Train1 0.288 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 75.76it/s]\n",
      "Epoch:11 | Loss 1.3982 | Train1 0.274 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 73.96it/s]\n",
      "Epoch:12 | Loss 1.5212 | Train1 0.264 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 72.65it/s]\n",
      "Epoch:13 | Loss 1.6207 | Train1 0.257 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 74.54it/s]\n",
      "Epoch:14 | Loss 1.8027 | Train1 0.241 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 74.02it/s]\n",
      "Epoch:15 | Loss 1.7010 | Train1 0.253 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 71.92it/s]\n",
      "Epoch:16 | Loss 2.0595 | Train1 0.208 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 75.80it/s]\n",
      "Epoch:17 | Loss 2.0406 | Train1 0.205 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 73.13it/s]\n",
      "Epoch:18 | Loss 2.0393 | Train1 0.216 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 70.66it/s]\n",
      "Epoch:19 | Loss 1.9430 | Train1 0.224 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 70.86it/s]\n",
      "Epoch:20 | Loss 2.0309 | Train1 0.215 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 73.90it/s]\n",
      "Epoch:21 | Loss 1.9556 | Train1 0.226 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 76.19it/s]\n",
      "Epoch:22 | Loss 2.0490 | Train1 0.213 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 75.08it/s]\n",
      "Epoch:23 | Loss 2.0607 | Train1 0.213 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 76.07it/s]\n",
      "Epoch:24 | Loss 2.1471 | Train1 0.202 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 75.11it/s]\n",
      "Epoch:25 | Loss 2.2028 | Train1 0.194 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 255/255 [00:03<00:00, 77.11it/s]\n",
      "Epoch:1 | Loss 0.7723 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 35.92it/s]\n",
      "Epoch:2 | Loss 0.8177 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.44it/s]\n",
      "Epoch:3 | Loss 0.8438 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 34.94it/s]\n",
      "Epoch:4 | Loss 0.8537 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 34.63it/s]\n",
      "Epoch:5 | Loss 0.8508 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.41it/s]\n",
      "Epoch:6 | Loss 0.8560 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.21it/s]\n",
      "Epoch:7 | Loss 0.8583 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 35.75it/s]\n",
      "Epoch:8 | Loss 0.8543 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 34.57it/s]\n",
      "Epoch:9 | Loss 0.8581 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.40it/s]\n",
      "Epoch:10 | Loss 0.8569 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.44it/s]\n",
      "Epoch:11 | Loss 0.8551 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.25it/s]\n",
      "Epoch:12 | Loss 0.8544 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 36.29it/s]\n",
      "Epoch:13 | Loss 0.8542 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 35.71it/s]\n",
      "Epoch:14 | Loss 0.8544 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 34.95it/s]\n",
      "Epoch:15 | Loss 0.8511 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 34.93it/s]\n",
      "Epoch:16 | Loss 0.8494 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 35.71it/s]\n",
      "Epoch:17 | Loss 0.8509 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.26it/s]\n",
      "Epoch:18 | Loss 0.8492 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.46it/s]\n",
      "Epoch:19 | Loss 0.8524 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.36it/s]\n",
      "Epoch:20 | Loss 0.8521 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 36.42it/s]\n",
      "Epoch:21 | Loss 0.8453 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 35.73it/s]\n",
      "Epoch:22 | Loss 0.8406 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 36.32it/s]\n",
      "Epoch:23 | Loss 0.8444 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 35.62it/s]\n",
      "Epoch:24 | Loss 0.8533 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:13<00:00, 35.84it/s]\n",
      "Epoch:25 | Loss 0.8449 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:14<00:00, 34.73it/s]\n",
      "Epoch:1 | Loss 0.7723 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 74.52it/s]\n",
      "Epoch:2 | Loss 0.8354 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 74.77it/s]\n",
      "Epoch:3 | Loss 0.9822 | Train1 0.193 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 74.00it/s]\n",
      "Epoch:4 | Loss 1.3356 | Train1 0.192 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 76.36it/s]\n",
      "Epoch:5 | Loss 1.7808 | Train1 0.189 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 73.12it/s]\n",
      "Epoch:6 | Loss 2.1497 | Train1 0.178 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 72.78it/s]\n",
      "Epoch:7 | Loss 1.9553 | Train1 0.185 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 73.83it/s]\n",
      "Epoch:8 | Loss 1.9117 | Train1 0.185 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 74.77it/s]\n",
      "Epoch:9 | Loss 1.9120 | Train1 0.182 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 73.93it/s]\n",
      "Epoch:10 | Loss 2.1032 | Train1 0.179 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 74.20it/s]\n",
      "Epoch:11 | Loss 2.1451 | Train1 0.179 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 75.72it/s]\n",
      "Epoch:12 | Loss 2.0580 | Train1 0.182 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 75.88it/s]\n",
      "Epoch:13 | Loss 2.3725 | Train1 0.167 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 73.72it/s]\n",
      "Epoch:14 | Loss 1.9671 | Train1 0.184 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 77.34it/s]\n",
      "Epoch:15 | Loss 2.0943 | Train1 0.178 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 73.92it/s]\n",
      "Epoch:16 | Loss 1.9795 | Train1 0.185 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 75.67it/s]\n",
      "Epoch:17 | Loss 2.1174 | Train1 0.179 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 76.88it/s]\n",
      "Epoch:18 | Loss 1.9752 | Train1 0.188 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 76.72it/s]\n",
      "Epoch:19 | Loss 1.9361 | Train1 0.186 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 78.16it/s]\n",
      "Epoch:20 | Loss 1.9319 | Train1 0.186 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 77.81it/s]\n",
      "Epoch:21 | Loss 2.0203 | Train1 0.181 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 73.90it/s]\n",
      "Epoch:22 | Loss 2.0066 | Train1 0.182 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 73.62it/s]\n",
      "Epoch:23 | Loss 2.1441 | Train1 0.181 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 75.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:24 | Loss 2.1594 | Train1 0.181 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 74.73it/s]\n",
      "Epoch:25 | Loss 2.1659 | Train1 0.182 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 499/499 [00:06<00:00, 75.54it/s]\n",
      "Epoch:1 | Loss 0.9003 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.16it/s]\n",
      "Epoch:2 | Loss 0.9432 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.41it/s]\n",
      "Epoch:3 | Loss 0.9671 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.88it/s]\n",
      "Epoch:4 | Loss 0.9761 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:14<00:00, 35.12it/s]\n",
      "Epoch:5 | Loss 0.9830 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:14<00:00, 34.89it/s]\n",
      "Epoch:6 | Loss 0.9850 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.21it/s]\n",
      "Epoch:7 | Loss 0.9876 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.71it/s]\n",
      "Epoch:8 | Loss 0.9876 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.25it/s]\n",
      "Epoch:9 | Loss 0.9863 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:14<00:00, 34.90it/s]\n",
      "Epoch:10 | Loss 0.9838 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:14<00:00, 35.13it/s]\n",
      "Epoch:11 | Loss 0.9873 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.15it/s]\n",
      "Epoch:12 | Loss 0.9833 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.19it/s]\n",
      "Epoch:13 | Loss 0.9775 | Train1 0.173 | Train5 -1.000 | Reg term: 0.0 ||: 100%|██████████| 492/492 [00:13<00:00, 35.31it/s]\n",
      "Epoch:14 | Loss 0.9832 | Train1 0.174 | Train5 -1.000 | Reg term: 0.0 ||:  95%|█████████▍| 466/492 [00:13<00:00, 37.67it/s]"
     ]
    }
   ],
   "source": [
    "# regression parameters\n",
    "num_samples, dims = 10000, 10\n",
    "phi = Left(Tensor([1.0]))\n",
    "\n",
    "# perform each experiment a total of 10 times\n",
    "for iter_ in range(10):        \n",
    "    for var in range(1, 20):\n",
    "        # generate random uniform weights\n",
    "        W = Uniform(-1, 1).sample(ch.Size([dims, 1]))\n",
    "        W0 = Uniform(-1, 1).sample(ch.Size([1, 1]))\n",
    "\n",
    "        # generate data\n",
    "        X = MultivariateNormal(ch.zeros(dims), ch.eye(dims)/dims).sample(ch.Size([num_samples]))\n",
    "        y = X.mm(W) + W0 + Normal(ch.zeros(1), ch.sqrt(Tensor([var]))).sample(ch.Size([num_samples]))\n",
    "        # truncate\n",
    "        indices = phi(y).nonzero(as_tuple=False).flatten()\n",
    "        y_trunc, x_trunc = y[indices], X[indices]\n",
    "\n",
    "        # empirical linear regression\n",
    "        reg = LinearRegression() \n",
    "        reg.fit(x_trunc, y_trunc)\n",
    "        emp_var = ch.var(ch.from_numpy(reg.predict(x_trunc)) - y_trunc, dim=0).unsqueeze(0)\n",
    "\n",
    "        # experiment parameters\n",
    "        args = Parameters({ \n",
    "            'alpha': Tensor([y_trunc.size(0)/num_samples]), \n",
    "            'phi': phi, \n",
    "            'epochs': 25,\n",
    "            'num_workers': 20, \n",
    "            'batch_size': 10,\n",
    "            'bias': True,\n",
    "            'num_samples': 100,\n",
    "            'clamp': True, \n",
    "            'radius': 5.0, \n",
    "            'var_lr': 1e-2,\n",
    "            'var': emp_var,\n",
    "            'lr': 1e-1,\n",
    "            'shuffle': True\n",
    "        })\n",
    "\n",
    "\n",
    "        # truncated linear regression with known noise variance\n",
    "        # dataset \n",
    "        data = TruncatedRegressionDataset(x_trunc, y_trunc, bias=args.bias, unknown=False)\n",
    "        S = DataLoader(data, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=args.shuffle)\n",
    "        trunc_reg = truncated_regression(phi=phi, alpha=args.alpha, epochs=args.epochs, lr=args.lr, num_samples=args.num_samples, var=args.var, device='cuda')\n",
    "        results = trunc_reg.fit(S)\n",
    "        w_, w0_ = results.weight.detach(), results.bias.detach()\n",
    "\n",
    "        # truncated linear regression with unknown noise variance\n",
    "        # dataset \n",
    "        data = TruncatedRegressionDataset(x_trunc, y_trunc, bias=args.bias, unknown=True)\n",
    "        S = DataLoader(data, batch_size=args.batch_size, num_workers=args.num_workers, shuffle=args.shuffle)\n",
    "        trunc_reg = truncated_regression(phi=phi, alpha=args.alpha, epochs=args.epochs, var_lr=args.var_lr, lr=args.lr, num_samples=args.num_samples, device='cuda')\n",
    "\n",
    "        results = trunc_reg.fit(S)\n",
    "        var_ = results.lambda_.inverse().detach()\n",
    "        w, w0 = results.v.detach()*var_, results.bias.detach()*var_\n",
    "\n",
    "        # calculate metrics \n",
    "        real_params = ch.cat([W, W0])\n",
    "        ols_params = ch.cat([data.w, data.w0.unsqueeze(0)])\n",
    "        unknown_params = ch.cat([w, w0])\n",
    "        known_params = ch.cat([w_.t(), w0_.unsqueeze(0)])\n",
    "        unknown_param_mse = mean_squared_error(unknown_params.cpu(), real_params)\n",
    "        ols_param_mse = mean_squared_error(ols_params, real_params)\n",
    "        known_param_mse = mean_squared_error(known_params.cpu(), real_params)\n",
    "\n",
    "        store[STORE_TABLE_NAME].append_row({ \n",
    "            'known_param_mse': known_param_mse,\n",
    "            'unknown_param_mse': unknown_param_mse,\n",
    "            'ols_param_mse': ols_param_mse,\n",
    "            'alpha': float(args.alpha.flatten()),\n",
    "            'var': float(var), \n",
    "        })\n",
    "\n",
    "# close current store\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lambda grad: {}\".format(results.lambda_.grad))\n",
    "print(\"bias grad: {}\".format(results.bias.grad))\n",
    "print(\"weight grad: {}\".format(results.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store.close()\n",
    "reader = CollectionReader(STORE_PATH)\n",
    "results = reader.df(STORE_TABLE_NAME)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "known, unknown, ols = results[['known_param_mse', 'var']], results[['unknown_param_mse', 'var']], results[['ols_param_mse', 'var']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results for regression parameter MSE\n",
    "sns.lineplot(data=unknown, x='var', y='unknown_param_mse', label='unknown', color='blue')\n",
    "sns.lineplot(data=known, x='var', y='known_param_mse', label='known', color='purple')\n",
    "ax = sns.lineplot(data=ols, x='var', y='ols_param_mse', label='ols', color='red')\n",
    "ax.set(xlabel='Noise Variance', ylabel='Squared Error')\n",
    "plt.show()\n",
    "# close reader\n",
    "reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.5256],\n",
       "        [ 2.3765],\n",
       "        [ 3.5738],\n",
       "        [ 5.6785],\n",
       "        [ 7.0232],\n",
       "        [ 6.7544],\n",
       "        [-4.5137],\n",
       "        [ 8.4928],\n",
       "        [-2.7278],\n",
       "        [-4.9227]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
