{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../..')\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "from cox.readers import CollectionReader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Gumbel, Uniform\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "from delphi.oracle import oracle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# procedure hyperparameters\n",
    "args = Parameters({ \n",
    "    'epochs': 25,\n",
    "    'num_workers': 0, \n",
    "    'batch_size': 10,\n",
    "    'bias': True,\n",
    "    'num_samples': 1000,\n",
    "    'clamp': True, \n",
    "    'radius': 5.0, \n",
    "    'var_lr': 1e-2,\n",
    "    'lr': 1e-1,\n",
    "    'shuffle': False, \n",
    "    'tol': 1e-2,\n",
    "    'samples': 10000,  # number of samples to generate for ground truth\n",
    "    'in_features': 3, # number of in-features to multi-log-reg\n",
    "    'k': 2, # number of classes\n",
    "    'lower': -1, # lower bound for generating ground truth weights\n",
    "    'upper': 1,  # upper bound for generating ground truth weights\n",
    "    'custom_criterion': F.gumbel_softmax,\n",
    "    'trials': 10,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CE LOSS TABLE FOR METRICS\n",
    "CE_LOSS_TABLE_NAME = 'ce_loss'\n",
    "\n",
    "STORE_PATH = '/home/pstefanou/MultinomialLogisticRegression'\n",
    "store = Store(STORE_PATH)\n",
    "\n",
    "store.add_table(CE_LOSS_TABLE_NAME, { \n",
    "    'train_acc': float, \"\"\n",
    "    'val_acc': float, \n",
    "    'train_loss': float, \n",
    "    'val_loss': float,\n",
    "    'epoch': int,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE Latent Variable Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel = Gumbel(0, 1)\n",
    "\n",
    "class GumbelCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        loss = ch.nn.CrossEntropyLoss()\n",
    "        return loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "        # make num_samples copies of pred logits\n",
    "        stacked = pred[None, ...].repeat(1000, 1, 1)        \n",
    "        # add gumbel noise to logits\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        noised = stacked + rand_noise \n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # remove the logits from the trials, where the kth logit is not the largest value\n",
    "        good_mask = noised_labs.eq(targ)[..., None]\n",
    "        inner_exp = 1 - ch.exp(-rand_noise)\n",
    "        avg = (inner_exp * good_mask).sum(0) / (good_mask.sum(0) + 1e-5) / pred.size(0)\n",
    "        return -avg , None\n",
    "    \n",
    "class TruncatedGumbelCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ, phi):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        ctx.phi = phi\n",
    "        ce_loss = ch.nn.CrossEntropyLoss()\n",
    "        return ce_loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "        # make num_samples copies of pred logits\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)   \n",
    "        # add gumbel noise to logits\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        noised = stacked + rand_noise \n",
    "        # truncate - if one of the noisy logits does not fall within the truncation set, remove it\n",
    "        filtered = ch.all(ctx.phi(noised).bool(), dim=2).float().unsqueeze(2)\n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # mask takes care of invalid logits and truncation set\n",
    "        mask = noised_labs.eq(targ)[..., None] * filtered\n",
    "        inner_exp = 1 - ch.exp(-rand_noise)\n",
    "        \n",
    "        avg = ((inner_exp * mask).sum(0) / (mask.sum(0) + 1e-5) - (inner_exp * filtered).sum(0) / (filtered.sum(0) + 1e-5)) \n",
    "        return -avg / pred.size(0), None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /home/pstefanou/MultinomialLogisticRegression/8f0f5d89-0b21-4fec-b950-fc836c4b2abb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cox.store.Table at 0x7f942ef214e0>"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CE LOSS TABLE FOR METRICS\n",
    "LATENT_CE_TABLE_NAME = 'latent_ce_grad'\n",
    "\n",
    "STORE_PATH = '/home/pstefanou/MultinomialLogisticRegression'\n",
    "store = Store(STORE_PATH)\n",
    "\n",
    "store.add_table(LATENT_CE_TABLE_NAME, { \n",
    "    'train_acc': float, \n",
    "    'val_acc': float, \n",
    "    'train_loss': float, \n",
    "    'val_loss': float,\n",
    "    'epoch': int,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-815-85ef1b54db2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGumbelCE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#             print(\"latent variable grad: {}\".format(multi_log_reg.weight.grad))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#             print((\"---\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# _forward_cls is defined by derived class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-666-731cee247cf3>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrand_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgumbel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mnoised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrand_noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mnoised_labs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoised\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m# remove the logits from the trials, where the kth logit is not the largest value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mgood_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoised_labs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "# optimizer and scheduler\n",
    "optimizer = ch.optim.SGD(multi_log_reg.parameters(), lr=1e-1)\n",
    "scheduler = ch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "\n",
    "for i in range(args.trials):\n",
    "    for epoch in range(args.epochs): \n",
    "        # train loop\n",
    "        train_loss, train_acc = Tensor([]), Tensor([])\n",
    "        for batch_X, batch_y in train_loader: \n",
    "            optimizer.zero_grad()\n",
    "            pred = multi_log_reg(batch_X)\n",
    "            loss = ce_loss(pred, batch_y)\n",
    "            loss.backward(retain_graph=True) \n",
    "            optimizer.zero_grad() \n",
    "            loss = GumbelCE.apply(pred,  batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            # keep track of algorithm training loss and accuracy\n",
    "            acc = (ch.argmax(ch.nn.Softmax(dim=1)(pred), dim=1) == batch_y).sum() / batch_y.size(0)\n",
    "            train_loss = ch.cat([train_loss, Tensor([loss])]) if train_loss.size() != ch.Size([0]) else Tensor([loss])\n",
    "            train_acc = ch.cat([train_acc, Tensor([acc])]) if train_acc.size() != ch.Size([0]) else Tensor([acc])\n",
    "        # validation loop\n",
    "        val_loss, val_acc = Tensor([]), Tensor([])\n",
    "        with ch.no_grad(): \n",
    "            for batch_X, batch_y in val_loader: \n",
    "                pred = multi_log_reg(batch_X)\n",
    "                loss = gumbel_ce(pred, batch_y)\n",
    "                # keep track of algorithm validation loss and accuracy\n",
    "                acc = (ch.argmax(ch.nn.Softmax(dim=1)(pred), dim=1) == batch_y).sum() / batch_y.size(0)            \n",
    "                val_loss = ch.cat([val_loss, Tensor([loss])]) if val_loss.size() != ch.Size([0]) else Tensor([loss])\n",
    "                val_acc = ch.cat([val_acc, Tensor([acc])]) if val_acc.size() != ch.Size([0]) else Tensor([acc])\n",
    "\n",
    "        store[LATENT_CE_TABLE_NAME].append_row({ \n",
    "            'train_acc': float(train_acc.mean()), \n",
    "            'val_acc': float(val_acc.mean()), \n",
    "            'train_loss': float(train_loss.mean()), \n",
    "            'val_loss': float(val_loss.mean()),\n",
    "            'epoch': int(epoch + 1),\n",
    "        })\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = CollectionReader(STORE_PATH)\n",
    "results = reader.df(LATENT_CE_TABLE_NAME)\n",
    "reader.close() # close reader\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=results, x='epoch', y='train_loss', label='train loss')\n",
    "ax = sns.lineplot(data=results, x='epoch', y='val_loss', color='red', label='val loss')\n",
    "ax.set(xlabel='epoch', ylabel='Gumbel CE Loss')\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(data=results, x='epoch', y='train_acc', label='train acc')\n",
    "ax = sns.lineplot(data=results, x='epoch', y='val_acc', color='red', label='val acc')\n",
    "ax.set(xlabel='epoch', ylabel='Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Multinomial Logistic Regression Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel = Gumbel(0, 1)\n",
    "\n",
    "class TruncatedGumbelCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ, phi):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        ctx.phi = phi\n",
    "        ce_loss = ch.nn.CrossEntropyLoss()\n",
    "        return ce_loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "        # make num_samples copies of pred logits\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)   \n",
    "        # add gumbel noise to logits\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        noised = stacked + rand_noise \n",
    "        # truncate - if one of the noisy logits does not fall within the truncation set, remove it\n",
    "        filtered = ch.all(ctx.phi(noised).bool(), dim=2).float().unsqueeze(2)\n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # mask takes care of invalid logits and truncation set\n",
    "        mask = noised_labs.eq(targ)[..., None] * filtered\n",
    "        inner_exp = 1 - ch.exp(-rand_noise)\n",
    "        \n",
    "        avg = ((inner_exp * mask).sum(0) / (mask.sum(0) + 1e-5) - (inner_exp * filtered).sum(0) / (filtered.sum(0) + 1e-5)) \n",
    "        return -avg / pred.size(0), None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Membership oracles for Multinomial Logistic Regression Logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_Lower(oracle): \n",
    "    \"\"\"\n",
    "    Lower bound truncation on the DNN logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, lower): \n",
    "        self.lower = lower\n",
    "        \n",
    "    def __call__(self, x): \n",
    "        return (x > self.lower).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(oracle): \n",
    "    def __call__(self, x): \n",
    "        return ch.ones(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = DNN_Lower(Tensor([-2, -2]))\n",
    "# phi = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth weights: Parameter containing:\n",
      "tensor([[ 0.1578, -0.2211, -0.8262],\n",
      "        [-0.7063, -0.6298, -0.9827]], requires_grad=True)\n",
      "ground truth bias: Parameter containing:\n",
      "tensor([ 0.9465, -0.5519], requires_grad=True)\n",
      "alpha: 0.6078\n"
     ]
    }
   ],
   "source": [
    "# generate ground-truth from uniform distribution\n",
    "U = Uniform(args.lower, args.upper)\n",
    "ground_truth = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "ground_truth.weight = nn.Parameter(U.sample(ch.Size([args.K, args.IN_FEATURES])))\n",
    "if ground_truth.bias is not None: \n",
    "    ground_truth.bias = nn.Parameter(U.sample(ch.Size([args.K,])))\n",
    "print(\"ground truth weights: {}\".format(ground_truth.weight))\n",
    "print(\"ground truth bias: {}\".format(ground_truth.bias))\n",
    "# independent variable \n",
    "U_ = Uniform(-5, 5)\n",
    "X = U_.sample(ch.Size([args.samples, args.IN_FEATURES]))\n",
    "# determine base model logits \n",
    "z = ground_truth(X)\n",
    "# apply softmax to unnormalized likelihoods\n",
    "y = ch.argmax(ch.nn.Softmax(dim=1)(z), dim=1)\n",
    "\n",
    "# TRUNCATE\n",
    "trunc = phi(z)\n",
    "indices = ch.all(trunc.bool(), dim=1).float().nonzero(as_tuple=False).flatten()\n",
    "y_trunc = y[indices]\n",
    "x_trunc = X[indices]\n",
    "alpha = x_trunc.size(0) / X.size(0)\n",
    "print(\"alpha: {}\".format(alpha))\n",
    "\n",
    "\n",
    "# all synthetic data \n",
    "ds = TensorDataset(x_trunc, y_trunc)\n",
    "# split ds into training and validation data sets\n",
    "train_length = int(len(ds)*.8)\n",
    "val_length = len(ds) - train_length\n",
    "train_ds, val_ds = ch.utils.data.random_split(ds, [train_length, val_length])\n",
    "# train and validation loaders\n",
    "train_loader = DataLoader(train_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "val_loader = DataLoader(val_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "\n",
    "# test dataset\n",
    "y_test = y[~indices]\n",
    "x_test = X[~indices]\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_loader = DataLoader(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /home/pstefanou/MultinomialLogisticRegression/3caf7896-e1bb-4339-91da-06f735e5d653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cox.store.Table at 0x7f1c8403a0f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CE LOSS TABLE FOR METRICS\n",
    "LATENT_CE_TABLE_NAME = 'trunc_test'\n",
    "\n",
    "STORE_PATH = '/home/pstefanou/MultinomialLogisticRegression'\n",
    "store = Store(STORE_PATH)\n",
    "\n",
    "store.add_table(LATENT_CE_TABLE_NAME, { \n",
    "    'trunc_train_acc': float, \n",
    "    'trunc_val_acc': float, \n",
    "    'trunc_train_loss': float, \n",
    "    'trunc_val_loss': float,\n",
    "    'naive_train_acc': float, \n",
    "    'naive_val_acc': float, \n",
    "    'naive_train_loss': float, \n",
    "    'naive_val_loss': float,\n",
    "    'epoch': int,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "naive_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "# optimizer and scheduler\n",
    "trunc_opt = ch.optim.SGD(trunc_multi_log_reg.parameters(), lr=1e-1)\n",
    "naive_opt = ch.optim.SGD(naive_multi_log_reg.parameters(), lr=1e-1)\n",
    "trunc_scheduler = ch.optim.lr_scheduler.CosineAnnealingLR(trunc_opt, args.epochs)\n",
    "naive_scheduler = ch.optim.lr_scheduler.CosineAnnealingLR(naive_opt, args.epochs)\n",
    "trunc_ce_loss = TruncatedGumbelCE.apply\n",
    "ce_loss = ch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(args.trials):\n",
    "    for epoch in range(args.epochs): \n",
    "        # train loop\n",
    "        trunc_train_loss, trunc_train_acc = Tensor([]), Tensor([])\n",
    "        naive_train_loss, naive_train_acc = Tensor([]), Tensor([])\n",
    "        for batch_X, batch_y in train_loader: \n",
    "            # truncated multinomial regression\n",
    "            trunc_opt.zero_grad()\n",
    "            pred = trunc_multi_log_reg(batch_X)\n",
    "            loss = trunc_ce_loss(pred, batch_y, phi)\n",
    "            loss.backward() \n",
    "            trunc_opt.step()\n",
    "            trunc_scheduler.step()\n",
    "            # keep track of truncated algorithm training loss and accuracy\n",
    "            acc = (ch.argmax(ch.nn.Softmax(dim=1)(pred), dim=1) == batch_y).sum() / batch_y.size(0)\n",
    "            trunc_train_loss = ch.cat([trunc_train_loss, Tensor([loss])]) if trunc_train_loss.size() != ch.Size([0]) else Tensor([loss])\n",
    "            trunc_train_acc = ch.cat([trunc_train_acc, Tensor([acc])]) if trunc_train_acc.size() != ch.Size([0]) else Tensor([acc])\n",
    "            \n",
    "            # naive multinomial regression\n",
    "            naive_opt.zero_grad()\n",
    "            pred = naive_multi_log_reg(batch_X)\n",
    "            loss = ce_loss(pred, batch_y)\n",
    "            loss.backward() \n",
    "            naive_opt.step()\n",
    "            naive_scheduler.step()\n",
    "            # keep track of naive algorithm training loss and accuracy\n",
    "            acc = (ch.argmax(ch.nn.Softmax(dim=1)(pred), dim=1) == batch_y).sum() / batch_y.size(0)\n",
    "            naive_train_loss = ch.cat([naive_train_loss, Tensor([loss])]) if naive_train_loss.size() != ch.Size([0]) else Tensor([loss])\n",
    "            naive_train_acc = ch.cat([naive_train_acc, Tensor([acc])]) if naive_train_acc.size() != ch.Size([0]) else Tensor([acc])\n",
    "        # validation loop\n",
    "        trunc_val_loss, trunc_val_acc = Tensor([]), Tensor([])\n",
    "        naive_val_loss, naive_val_acc = Tensor([]), Tensor([])\n",
    "        with ch.no_grad(): \n",
    "            for batch_X, batch_y in val_loader: \n",
    "                # truncated validation loop\n",
    "                pred = trunc_multi_log_reg(batch_X)\n",
    "                loss = trunc_ce_loss(pred, batch_y, phi)\n",
    "                # keep track of algorithm validation loss and accuracy\n",
    "                acc = (ch.argmax(ch.nn.Softmax(dim=1)(pred), dim=1) == batch_y).sum() / batch_y.size(0)            \n",
    "                trunc_val_loss = ch.cat([trunc_val_loss, Tensor([loss])]) if trunc_val_loss.size() != ch.Size([0]) else Tensor([loss])\n",
    "                trunc_val_acc = ch.cat([trunc_val_acc, Tensor([acc])]) if trunc_val_acc.size() != ch.Size([0]) else Tensor([acc])\n",
    "                \n",
    "                # naive validation loop\n",
    "                pred = naive_multi_log_reg(batch_X)\n",
    "                loss = ce_loss(pred, batch_y)\n",
    "                # keep track of algorithm validation loss and accuracy\n",
    "                acc = (ch.argmax(ch.nn.Softmax(dim=1)(pred), dim=1) == batch_y).sum() / batch_y.size(0)            \n",
    "                naive_val_loss = ch.cat([naive_val_loss, Tensor([loss])]) if naive_val_loss.size() != ch.Size([0]) else Tensor([loss])\n",
    "                naive_val_acc = ch.cat([naive_val_acc, Tensor([acc])]) if naive_val_acc.size() != ch.Size([0]) else Tensor([acc])\n",
    "\n",
    "\n",
    "        store[LATENT_CE_TABLE_NAME].append_row({ \n",
    "            'trunc_train_acc': float(trunc_train_acc.mean()), \n",
    "            'trunc_val_acc': float(trunc_val_acc.mean()), \n",
    "            'trunc_train_loss': float(trunc_train_loss.mean()), \n",
    "            'trunc_val_loss': float(trunc_val_loss.mean()),\n",
    "            'naive_train_acc': float(naive_train_acc.mean()), \n",
    "            'naive_val_acc': float(naive_val_acc.mean()), \n",
    "            'naive_train_loss': float(naive_train_loss.mean()), \n",
    "            'naive_val_loss': float(naive_val_loss.mean()),\n",
    "            'epoch': int(epoch + 1),\n",
    "        })\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Experiment Data from Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 126.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: exp_id 910b6273-0c72-43fe-b194-ad618d34d0fb has no table 'trunc_test'. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trunc_train_acc</th>\n",
       "      <th>trunc_val_acc</th>\n",
       "      <th>trunc_train_loss</th>\n",
       "      <th>trunc_val_loss</th>\n",
       "      <th>naive_train_acc</th>\n",
       "      <th>naive_val_acc</th>\n",
       "      <th>naive_train_loss</th>\n",
       "      <th>naive_val_loss</th>\n",
       "      <th>epoch</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935318</td>\n",
       "      <td>0.968852</td>\n",
       "      <td>0.168875</td>\n",
       "      <td>0.129807</td>\n",
       "      <td>0.929980</td>\n",
       "      <td>0.966393</td>\n",
       "      <td>0.182690</td>\n",
       "      <td>0.133580</td>\n",
       "      <td>1</td>\n",
       "      <td>3caf7896-e1bb-4339-91da-06f735e5d653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.972690</td>\n",
       "      <td>0.986066</td>\n",
       "      <td>0.106584</td>\n",
       "      <td>0.097690</td>\n",
       "      <td>0.971458</td>\n",
       "      <td>0.984426</td>\n",
       "      <td>0.108881</td>\n",
       "      <td>0.099178</td>\n",
       "      <td>2</td>\n",
       "      <td>3caf7896-e1bb-4339-91da-06f735e5d653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.984189</td>\n",
       "      <td>0.976229</td>\n",
       "      <td>0.087108</td>\n",
       "      <td>0.093668</td>\n",
       "      <td>0.984189</td>\n",
       "      <td>0.974590</td>\n",
       "      <td>0.088403</td>\n",
       "      <td>0.095360</td>\n",
       "      <td>3</td>\n",
       "      <td>3caf7896-e1bb-4339-91da-06f735e5d653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.984394</td>\n",
       "      <td>0.975410</td>\n",
       "      <td>0.077555</td>\n",
       "      <td>0.086910</td>\n",
       "      <td>0.983984</td>\n",
       "      <td>0.974590</td>\n",
       "      <td>0.078495</td>\n",
       "      <td>0.087777</td>\n",
       "      <td>4</td>\n",
       "      <td>3caf7896-e1bb-4339-91da-06f735e5d653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986653</td>\n",
       "      <td>0.993443</td>\n",
       "      <td>0.070763</td>\n",
       "      <td>0.071812</td>\n",
       "      <td>0.986448</td>\n",
       "      <td>0.993443</td>\n",
       "      <td>0.071445</td>\n",
       "      <td>0.072586</td>\n",
       "      <td>5</td>\n",
       "      <td>3caf7896-e1bb-4339-91da-06f735e5d653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trunc_train_acc  trunc_val_acc  trunc_train_loss  trunc_val_loss  \\\n",
       "0         0.935318       0.968852          0.168875        0.129807   \n",
       "1         0.972690       0.986066          0.106584        0.097690   \n",
       "2         0.984189       0.976229          0.087108        0.093668   \n",
       "3         0.984394       0.975410          0.077555        0.086910   \n",
       "4         0.986653       0.993443          0.070763        0.071812   \n",
       "\n",
       "   naive_train_acc  naive_val_acc  naive_train_loss  naive_val_loss  epoch  \\\n",
       "0         0.929980       0.966393          0.182690        0.133580      1   \n",
       "1         0.971458       0.984426          0.108881        0.099178      2   \n",
       "2         0.984189       0.974590          0.088403        0.095360      3   \n",
       "3         0.983984       0.974590          0.078495        0.087777      4   \n",
       "4         0.986448       0.993443          0.071445        0.072586      5   \n",
       "\n",
       "                                 exp_id  \n",
       "0  3caf7896-e1bb-4339-91da-06f735e5d653  \n",
       "1  3caf7896-e1bb-4339-91da-06f735e5d653  \n",
       "2  3caf7896-e1bb-4339-91da-06f735e5d653  \n",
       "3  3caf7896-e1bb-4339-91da-06f735e5d653  \n",
       "4  3caf7896-e1bb-4339-91da-06f735e5d653  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = CollectionReader(STORE_PATH)\n",
    "results = reader.df(LATENT_CE_TABLE_NAME)\n",
    "reader.close() # close reader\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeZhU1Z34//fnLrX0QnfTICBro4BAA01kiTK4JWqMCUajQSMakohh8lXHx598dSaOXzWZGZNxshiTcYlGTTSSmMQYdcaJC1FHkwiIggrIKg3I0ntXdy333vP741R1F02v2EXT3ef1PPV0Vd3tVEPfT53tc0QphWEYhmG0ZfV1AQzDMIxjkwkQhmEYRrtMgDAMwzDaZQKEYRiG0S4TIAzDMIx2OX1dgN4ybNgwNWHChL4uhmEYRr+yZs2ag0qp4e1tGzABYsKECaxevbqvi2EYhtGviMjOjraZJibDMAyjXSZAGIZhGO0yAcIwDMNo14DpgzAMI/dSqRSVlZXE4/G+LorRQ5FIhDFjxuC6brePMQHCMIxuq6yspLCwkAkTJiAifV0co5uUUlRVVVFZWUlZWVm3jzNNTIZhdFs8Hqe0tNQEh35GRCgtLe1xzc8ECMMwesQEh/7pSP7dTIAwDMMw2mUCBEC8Hppr+roUhmF0oba2lp/+9KdH/boPP/wwe/bs6fFx9957L48++mi399+xYwfl5eU9vk6umAAB4MWh8UBfl8IwjC50FiA8z8vZdTsLEL7vd3jc8uXLufLKK3NVrJwzASIj2dDXJTAMows333wzW7dupaKighUrVrBq1SoWLlzIokWLmDZt2mHfwO+66y5uu+02AM444wxuuukm5s2bx+TJk3n11VcBfYO/8cYbKS8vZ+bMmfz4xz8+5JpPPvkkq1ev5vLLL6eiooLm5mYmTJjATTfdxCc+8Ql+85vf8MADDzB37lxmzZrFF7/4RZqamgC47bbbuOuuuzq9fkfi8Thf/epXmTFjBrNnz+bll18G4N1332XevHlUVFQwc+ZMPvjgA2KxGOeffz6zZs2ivLyclStX9srv2wxzzUg09nUJDKNfuf2P7/LenvpePee044fw/z4/vcPtd955Jxs2bGDdunUArFq1irVr17JhwwbKysrYsWNHp+f3PI+//e1vPPfcc9x+++288MIL3H///ezYsYN169bhOA7V1dWHHHPxxRdzzz33cNdddzFnzpyW90tLS1m7di0AVVVVLFu2DIBbbrmFBx98kGuvvbZb1+/IT37yE0SE9evXs3HjRs455xw2b97Mvffeyz/8wz9w+eWXk0wm8X2f5557juOPP55nn30WgLq6uk5/D91lahAZXhy8ZF+XwjCMHpo3b163x/ZfdNFFAJx88sktweSFF17gG9/4Bo6jvy8PHTq0W+davHhxy/MNGzawcOFCZsyYwWOPPca7777b7et35LXXXmPJkiUAnHTSSYwfP57Nmzdzyimn8K//+q9897vfZefOnUSjUWbMmMGf/vQnbrrpJl599VWKioq69Rm6YmoQGX4S/AQ4ob4uiWH0C5190z+a8vPzW547jkMQBC2v2477D4fDANi2/bH7LLKvu3TpUp566ilmzZrFww8/zKpVq9o9pjeu/+Uvf5n58+fz7LPP8tnPfpb77ruPs846i7Vr1/Lcc89xyy238KlPfYpbb731iM6fzdQgMvwUeIm+LoVhGJ0oLCykoaHj/sIRI0awf/9+qqqqSCQSPPPMM12e8+yzz+a+++5ruWG3bWLqznUbGhoYNWoUqVSKxx57rBufpGsLFy5sOdfmzZv58MMPmTJlCtu2bWPixIlcd911XHDBBbzzzjvs2bOHvLw8lixZwooVK1qavj4uEyAyAg+Ssb4uhWEYnSgtLWXBggWUl5ezYsWKw7a7rsutt97KvHnzOPvssznppJO6POdVV13FuHHjmDlzJrNmzeLxxx8/bJ+lS5eyfPnylk7qtr797W8zf/58FixY0K1rdsc3v/lNgiBgxowZLF68mIcffphwOMyvf/1rysvLqaioYMOGDVx55ZWsX7++peP69ttv55ZbbumVMohSqldO1NfmzJmjjnjBoMb9sPN1KJ0EI4+NarNhHIvef/99pk6d2tfFMI5Qe/9+IrJGKTWnvf1NDSLDdiHRuyMyDMMw+jMTIDJsVzcxDZAalWEYxsdlAkQLAZTpqDYMw0gzAeIQoudDGIZhGLkNECLyGRHZJCJbROTmdraHRWRlevtfRWRC+v3LRWRd1iMQkYpcllVTej6EYRiGkbsAISI28BPgPGAacJmITGuz29eBGqXUicAPgO8CKKUeU0pVKKUqgCuA7UqpdbkqawvLMSk3DMMw0nJZg5gHbFFKbVNKJYEngAva7HMB8Ej6+ZPAp+TwVS0uSx+be3bIjGQyjAGmpym3O/LUU0/x3nvv9fi4p59+mjvvvLNHxxQUFPT4OrmQy1Qbo4FdWa8rgfkd7aOU8kSkDigFDmbts5jDAwsAInI1cDXAuHHjjrigjYkUJHwKIq6pQRjGALN8+fJeOc9TTz3F5z73OaZNa9sQopPwZXI5tbVo0SIWLVrUK2U42o7pTmoRmQ80KaU2tLddKXW/UmqOUmrO8OHDj/g68VRAXVNSD3X1miHoOL+7YRh9Z8eOHUydOpVly5Yxffp0zjnnnJaZzV2l3N64cSPz5s075FwzZswAYM2aNZx++umcfPLJnHvuuezdu/eQ677++us8/fTTrFixgoqKCrZu3coZZ5zB9ddfz5w5c/jRj37EH//4R+bPn8/s2bP59Kc/zb59+wC9lsQ111wD6BnZ1113HaeeeioTJ07kySef7PTzKqVYsWIF5eXlzJgxoyWN9969eznttNOoqKigvLycV199Fd/3Wbp0acu+P/jBDz727zuXNYjdwNis12PS77W3T6WIOEARUJW1/VLgVzksY4vGVFZQ8BIQyjsalzWM/uu/boaP1vfuOUfOgPM6b4754IMP+NWvfsUDDzzAl770JX7729+yZMkSLrrook5Tbp900kkkk0m2b99OWVkZK1euZPHixaRSKa699lr+8Ic/MHz4cFauXMm3vvUtHnrooZZjTz31VBYtWsTnPvc5Lr744pb3k8kkmQwONTU1/OUvf0FE+NnPfsb3vvc9/uM//uOw8u/du5fXXnuNjRs3smjRokPO19bvfvc71q1bx9tvv83BgweZO3cup512Go8//jjnnnsu3/rWt/B9n6amJtatW8fu3bvZsEF/n66tre3GL7xzuQwQbwKTRKQMHQguBb7cZp+nga8AbwAXAy+pdO4PEbGALwELc1jGFomkRxCAlRnqagKEYRyTysrKqKjQgxqz02Zv2LCBW265hdraWhobGzn33HMPO/ZLX/oSK1eu5Oabb2blypWsXLmSTZs2sWHDBs4++2xALyA0atSobpUlO+V3ZWUlixcvZu/evSSTyQ5TkH/hC1/AsiymTZvWUsvoyGuvvcZll12GbduMGDGC008/nTfffJO5c+fyta99jVQqxRe+8AUqKiqYOHEi27Zt49prr+X888/nnHPO6dZn6EzOAkS6T+Ea4HnABh5SSr0rIncAq5VSTwMPAr8QkS1ANTqIZJwG7FJKbctVGbN5PiR8nyiYuRCG0R1dfNPPlUzKbNBpszNNTN1Jub148WIuueQSLrroIkSESZMmsX79eqZPn84bb7zR47Jkp/y+9tprueGGG1i0aBGrVq1qWcmus/IfaS680047jVdeeYVnn32WpUuXcsMNN3DllVfy9ttv8/zzz3Pvvffy61//+pBa0JHIaR+EUuo5pdRkpdQJSql/Sb93azo4oJSKK6UuUUqdqJSalx0MlFKrlFKfzGX5siWDgKSnwDZDXQ2jP+pOyu0TTjgB27b59re/3fLtf8qUKRw4cKAlQKRSqXYX/Okq5XddXR2jR48G4JFHHulwv55YuHAhK1euxPd9Dhw4wCuvvMK8efPYuXMnI0aMYNmyZVx11VWsXbuWgwcPEgQBX/ziF/nOd77TKym/zYJBaUGgaE55FEXNUFfD6I8yKbeHDx/O/PnzO7yZL168mBUrVrB9+3YAQqEQTz75JNdddx11dXV4nsf111/P9OmHZna+9NJLWbZsGXfffXe7ncu33XYbl1xyCSUlJZx11lkt5/84LrzwQt544w1mzZqFiPC9732PkSNH8sgjj/Dv//7vuK5LQUEBjz76KLt37+arX/1qy4JJ//Zv//axr2/SfQMHP9rFtvWvUzr8eE4YFoVEA5xwZi+X0DD6P5Puu38z6b6PkGtZxJIeWLZePMhP9XWRDMMw+pQJEGmWBUlfkQoUJmmfYRiGCRCHSXq+XhPCM0n7DMMY3EyAaCPpKbAEUk19XRTDMIw+ZQJEFluEWMLTSfviZiSTYRiDmwkQWUJOuqPaDkHSzIUwDGNwMwEii2NZNCV8lOXqADFAhgAbxkBRW1vLT3/6074uRpeWLl3a7lyJjt4/VpkAkcWyIFCKZACowKwuZxjHmM4ChOd5R7k0A58JEO1IegFmqKthHHtuvvlmtm7dSkVFBStWrGDVqlUsXLiQRYsWMW3aNHbs2EF5eXnL/nfddVdLTqQzzjiDm266iXnz5jF58mReffVVQCfnu/HGGykvL2fmzJn8+Mc/PuSanaUJv+OOO5g7dy7l5eVcffXVPcqt9OKLLzJ79mxmzJjB1772NRKJRMtnnDZtGjNnzuTGG28E4De/+Q3l5eXMmjWL0047ree/uCNkUm20I+H5FIrSab8Nw2jf9dfDul5eCbiiAn74ww4333nnnWzYsIF16euuWrWKtWvXsmHDBsrKyloyu3bE8zz+9re/8dxzz3H77bfzwgsvcP/997Njxw7WrVuH4zhUV1cfckxHacIBrrnmGm699VYArrjiCp555hk+//nPd/kx4/E4S5cu5cUXX2Ty5MlceeWV/Od//idXXHEFv//979m4cSMi0pKy+4477uD5559n9OjRvZLGu7tMDaINPaPa1zOqk2aoq2Ec6+bNm9dhau22LrroIuDQNOEvvPAC3/jGN1pWhBs6dOhhx2XShAOHBIiXX36Z+fPnM2PGDF566aV2k/y1Z9OmTZSVlTF58mQAvvKVr/DKK69QVFREJBLh61//Or/73e/Iy9PLDixYsIClS5fywAMP4PtHb0EzU4Now7UtYnEPCkIQr+vr4hjGsauTb/pHU3bKbcdxWpLVgf6mni2Tatu27R71WbSXJjwej/PNb36T1atXM3bsWG677bbDrtdTjuPwt7/9jRdffJEnn3ySe+65h5deeol7772Xv/71rzz77LOcfPLJrFmzhtLS0o91re4wNYg2HFtoTgUEEtJJ+wzDOGZ0lXJ7xIgR7N+/n6qqKhKJBM8880yX5zz77LO57777WgJG2yYmaD9NeCYYDBs2jMbGxh6NTpoyZQo7duxgy5YtAPziF7/g9NNPp7Gxkbq6Oj772c/ygx/8gLfffhuArVu3Mn/+fO644w6GDx/Orl27un2tj8PUINoSAEUCi6gfRy8zZ+KoYRwLSktLWbBgAeXl5Zx33nmcf/75h2x3XZdbb72VefPmMXr0aE466aQuz3nVVVexefNmZs6cieu6LFu2rGUN6Wxt04QXFxezbNkyysvLGTlyJHPnzu3254hEIvz85z/nkksuwfM85s6dy/Lly6muruaCCy4gHo+jlOL73/8+ACtWrOCDDz5AKcWnPvUpZs2a1e1rfRwm3Tc63ffu9/9CXslIAOqaU0w6rpCioBbGLzDLjxpGmkn33b+ZdN+9wBKhOZVun/TNSCbDMAYnEyDa4dqiO6rBDHU1DGPQMgGiHS2LB9muSdpnGMagZQJEO2xb9OJB4pqkfYZhDFomQHQiqWwz1NUwjEHLBIhOJANLJ+zzTRIwwzAGHxMgOtCyeJBJ2mcY/dq9997Lo48+etSve9ttt3HXXXd1+/1jkZko14GWxYNC6JFM4YK+LpJhGEdg+fLlfV2EfsvUIDrQsngQQKq5r4tjGAY61fbUqVNZtmwZ06dP55xzzqG5Wf99PvDAA8ydO5dZs2bxxS9+kaYmnWwz8429s7Tda9as4fTTT+fkk0/m3HPPZe/evYdct66ujvHjx7fkeYrFYowdO5ZUKtXhdbtj3bp1fPKTn2TmzJlceOGF1NTUAHD33Xe3pPy+9NJLAfjzn/9MRUUFFRUVzJ49u9OUI73F1CA6YFngK0USh3DSdFQbxmH6IN03wAcffMCvfvUrHnjgAb70pS/x29/+liVLlnDRRRexbNkyAG655RYefPBBrr322pbjOkrbnUqluPbaa/nDH/7A8OHDWblyJd/61rd46KGHWo4tKiqioqKCP//5z5x55pk888wznHvuubiu2+V1O3PllVfy4x//mNNPP51bb72V22+/nR/+8IfceeedbN++nXA43JLe+6677uInP/kJCxYsoLGxkUgk0qNf7ZEwNYguJJVj5kIYxjGkrKyMiooK4NC03Rs2bGDhwoXMmDGDxx57rN3U2+2l7d60aRMbNmzg7LPPpqKigu985ztUVlYeduzixYtbjn3iiSdakvZ157rtqauro7a2ltNPPx1oTfkNMHPmTC6//HJ++ctftqQhX7BgATfccAN33303tbW1Le/nUk6vICKfAX4E2MDPlFJ3ttkeBh4FTgaqgMVKqR3pbTOB+4AhQADMVUrlpLdYGhuxGxqhpM37QEJZFCZjen1qkVxc3jD6pz5K951J2Q06bXemiWnp0qU89dRTzJo1i4cffphVq1Yddmx7abvXr1/P9OnTeeONNzq97qJFi/inf/onqqurWbNmDWeddVa3r9tTzz77LK+88gp//OMf+Zd/+RfWr1/PzTffzPnnn89zzz3HggULeP7557uVjPDjyFkNQkRs4CfAecA04DIRmdZmt68DNUqpE4EfAN9NH+sAvwSWK6WmA2cAqVyVleZmQnv2Hfa2a1nEUgqUb9anNoxjXENDA6NGjSKVSvHYY4+1u097abunTJnCgQMHWgJEKpVqtxZQUFDA3Llz+Yd/+Ac+97nPYdt2t6/bnqKiIkpKSlqWPs2k/A6CgF27dnHmmWfy3e9+l7q6OhobG9m6dSszZszgpptuYu7cuWzcuLFHv58jkcsaxDxgi1JqG4CIPAFcALyXtc8FwG3p508C94iIAOcA7yil3gZQSlXlsJwAOLV1+KkUuG7Ley2LB4VFj2Rywp2cwTCMvvTtb3+b+fPnM3z4cObPn99hJ27btN2hUIgnn3yS6667jrq6OjzP4/rrr2f69OntHnvJJZccUkvo7nXb88gjj7B8+XKampqYOHEiP//5z/F9nyVLllBXV4dSiuuuu47i4mL++Z//mZdffhnLspg+fTrnnXdez35BRyBn6b5F5GLgM0qpq9KvrwDmK6WuydpnQ3qfyvTrrcB8YAm62ek4YDjwhFLqe+1c42rgaoBx48advHPnziMqa9X6tTT85hcEZ5yJPzSrnUlBfdxjdqmHdXwFFAw/ovMbxkBh0n33bwMl3bcD/B1wefrnhSLyqbY7KaXuV0rNUUrNGT78Y968RbAPHGzzHiilSARAMvbxzm8YhtHP5DJA7AbGZr0ek36v3X3S/Q5F6M7qSuAVpdRBpVQT8BzwiRyWlSAaxq6ugbbr1Ep6JJMZ6moYxiCTywDxJjBJRMpEJARcCjzdZp+nga+kn18MvKR0m9fzwAwRyUsHjtM5tO+id6U88AIkCLAaD60pWAjNgWWS9hlG2kBZhXKwOZJ/t5wFCKWUB1yDvtm/D/xaKfWuiNwhIovSuz0IlIrIFuAG4Ob0sTXA99FBZh2wVin1bK7KKvV1ONXVKDeEc+DQ/nDXEWJJ0U1M6VmUhjFYRSIRqqqqTJDoZ5RSVFVV9XhyXU7nQSilnkM3D2W/d2vW8zhwSQfH/hI91PWocOoa8SIh7KoqOGGCnkpNZqirr3fyE2BFj1aRDOOYM2bMGCorKzlw4EBfF8XooUgkwpgxY3p0jEm1kSbxBNKcAM/HaowRDCkE9OJBiaTCCxSOFwfXBAhj8HJdl7Kysr4uhnGUHKujmI46UQqntg4cB6u65tBtQMpX4JnJcoZhDB4mQKSpiItVW0sQDuPuP6BTa2S2oUiYjmrDMAYZEyBaCBIESDIBqRRWrDVlryMWTb4FCZO0zzCMwcMEiCyB6+LU1IFlY9W0NjO5tkWjJ2aynGEYg4oJEFlUOIxVV0cQDuHsa21mcm2LWEpQqbhZn9owjEHDBIhslqWbmVIprHgCSacRziwelFJKD3U1DMMYBEyAaKO1mUmwaw/tc0h6gc7qahiGMQiYANGGCoexa2sJQmGc/YdOBkp6vlmf2jCMQcMEiLYsC4IA8TykMYbEdY3BtYSYb5uhroZhDBomQLQjCIWxa2rAEqx63czk2haNKTPU1TCMwcMEiHaocAi7rh7luHo0EzpANAc2QaKxj0tnGIZxdJgA0R7LAqUQ38eqb0CSSb14EEIq5ZmUG4ZhDAomQHQgcEPYtbWgFFaDrjUoIOkH4MX7tnCGYRhHgQkQHchuZrLTo5kshHjKA9/UIAzDGPhMgOhIpplJBTjVNZDycG2hKRWYlBuGYQwKJkB0IgiF9DrVgN3QiGNbNHq2GclkGMagYAJEJ1Q4jF1fT2DZ2AercGwhrhy8ZjMXwjCMgc8EiM6IoJQgKsCuqgbfR4lDqrnhkPUiDMMwBiITILqgwi52TR3iB1iNMRAh6fsmJ5NhGAOeCRBdyDQzKQG7uhpbhOakGepqGMbAZwJEV9LNTKBw9h3EFWhKeKYGYRjGgGcCRDeosKtTf/se4XizXl3OpNwwDGOA6zJAiMgCEclPP18iIt8XkfG5L9qxQzcz6Y5pp7YOTxySzbV9XSzDMIyc6k4N4j+BJhGZBfx/wFbg0ZyW6lgjggJQCnf/AZQ4JGNmLoRhGANbdwKEp5RSwAXAPUqpnwCFuS3WsUeFXOz6RiSRQOIpUvEmCPy+LpZhGEbOdCdANIjIPwJLgGdFxALc3Bbr2JNpZlIqINJQT1PKNyk3DMMY0LoTIBYDCeDrSqmPgDHAv+e0VMciEZRSECiiB6uIpSyo3tbXpTIMw8iZbtUggB8ppV4VkclABfCr7pxcRD4jIptEZIuI3NzO9rCIrExv/6uITEi/P0FEmkVkXfpxb/c/Uu6ocAi7MUYoEacpYRHU74Pmmr4ulmEYRk50J0C8AoRFZDTwP8AVwMNdHSQiNvAT4DxgGnCZiExrs9vXgRql1InAD4DvZm3bqpSqSD+Wd6OcOafCYey6evB9pLaehB2FA5tN2g3DMAak7gQIUUo1ARcBP1VKXQKUd+O4ecAWpdQ2pVQSeALd0Z3tAuCR9PMngU+JiHSv6H1ABCUCfkDkYBUfxS1I1EHsQF+XzDAMo9d1K0CIyCnA5cCzPThuNLAr63Vl+r1291FKeUAdUJreViYib4nIn0VkYTeud1SoUAgrFiM/HqNmTxVNkg8HNpkRTYZhDDjdudFfD/wj8Hul1LsiMhF4ObfFYi8wTik1G7gBeFxEhrTdSUSuFpHVIrL6wIGj8y1ehUPYDY0Qcil67332b9oNySao33NUrm8YhnG0OF3toJT6M/BnESkQkQKl1Dbgum6cezcwNuv1mPR77e1TKSIOUARUpeddJNLXXyMiW4HJwOo2ZbsfuB9gzpw5R6cjINPM5Pm4pSU0b9xCLDmCfE9BwQhwQkelGIZhGLnWnVQbM0TkLeBd4D0RWSMi07tx7jeBSSJSJiIh4FLg6Tb7PA18Jf38YuAlpZQSkeHpTm7SNZZJwDEzplRlVppzbKxhpVTva4A334HNa/u6aIZhGL2myxoEcB9wg1LqZQAROQN4ADi1s4OUUp6IXAM8D9jAQ+kmqjuA1Uqpp4EHgV+IyBagGh1EAE4D7hCRFBAAy5VS1T3+dDmiwiGs+nqsmlrChQXUhyLECgrIf+0FSNhQXgHuoJtLaBjGANOdAJGfCQ4ASqlVmeR9XVFKPQc81+a9W7Oex4FL2jnut8Bvu3ONPiGCikZxd+5CAPLyOFA6lLzjipBNa6G+CWbNguLivi6pYRjGEetOgNgmIv8M/CL9egnHUHNPX1GhECoUAqUIJZLEt31I036X/EIbJB9qa6G8HMrKwDJZ1Q3D6H+6EyC+BtwO/A5QwKvAV3NZqH5FBBUJY7suVSog6vlYm9ZB4WjYtg0mTYJTT4WhQ7s+l1KQTEI8rh8NDfq47hxrGIbRy7oziqmGNqOWRGQlOkeTkebYFk3JgFgon0K3CQrDQAjefRfWrYPZs6GiAkaO1AckEjoINDdDfT3U1emA4GfNpxCBXbvgtNPAtvvkcxmGMXh1pwbRnlN6tRQDRMS2qY4lyBsSwW7YC6WTYPRo8DwdKDZv1jf94cN1rUBEP1wXwmHdZ9G2OWr/fti7F8aM6ZsPZRjGoGUax3uRZQuer4ilBLwkxNOrzjkOjBoFhYWQlwdVVVBZqWsFpaVQVASRSPt9FcXFOrB43tH9MIZhDHod1iBE5BMdbWIQrgfRXRHXpqopSbQ4D7fhIwgX6UAgooMA6CCRSMB770FBAUyYoINEe2moQiHd4b13L4wde/h2wzCMHOmsiek/Otm2sbcLMlBYlqA8RWMioMQOoKkKCo87fMdwWD/icdiwQdcUxo/XtYy2Skp0LWLUKF0bMQzDOAo6vNsopc48mgUZSCKuQ21zioLiKG5sH+QVgR3uYOeIfjQ1wdtvw7Bhur+hoKB1H9eFVAp279ZBxDAM4ygwfRA5IAIoRUPCB7Gg8WDXB+Xl6f6IhgY96umDD/QIp4xMLSKVylm5DcMwspkAkSNh16G2KUXKjkJzNaSauz4IdM1h6FCoqYG1a3WtAXTTku+3vjYMw8gxEyByRI9gFWqbU2C50LCvZwcXFuqO6+3bdbCA1lpEMpmbQhuGYWTpMECIyJKs5wvabLsml4UaKCKOTUPcI2GFINEAicaencC2daDYtEk3NzmOnm1dWZmbAhuGYWTprAZxQ9bzH7fZ9rUclGXgSdci6ppS4Iagfjf4PexDCIV0YNi0Sc+FKC6GrVtNLcIwjJzrLEBIB8/bezV1ksYAACAASURBVG10IFOLiCtHL0tavQ28RM9Okp+vh8Nu365rFUrpFByGYRg51FmAUB08b++10REB1xZqmjwI5embe9W27ndaZwwZAvv26QlzmVpEooeBxjAMowc6m3V1koi8g64tnJB+Tvr1xJyXbABxHZumhEdz0iEaiugaRPU2KJ4A4W4traE7rouLdYbY/PQxH36os8UahmHkQGcBYupRK8Ug4NpCVSzJMCtExAlDYEHNNiiZAOF2Zk+3x7b1MNj334cZM3QtYuzY1hQehmEYvaizJiYXGKOU2pn9AMZw5FlgBy3XsQmUYnd1nP0NCRLKBjcK1duhubb7JwqHdaDYulU3V+3cmbtCG4YxqHUWIH4I1Lfzfn16m9FDrmOTF3aIJX121zRzoMkn5eRDzYcQq+r+iQoKIBbTSfy2bj10xrVhGEYv6SxAjFBKrW/7Zvq9CTkr0UAnOuNr1HVoTPjsqo1T5YdJ1e7Sk+lUN/v/i4r0WhE1NbBjR06LbBjG4NRZgCjuZFu0twsy6KQDRcR1qI97VDY51B2oJFW/F4KgG8enO60PHNCLETU15b7MhmEMKp0FiNUisqztmyJyFbAmd0UaXEQgEnIIuy7VXoSPdu+idt92/OylRzuSmWm9bZtOwWEYhtGLOutsvh74vYhcTmtAmAOEgAtzXbDBRgQiYYfALaKu+iC1TQlKRpZRGI1gWZ3MSwyH9bDXl1+GiRP1fAnDMIxe0GENQim1Tyl1KnA7sCP9uF0pdYpS6qOjU7zBx7KEUEExYa+ZqsrNfHiwjmRXtYmiIt1R/fLLR6eQhmEMCl0OV1VKvQyYO8/RFikg32smUbOVDxOjGD1iBNGQ3fH+Y8bodSSmToXJk49eOQ3DGLBMuu9jWOBECYXCRGO72L1rC/WxTjqiLUsvOPSnP+k1I7rT0W0YhtEJEyCOccpysSJF5HuNVO18j6qqg6iOhsIWFemkfs8/Dy+8AFU9mFthGIbRhpkRnYoT2vsiCenGqKG+IgKRAiKeR8NHW0g11TJs5FgcN3z4fqWlehLdO+/oNa6nTYN582D48L4pu2EY/ZYJEHvWUrDpP/Hzp9F0rKefchzC+cUkGmvZv72OYaNPIJRffNg+FBXpRyKh50isXQtTpsApp8CoUXofwzCMLuS0iUlEPiMim0Rki4jc3M72sIisTG//q4hMaLN9nIg0isiNOSvkuFPwCk8kv3AHqH7Qbi9CKK+QlHLZ9+Emmg/u6HgRonAYjj8exo3TmV8ffRQef1x3ZldXm34KwzA6lbOvkiJiAz8BzgYqgTdF5Gml1HtZu30dqFFKnSgilwLfBRZnbf8+8F+5KmO6oDSPXURhw/eJqG3E5cScXq63hCJhPN/lo/0HGd5cT8Gw8RAZopuZ2rJtGDkSfF+n5njpJf36uONg/Hj903H0sZalH5nnmZ+GYQw6uWxrmAdsUUptAxCRJ4ALgOwAcQFwW/r5k8A9IiJKKSUiXwC2A7EclhGA1PD5eKko+bKWuNU/AgSAY1tY0QL2NSVI7d1CcckwZMgosEPtH2Dbuo8ikYCDB3VfRX09RKOHBxYRnRcq89Oy9PGZnwUFOtV4SYlpsjKMASqXf9mjgex1MSuB+R3to5TyRKQOKBWROHATuvbRYfOSiFwNXA0wbty4Iy7onmYLq2ECxUPfxw32kLKOP+JzHW2WJeSFI1SnPFLVNZTEG3CHjIRIMdgd/POGw/rR1KSXLi0t1X0W4bBeA9t19cPOmnehlG6SUko/Ghpg9Wq9z5gxum+jqMjUNgxjADlWv/rdBvxAKdUo7TWZpCml7gfuB5gzZ84RLYP6+taDXPFqiv9IzWUR2ykI1lLTjwIEAAJ5IYdYEpJNUOrtIeJ+hOQPh7ySjmsUeXm69tDUBHV1h/dJhEJ6MaL8fL1vJniEQvq9ggLdbLV3r16XIhTS/R0jR+ptnfzbGYZx7MtlgNgNjM16PSb9Xnv7VIqIAxQBVeiaxsUi8j10VtlAROJKqXt6u5Bzxg9lVBR+nJrPWbKRQvU3bFWDLyW9famci4QcUp7PnmabcBJKUh8RbdiPlV8KeUPBbWflORF982+P74Pn6eYozzs0FbnjwLBhMHSoDhbFxXqfHTtgyxb93oQJep+Ozm8YxjEtlwHiTWCSiJShA8GlwJfb7PM08BXgDeBi4CWlZ4EtzOwgIrcBjbkIDgAhx+L/TLL5x7dLeEadwWWsIT94i3r7rFxcLudcx8Z1wPMC9sUdbAtKUgeIxg7i5hVD3jAIdfOGbdv6EQ4fvs33deDYu1cHmSFDdDAoLNT9EsmkXho1CPTr8eP1XAzTX2EY/UbO/lrTfQrXAM8DNvCQUupdEbkDWK2Uehp4EPiFiGwBqtFB5Kg7e6TFI6v3cbdM5fORqRQE79NofZJA+u83X8excLAIAsXBJEgSipK1FMZqcCOFUHAchPKPvBkok2ocdM0imYTt23VAcN1DaxepFLz1lt5/1iyTcdYw+gnpMG1DPzNnzhy1evXqIzq2etWfeO1Xz3BdyTncGl7NV+X7NFpzabRP6eVS9h2lIOH5BIGi0AkYEgqIRPMgfwSECnq3c9n3db+G5+nXmdpFKKTfmzJFNz+ZDm3D6HMiskYpNae9baa+nzY39RHz7Vp+mJjFl6InkB+sJ2bNQYnb10XrFZJewQ4Fzb5PQ5NFJBGnpHEbkUgEq2C4nkdh98Ln7ax2MWKETgGybx/MmKE7sw3DOCaZr3BZ/j78IfW4POF/Bos40eC9rg/qbwRCjk1e2MHHZm/SZXdDiubqSjiwEep266FQvVWzFNF9GMXF+lFVpYfWbtgA//3fevSTmdFtGMckEyCyTLGbONs5yL8nP0mMUeQHb/WP9BtHyHVs8kIOWA57mh32J1xSTbVQtRWqt0BzrW4u6i2WpZubSkr0eT/8EH73Oz2zO5bz+ZCGYfSQCRBKEfrv/2n5FvuN8C58hCf8z+BQT0Rt6eMC5p5jW3oeRSqgMibUqyiBr6B2FxzcCA37wEv03gVFdNPSccfpTuw334T77tNNT70ZkLqilK7R1Nb2Xo3JMAYQ0wfx4osUfPcunHGjqSk7kdEOXOju487UWXzZfor8YC1xmTTwJ32l+yiCQHGgMUGDa1FakE/EUtB0EGL7wS2AgmHg5vdeB3Nenn7EYvCHP8Bf/gKf/rQeFpurIbGZwLBpk54gKKInDJaV6aAVjebmuobRz5gaxIwZ+GOOJ/Lhbob+YiWSSLI0tBsX+LV/DiG1n5BqO79v4NKpOxz8QLG7ppmqZh/PyYdwIQRJqNkBBzZD4wFIxXvvm3d+PkycqBc8WrlSNz3t2KFTevTWNZTSczdef13XWjKd5scdp0dYbdyo1/VevRr2728dhWUYg5SpQXz0ERJrJrBtQtt2MPThx+DKS/lyaA//mjyPy+w/kh+sJWmN6euSHlWuY+PaUN+cojHhMawgTH4oDE4YAl/XKBo/0mk88kr1UNn2Zmr3VGmp7qfYtUvfzIcO1TmeRo/WN/MhQ3r+Db9tjaGwUAeFbJn8VErp2syaNXo01tixOmX6kA4y5RrGAGbmQQC1T/yS/L//Pzh1DSCCd9wwdl+5hAutv+P/Or/lMvuPHHAux5PSXi51/+D7AQkvoCDsMLQghGtl3SgDT/dPqKB3g4VS0NioJ9kppZub8vL0zX3YMB0wMsGko6YopfS6Fxs3tgaGnqT98H2d7TaV0jWcsjI9GzzSC4HQMI4Rnc2DMAECPVEu+bOfUvKXtwlv3Y6yLPziIn655Hp+FJ3Em5FrSMpk6pxP93Kp+5eE56MCRWl+mIKwc3g3RHawcMIQLYVwgX7+cSilU5TH47pZKAj0TbqwUHd2jxrVmk02L0/f2A8c0DWGmhp9c8/UDnxf//Q8/fB9vS0a1edsL60I6Gtnmrsy62iUlBya8dYw+iEzUa4bVChE9ZWXUvTH/yZv9VvYtXUsefgunl/8HZ4d8Xcssl+hQZ1CIPl9XdQ+E3Z0J/bBWIKDsQQigmMJjmVhp9cZcqwQtm1hJT2seCWWgOVEIK8UNxQFJ9TzyXgi+uad+eYeBNDcrGsHBw/quRT5+a2T8yordTNR9jHtnTOzIJLvt87FyCzZWlioz5kJGplzZWo2b76pU4qMH6+Dk5nwZwxAJkBks23qLvgsXmkJQ55/Cbsxxs9/+Y9cs/hGPj/+z+QH62iwF/R1KfuUZQnRkP5vo5eGUHhBQMpXBAoUPplaqeCgAAniSNU2wo7NkKhDJORiO1GdNNCNgOXq5qmO1q84vBD65p2fDtaplA4YmbkU7fUxdFcmTUhtbWvQyFxvyBB97khEnz87e21xcWv2WndgzL43DBMg2hIhtvBU/JISin/zFOFEM3c/9j3eumwas8vW02jNRUkH6ysMMiIgIlh01XnrABFSns9HcYUVDygON5GXaCJsBYAACsTRQcOJgBvVNQ0r1HUzTmaBo95g27q5KbsjPAh0ENq3D3bv1pGxtFR3YA8dqvdpatLzOERaO7aLikzHttGvmQDRgXj5VKqKCil59Ami8QQzHnsHa7FL3pR3idmz+7p4/ZLr2Ljo+2tt0qcmroiEXIqiLhHHxsYHLw7JGCgfSC93aod0TcPN1Dic7gWO3mJZraOcMhoaYN06PbJqzJjW+RxB0LqA0tHu2E6lTO3F6FUmQHQiNXYMVX//dYY+8jhuVQ3qVx55X3yd2KyZIKZz8ki1JA4EUp7Pvvo4IkJx1CUv7BIOtekoDjKBozFrToTSQcKN6LTlTjjdVOWCdRT+bQoKWkdJ7dunR1Udf7yeT1FcrPdJJODdd/XzoUN1p3ZmmG40+vFv5pmO84MH9byN5mbdxFVWpq9nai/Gx2QCRBf8oSUcXP41wr/8LSU7d+A8WcOQ5P9QP++8vi7agJCpVQSBorY5RU0sSTTsMCTi6FqFBVg2SmyUFUZBywPlQ7IZmuvTcUMhIrjhAp2Z1o3q5qpcpRUX0X0SmVrDRx/p2sTIkbqzOxzWtQel9M175079LT8jEtHBpKREB5xM4OiovI2NOiDt3w979ug+l2RSXz/T4V5X17rO+Ikn6r4Ss0iTcYTM/5xuUNEo8a9exhtPvswpG/5C/tNrCGrDNH1yDoFZ/KZXWJYQsVprFR/VeS33yc5GYuvvyDaIAqXvldHmegrtOkKuEHIcJFQA4SJd23DCvf/N2rL0jd739c159+7WFfRsu3VZ17ZzMDxPz7M4cKC1QzyTp6q4WNdAqqp0DWXvXl1jENE3/Eik9dy2rd/LBIgg0EFk1y59npNO0rUbk0LE6CETILrLsXEv+Sz/UyKc8+obFL7yOoWvvI43tIT41MkkJp1Acvw4cM2v9OPKLJtKJjD08H7u+RYHUwEqCY4NhU49EbuWsGVh2bZOGxIZomsXdqj3AoZtt67NvW2bHm47YYJu7mlbK9BDwFpv8JlaRmOjXjujoUEHHNvWwaC0VDdfdSXT1xGP69rGgQN6pFVpqV6oaeJE3XluGN1g7mY9MNpO8tvTr2D+cZsoeKkBuyaFU11D/v/+lYL//SvKtkmWjSc++UQSkybiDys17cAfxxH+6hzbwrH1DTkIFLUpQSUtRIQCV8jzGgg11eJagLgQzk83R6X7MSz343WAO07rutybNumaw6hR+qYdj+tAEG8nj1WmJhAK6c7vj9M0lj1vo7lZ1yh27tR9IGVlMHu2ruGYVf2MTpgA0UNLQvu5Z8plfKv8F6TqRpDYOg5n835CW7djeT6hLdsIb9kGgF9YQHzKJJKTTiBxwgSUSdFw1GU3XSkFTZ5PQ1IBFtGQQ4ELTlMDomqBAEF0BkvHBScKoShiR7BsF3HCSE8CRyikaw+JhK4VZAJAZjLe0fjykN28FQS632L9eli7VveXzJypaz35+a01Gej8ZyaIZR7mS9CAZQJEDw21PEL2NJYm/y//NuRBRn1iA7E55ewPPof74QHCm7cQfn8zbnUNdkMjeavfIn/1WygRUqNGkBo7htSY40mOGY1fOhQs88d1tEh6NT0AlO7rOJBU6YqKhULXMlBKpw2hBvEPIGQtGmU5KCdCxHWIug4h18a19WzyrCu1XjDDdtKjrdzuTwjsbZalO9ULC3UzWE0NPPNMa1nz83XNJz9f91d0JxhmAlB+vu47ycw+D4V0J73rHlkAyXS8G33K5GJC52JKPPozOGFyt495zSvm3vgoFtvPcJX9HL5EabRPa1k7wq6pJbx5K+HNHxDash0rvRCOorXlJAi5pI4fRXL8WFJjRpMaezyBSdlwbAt8CHy8wMcLWv92QpYQcW3Crk3IFlyRQ++LKkjP7UA3ZYWL0gEj0ncBI1tm7fB4XPd9ZILJ0KH6xp+X1/5oKKX0yKzMI5MiPXNfyQSQzLDeTNqScLi1NgW6ltXcrGew19To84wZo4cPm0y6OWWS9XXhSAIEQEIJv0wez+pUku+4D1FubadZJtBgn4EvWaObUh6hnR8S2rUbZ+9HuJV7cOobWjZnBw0/L0pq9CiSZWUkx40mNW6sqWX0A74fkAoUSqVrJCJEXZuoaxFyLBzbxpH0fS7wwEv2j4DR3Nx6sy8o0AEj0xzlOPpn5nlH50mldNDxfX3OpqbWDvm6Ov08w3V1QMkEkEwz3Ukn6WDRUTJF44iZANGFIw0QGXuCMHcnxnCCWs2Nzq8JSUCTNZ+YVQHSfjVZ4nHcvftw9u7D3b2H0K7d2DW1SJt/D78gn4ZPnU7z7Fl6SI7RLygFnu/jK/1CkR6wJIJr2zh2a2e6ozysIIWFjyMW4mYHjHDPkxvmQnYNIzMCK5tIaw3BdVubmUIhXRtpatLBoKHh0MSI4fDho7OCQNcgkkn98DwdRBxHd7BPm6aH7RYUdG9kl9EpEyC68HEDRMb/esU8Hi/km87jfNp+iyZGEHPOxJNuJo7zPJz9B3H3foT7YSXhD7bh1NcDEETCNJ62gNgn50LoGLhhGD2nIFCKQOmahp9OdpjORNXCwSckHq4oQraF7YaxokXYkQLccETPID/WmlyUar2xZ7LjZmfJzaQryQSMI5FK6SaoWEzXWkaO1KO9Ro9unaVeUGAmBvaQCRBd6K0AAZlmp1Hs8/Zwq/sIpdTTaFXQZM/veZI/pQht2Ubh8y8S+mi/fst1iH1yLo2nnYoyE58GpCDICiIBukkqSGEpDwHcUAgnMgQ3rwg7HMF1o9i24NqDqFPX81oXlIpEdIDIdKwPHdqaLLGwsPcDRmZdkUwQzDyyXycSOpA1NuoyTJhwzC40ZQJEF3ozQGTsCcLcnxjOQp5nifMiTQwhac8hLiegpOc3dmf3Xob89wuEtu/U3zgti6bZs2j89OkEhaZje7DQ9ybdhxH4yfS7Fr6bTxAqIBoOEXVtwo6F61i4ltWmstGm5iGi3xNLPywLPTNd+s8oosy8EmhtCkskWvtHSkp0TSOzfG1+vq7JZPeh2Lb+vJmRW76vg1DmRt/QoG/2zc2twSC7cz6R0M1omXku2Z30mUWpZszQw4pHjDimajkmQHQhFwEi43+9Yl5IpLje+SUnWbsIlBCTMQRWGXHrBAIp7NH57KpqCv7nJaLvbWqZiRufOoWGz3wKf2hJr5ff6AeUj/gp8D18FeD7CkVmTQ49tDec7ix3LQvHEiwrPZz3sNmIWfcDsXQKdsvSySktO51JN53WQ9KBRKzWn2QCjrSew5Kj3yyWafLKLC7V3Kxv+EHQurZHfr5+nelbyeyXTLaW1bZb+1SiUR1YMqsbZt87Lat1VFYm8GTLzGxPJPQExVmz9Mz24uI+D8QmQHQhlwECdLPTr5Mj2erHKJcNnGu9yWRrNwD1jARrAgnrBDy6n4HTamik4KU/k7f2bcQPUEBy4ngaPn0m3nHDzKQ8Q1PgBQFemxFWIcci4lgt80JUukkrSB8DEARB+v2AlkRXKkjfGBVkzw8BQJB0aJJ04JH0ydxQGCt/GHZ0CE4o0nfNYW2H84q05rfKfmT2DYJDl6rNTBTM5L7qqSBoHb0lAuPGQUWF/tlHQ9z7LECIyGeAHwE28DOl1J1ttoeBR4GTgSpgsVJqh4jMA+7P7AbcppT6fWfXOpYDRLbdQZhXvRK2eEnGsZFz7NXMtrYA0MBQAikjZU0kJSO79R9Q4gnyX32D/Nf/ipWVKVTZNkFeFL+wAL+kGG/4MLzjhuOXFOMXDyHILzDDZwerNkEDpRd+Ag6rUFhyxBlPDuF7HpYfBxSBHcGPlGBHhhCJhIk4Fq5jp5evlZY0KQNeKqUDRSymm77KyqC8XDdBHcUveH0SIETEBjYDZwOVwJvAZUqp97L2+SYwUym1XEQuBS5USi0WkTwgqZTyRGQU8DZwvFLK6+h6/SVAZKtTNm94JbzjCSVqC2daa/ik9T6u+MQoJCkTUdYYkjIaJV38h/E88v62hui69dgNjVhNTYjf9hteKyWCioTxC/IJ8vMJohGCaBSVn4efn4+KRlDhEEE4jAqHUOFw6/NQGAbLH7HR68RP6j4UFeBZUeJuMb4bBXEI0MN/I45FxLWJuBaubePa4HY2szsIWmsD/Y1Suv+ioUEHjREjWueCZCYVRqOt+bUyKyhmPzpbf70LnQWIXPaUzAO2KKW2pQvxBHAB8F7WPhcAt6WfPwncIyKilGrK2ifCoaMAB4wi8fmMe5DPuJBUxazxL+T/eZfhBDs41VrHadY75Km3CZRQJ8cRyPGIdXz7AcNxaDp1Pk2nzm95S+Jx7Np67No67INVuPv3Y1fVYNc16ADSHMdtjsOBqh6XPQiFCPLzCAoL8IuG4A0twS8pJhhSiJ9+qGi0f/7BGjml7BDYId0/4iWIpPZBCvxQAX64GM/KI+UpmlMpVJCega4CHHzCNkSsgIgT4AYpHHycIIkoT/eJhAshVAhuGOxwr7bv6+Y2nd+rV2XSnOTn66asxkb9yB4VlXme/YU+87cVBHqo79e+1rvlIrcBYjSwK+t1JTC/o33StYU6oBQ4KCLzgYeA8cAV7dUeRORq4GqAcePG9foHOJpCojjFqeMUpw6lomwMPs0PvQuJ+VUMUzuZa73PHGsDEfUWgRJqZQS+HI9tjeqwhqEiEbyREbyRxwGTDr+o52PX12M1xrCa40hzM1asCauxETvWhMSasJqb9bZEAiuRRFJJJFBYySRWMgk1tR1+JiWiayHRKH7REJITJxCfciLeyJGmBmIAoJwwPmFQCvHiuMlKXIHAiSK+j6WSrX0iCgIVkPAVTWKjWjrKbUIhF1cUVnMttjqAJYIlFkQKIFSAuHmIE8ay7JaKRkvarUDPT/GVQgWKVKDw/ABPKTxf4XkBPrpPBoT8kE1hVOfiCjtWa/Ncb7DtnqdjTyT0uiI5cOyMtWpDKfVXYLqITAUeEZH/UkrF2+xzP+m+ijlz5gyYWoYITLVjTLVjACTVaDYGk7nHy6PRr6JEfcjJ1kbmWOuJqLUESqiWEXgympAch28NxaNIj0DpjGPjDy3p+einZAo7FtPBJBbTAaahEbumFqeuHivTxBVPIPEETjyBU1NLeMeHFL70CkoEv7iI1NjRxKdOITlxPEF+/pH9soyBQQTlRNIrBQZI4KFsC5/8Q2qhgr5pHfI/O92nElcKhU2g0k1RgYJ4A5Zf1dJZ7tt5eKFCAidCYIVALD0YsKWRQnfk26I7X2xLsAEXPXhLKUUyFbA3kQIE27YYEnEoiLi6L2WAffHJZYDYDYzNej0m/V57+1SKiAMUoTurWyil3heRRqAcOLJOhn4uJIqZdiMz7UYAPDWarcEk7vfzaPCqKeZDKmQTJ1vvEJEUBOhmKUpolqEoiglbhYgU40kJQZs/up4XyMUPFeOXFHe9b6CQeBynuprQ5m2Et2zF3X8Ap6YWp6aW6Dt6zeYgHMYbMZz4iRNJnDRZ13r6yzh8o3eJpZuhur0/nXRsO0B63pFShIIU4lchmZyC6eMle3EqlbXt0MsArW3eIoKPTbLW4qBl4VsOYTdEQTRMJBIm7LhYVntDga30aGDrmG+CzWWAeBOYJCJl6EBwKfDlNvs8DXwFeAO4GHhJKaXSx+xKNzuNB04CduSwrP2KIzDFbmKKrbtqAjWGncEkfu5HqfcbcFUNBVQxSvZRJh8xUdaTFyRajk+oELUMIyElCEVErSKUVYJHcde1jp6yBJUXJZU3mtSY0cTOWqjfjsVwt39I5P1NLXmoQh9WEvqwEtK1jCA/T3ee56X7OoYMwS8p0rWewgL9fn6+WcXP6B4RlB3qWfDpTHr4b9jODP+N48djNMQC6pWPiBAN2UQcGytdE8ES7HSmX0fQTWRYuslV7NYJi05EL2JlObov5eMsYPUx5OwvK31zvwZ4Hj3M9SGl1LsicgewWin1NPAg8AsR2QJUo4MIwN8BN4tICj3Y+ptKqYO5Kmt/ZwmU2c2U2ZmsmAVAATE1kcogzFtBhJogga/qCKsahlDFGNnHRNnDaHkPK1AQgK8saiilSYYBxUStIrCG5iRwBPn5JMqnkiifmn4jwNl3gPCmD3QOqn37sRpj2I0x2lQqD6MsCxVyCdKZPkU3KqebKtLj2AOlEyG2fYAeoVWQj1dchD98GMnjR+KNPA5/6FBUxGQPNTqQTsSppPXmbTmQqcsoBc2+T2MSFK05tyTzTMAWhS0BjuXjSEo3aVkKK6hHCFpqLWK7EMoDN4o4EcRxEVs3kVmBwsrMcentj2gmyvXdMNe+VKccdgURdgc2saARVA356iAjZR+TpJLxsg9H9DDZQAk1lBKTYUAJUWsIlhTgSx4BeShyNEtWKSSe0IGioQGrrh6nugartg67oRG7MaY71uMJJJXSwSBzKJDdG6ksaUkfoTJpJCwLAoUVjyPp9ToOK4JtE0Qj+IWF+ENL8EYMJzVyBP9/e+caK1l23fXf2nufU4/77Pf0PD0PC9lOjINHRiIGWURBAQkShEkwEAJCSj7EEhESikE8okiAACtAogAAHQtJREFUQUAAKYIEiGQHkxBCDBF84JEgg0GOPTYO9thxPJ6MPdMzPf243fdVVeex9+LD3qeq7u3b3ben7+3bfXv/WkdVderUqb3r3N7/s9Zeey1/6iR+aREd9O97N0HmPmVX8sYQl6QwPyZP/7JCAFpM8EiIC/wUJdge3huGWB79O3/3LTXjqMJcM/cxK9KyYrf4tunNzzKwzESf5dUw4P+Egs2whep1hlzhES7ynLzO2+TrFGHnYFppyTaLTFiklQWUIVYGlNLDJRHxsnDncx8i6KCPH/TxZ07d/vgmOZatueP5C5lUcZL9zUsUr1/EXb6CvXY9TsBvj6Il88ZFePGrOz6ngBYF2u/NFiaurEwXJ/rVFcLSYnSFHbMJzMxdIsRoq33f+9/oGpPQoqNtdHu8x/F3TxaIzA76orzdjnj7VDiWgCVqfYZXQ5/PhpKNMCLoNqJjSrbps8mSbHKadc7Idc7Iq5xg64ZZvlYt65xgxAqtLGNlkb4sJGtk+e4nz+9iLkL7Pdrz52jPn2Pynm/f9aZGkbi6RnHhjSge6+uYjS3s9nYMAd7awm5uUbx5ee/zEzPxar9PWBjGtSKrq7SnT+JPn7r12hHV+B1dKPJojNkaYTdTxFgSMZyLRaaeeJzmkbPocPiWf4/Mg4EaRzAlQhaIzBFSivKsHfPsdJ6jTFuM2Q4KG+p4Uwu+qiVrKlShotUJMMKxxVDXOSlrPCZXeJyXOcP6DhFp1XKdVbZZpZVlYIiVEkdJIQ5LDzU9lB6B3uG5tnYjQlhcICwu0Dz1xN7HqCLjMXYjhvvaK1dxV9ew6xvYjU3M9giZTGI48OYWRUrffsNpRNCyRMsCaVukaaFt932P2f/a16fPQ1HgV5dpz52lftuTNI+dpz1zJs+rZPZNFojMgWAEVqVllRZuuJsZpO0MXuGKlnw+9LisMA5jVLdwbDDgOqtc47xc5XG+wSk2MbtjDueyhwQVRgwYM6SmT0OfRhaABawMGUifQhbwskhgwM2q+x0IIuhwSDscpoWJN8H7JBKbUUguzwnJ5iZmNEaqGlNVqIBahw4HUTT6vbjocDhEFxeiO2t5ibC0iA4GSFVRpEgwd+lyFKLLVykuX2Xw5ZlrLPRK/IkTNI+ewy8uTudj1Bh0mvY6vu5SYKs1qLFoURBWl/ErK1loHgKyQGTuKVbgnNScM/Xc3n7azqIKG1heDD2uBUdFS60NXmuUGtUaQ4VjQpG2AWMGjFiRbc5ygbNco8TvsE68GtZZZptlKpYIsoiVISV9nDgKHEiBSoFSEIiP09oIB/YDWMLqCmF1heaJx/c+JtYrjSVm7/C762efZrt7ERR7Pc2r/M63KC+8jruyFkOML75JcfHNu+qKGhPDkBcX8KsrtCdP0jxyFn/2dEy7srDLZRgCZjTCbG7H9C9ra7i1a9jrG5itrbjwcjJB6gYti3i+Jx6jeu4ZmscfzXVPjoAsEJn7ChFYwbNiRzE4evYO0EvbjTU0VGGM4XUt+U1fsElNFSYE3cKwTY9NFtlglXUekTUe5Rss0hWZuXl7WjVU9Kjo0VDSUlLTp2VIkCFGBpT06UkPawYEFgj0785aETmYtR1Gpivlq3f8rrlOtbgrV3EXLyFVBSGGA4sPs/TW6bV0Kb5D3GfqOg7u6xtxsB+NsdujPedepu4yZzFVvS9XWReyLFVN+foblK+/wcJvxOhEdY72xCrNY+epnn2G5snH8CdO5KzEh0gWiMyxQASGBIYy4QnTZWQRukl2eAQAr7CmBZ/RkmtBqbTC06DagjYgDaINhgZLjUtbSU1JRZ+KJRlxmjc4w3X6pBTrc+URvApbLE4juxqGBCnpkkQIDhGLwWJxWLE4LC7tQ1yyYvrRijnoeRbnaB85R/vIubs/l2oUimvrFJevYN+8hLuyhr1+PYUhTzB1jZYFOlzCD4eEpQXC8jLtiVXaUycJJ1bwi4s7Fz0Gxa6tUX7zW/ReeoXijYuYa9cpLl+huHyF4Re/FL/eGPzyEu3Z04DEcOdu7sa3SOtjCLP3UwGUrpCQCKHfIyws4FeW8adP0pw7S3P+EfzJ1VhTZZ+/vdR1DBjY3MJeu4a7eh17/TpmNKY9e5rqmadpHj//wAUOZIHIPFRYgTPScIZmzkIxzCbdb89Ehcta8LXg2NAoMq1OUB1hiJFdA7ZYZJNV2eSMXGCoE/o0DCWtaJ+3Wm5hwVRasMUiIxaoGNIyRGWA0MdJj770KKUHMkgT95boFrtHIbUiMV38wgLt448e3HmN4E+fYnz6FOP3fkfcp4rZ2KR47QK9r79M+drr0U11fR13ff2mp1KZWwNjTQxLtiZaRJNJtIAuXYavf+OGz2mvJAxj1Fl78gQSQkynv7WNGY+RqkLqJi7CvBm//RKLn/4MAKFwhOVlmkfOUj/1JNVzz+BPn7xv08pkgchk7pC+KOel5vyOeZROYHbmp2pUuKqO17BUaqhUqFVp8XhaPIGgHqUlqAdaVD1GaoyOKRkxYJtFtliWLU7Ja5zSDQaSspzeZFxq1dBS0GBpKWhjYuzpFrDpeQ8vfaCHSB9LSSklfSkR6SUrpnfvBOdWiBBWlqlWlqne9Y7Z7tEId+UqGBstlWJ+c7cffJsGe20dd/EixcVLuCtXsdfWsVtbmPEEu3YNt3aN3ivf2vGxLnQ5DFNKmIUhYWkppr9PKWF0OMBduEjvlW/iLl7Crq/jrq7hrq4xePG34nlEYvDBqRPUj56nfeQsUjeYqkKqGqm7rYkWUtMgTRstpbaFpqE5cwr+6cH+3JAFIpM5VApRzkoDNLc4qrNgbk2jwpo6XtaCjRCYUNNoRdAJMMFohcEjeAwtlhaDx9Fg8VhaXJKLQhp6NCxxhVNsscoW9mZZ6oAtHbDNAhMGU5FRLGH6aAEXE+1hkelmMOJwFJQSN5F+snYORnh0OKR58i5cN0URJ9bPnqZ69x7ve4/d2MRevhJX1q+sEBaHaK+3LxdU8/hjjH/ve6evpapwr1+k943foXj1QlxXs72NffUC5au785nuj9A7oPxSu8gCkck8IBSie7jHirTdOHF/K1ShRdhWy0s4NoNlrC01Na3WBK2ACqsTnIwodUKfEQNGFNIJTUXJVpy+l5aShp429GjpyZwg6q7HOcbaY8SQCQMq+rT08fRRccldZiA9xjXHFkkZUQUT/0l8LMVRUICUBMq0TuYALB9rY6ne/WQv3gfa69E8/RTN00/t2G+2tihf/ib20hWYq+YY+n2030N7PdQ51FlwLj13hKpCtjY4QAfflCwQmcxDiAgU6Gztyo5xtBOd24eVtgoNhk2S+wxDrYZGoQa8Bho8NQ2txjBlqBCtsFQUjOkxjqtZZMwSWyzLm/S1pqC9UWzgRqG5hft/rD0m9FMkWp+GWKAoUBIkhTHPbZ0ACRaDQcRisQiCE0uBxYhDKQkURKvpYIIIwuIik3e/684/WB9eFFcWiEwm85ZxAo7AgMCtY1hvHabcUSU3WoWhRWhUaFXwQKsBTwDiYyCgaQvqCTSoRndeFKCaggmOmh5j+lIxYMIi11iRMYs6oUzBy0bmVGafAQQQI9YmRBGKsW492hQO7SlTFJqdBQ8kKwgsRjorKIqSTRZRFCKThKhAcdPtXs8FZYHIZDL3DT3RGy2GW5IK8OCI4nNrVKHCsKaW1zC0aqgVPNHa8Ul6/FR8PKo+PY8BBHE+qcFojZUGqxWOhpIqhkJLxYARQ9ZYkIqe1pRdqIDMpQK4AyHqqNVR0aOmoKGkoaC1jrXhY9nFlMlkMneDCPQJ9CVw+/zAnfgUd/w9IS3cfFMtNYYGoVFDnWpfRynSqSAFAqrxOVNRaokOvBaj6ZEGR4NLEhG3mityOOsrskBkMpnMAWMEFggszFsMN0WYzYPcOWE05sntm68DuRvug+DmB5QuJUEmk8kcU7IFcSt8QHxKt9z62RycKupsXLrfvTYm5vt3Dlz+WTOZzINPHskSUjfI2jVkGrKmMbXxYEBYGMIgpVzuVmdaG/O7VFUs5jIax2yUW9uYapJqImt0ejpHcC5m59xdEzlorAk93RctEwmpXrIwFR21FhFQMakAu0klNVNqZiGuGr1d2F3Q2YpMDWl+TOL3p7TOMcWzTcXUczK0TOZhJAsEoMsrjJ9+gvLE2TQQG7AuDo4hpDX1IVkSLTJmFtLnXKwDsLycLIgiDuSaEoNVdczxPx4jbRM/aM10kUs3EKtLg7Kbs0KsgabFbmxg1mPRGcIs6di0rrJqFKtk6ewIiQgBaRpo2lSzOVk7Sfi034/fpwFpfDy2bjBti1QTxIfYn/hLxdLrRqKIpDrPKmb6nO75W74YnVAy58LbvcJ352thJrZIrCM9bcd9muMmk3kQyAIB6KPn2fiD72d44pF9fiANSHc6+HSD+h3Sdk+8j1kjxxUy2p5WJ6Npo9VhBLVumrFSAaxJ+WGWCAsLURD6u1IEqM5EJOV9MeMxZjtaRUzGUXhaj/g2CpSPWTLFB8TX0SrxPrrlNImqsHNQ7/aFlEQogEgSnU4MOtFJ4je150SSOMXXIhJPKRLPKUksQ8C0oyhsPqQC7/F9tSbm67EWMUKSlqnlFUUvWWN2TnxT+msgJmVLLsWpQO95rXWaJrv7PbQTrLsV0UzmHpEFItHWNaONawgabzzRmACSuAlxADZiiHfSMyMihEBAYsr8eCQ+xMHLT2uidXfajsI5CmtwRm6zuGgX1qKDAX4wgJNzy/6bBjOpYknL7W20KGfWQW8fZTlT3n7KEl2I4XJ+/v0QUqKwOiYJG0+Qpt7zVN3xXf0AmasvMB2EnUOdQW0BrhtobRrAu8FTZm4z6VxpMb0zdKIge7vUujmjponPJxUyGmMno5h+elRBNYmDfQjgA6ZtoG6RyQRpW0zbgvekyvJTMQipTcaHORdd/JsQJP1lAMYSegW4Mj5aC22DqesoxDr7G9IkpPN6qkl4RDWKnEZBRZL7sRPZZGlJytynxu6wTGfiZ3Y83vC7dRZYSAKfBE7C7DnITLBVp7+LJtHbce67EcAuHbc94GJNu75D2jbdDBzi9zzgZIEAFheXeOrt76IJsfJYq9CqxIyYaSVnG6ANsZ5AvOuc3fU6gdIozgQKCZQEnMTnhVGsKEY9Ejx1NWI82WA0ahl7gICqxiX9zuFciXUONQ7MrrA37SKnQkovrGhQQvB4p4SFEgaOIDFsToMnTKq0krNzEt2cbswVSQOBxCFBBMQViCthCLLCdK6mu4G/I6E7bLo8NbtKYrbzL9IAQdvGH8XM3GM7XGY+HjerKRAtqTg42jS4R6tCukFWk3hUDVLHjJymid/u576faTGeKFJdnYLYLh8H37KYcz1aKFy0Ep0l2DQ3VaRHkVibYWMzpqSeTKLINantSix5ms4/FanOInI2lji1FuycSMG0BKmKmVpR+CR0qhivEHzsZ+ujBStmXjLpRHR6w+A7i9RDEllIRYOsiTcjSTZj8aEeIeUkwu0zJLS7WWjbqRUIRLEf9OJ7o/Eua5fpnJ9ac/8FnYQwq1XetkjT4O1bC5G9HfdZz4+G/uIq/cX37Pt4H5SgihFJ48gdjo4hQGgIbc2kqqirivFkxGh7m9H2Jk01xvgNjK/SwK6ISMyYaWx0qxAHCGMs1pY45zCuwJUWR4C2xoQa42tEY9UwI/HOvEuP393CijFoCPigKJrm15XgIWjaFySuLQ3x/ZDmCVTisdFNRLzDVXYOCmLiHacwfU8AawzWgDWC7QZonU6Zz52BtC/tFZ1NT8yrU+pfnMQ3sU0pu2hACPF2moCmaY7O3QSltXt7i7rotDu7wneMavq7Ci0hJPeYNRS2wLr9uyV3WH5tchlWNWYyiQEUW9txQIQ4iGv828IYVJJYWJeSxPXQsof2immiuDhYKtJ4aBtkUsUyoVWFmdT4up6euxNB8SEKabo+COigH1NkD4eE4RDtlXFzJZQuCm5Vz+ourG/g1tYw19ZxV6+Cj/NpUdxNtNLERKvRB0y6kVJXxO/p96HXm6UD76yrZLnRzgZcmhZTV0hTY7YbxLeomNmNw9w8mdHO9AsQkm8hpJsFkWR5sWN+Tufm7cTsCjLprGMEQnLrdjcoqb1q7ez366/gVWl7WSDuG6yJiYzfMsaA6WFcj2F/iSE7qwj4oFStp6pbWh+w1mCtjd8rEuvISxxU9y1OwUNo5x7Tc/Xgm/THmyZ397MB8a817Ng0eDQJzfS1hqkANd3WKOPWM26VUe2pWp8G8G6Qj7k7USVoQCTdpUMa1NJ/QgVVH///BY+oR1L/TGiQ4LFUsSqChmjNiWKMib+jEWofGI0D3s/uMI0IhY2/sbV7DNBp8kL2kI5uft1rmBPUeF3jiJREX5m7AVAKm9yPzuF6JW3TMB5tUM21yxqhsAbrCsRGS1NlD2sTZnfBgx5Bl+DcqfSbheh2q5KF4Qq0KFOQRRkDNN6qy0V1dmfbtklI2tiWMkYAarkPtycxes8vDKeit8OpOR5jtkbYrW3Mxjo2iUZYXiYsLhEW+rEiXFHMub7mgyvSYB90R+BHfEwWV90gSQSjEI6Rqk2u0DTfZ02yuGxyn87msigcakx0CTbpXNPaDj66aZsG07RoCBgNaPxDQQSC7c2CSRaGhLKMv92ucrS+bfFmPwvy7pwsEPch1gjD0jEsD/DyGLv3IHLAdEP8zRjcZL+q0gal8YGmVWofqFuPkc66iIO2kB47V9ie++PzKKay+4uSMIYojmEW9dX4QNXGbVS1bE1arlUtVVoDo8RUa84ZNOhUAGK/4zyAJtOmsELPCoUz9J2hsIbSWZwrotg7g7MOay2FdRh7k8I2qjRNxWQyoapqNkYjtkdjJtub0E4w9QTrN2KuHxctsAAQ4qNiUEy0oJKrMYhDpZ/KX5oopsQynVJViLY75lZmEw+7rrRqtBiToEuKINDpnJFAIXFuqxP7pkXrZq6vKfhgat3Oz4sksU+PRtN1SwEKFMCJHnriPPrM04gozlc4E60iYyTNJXowJCGV6L6VnSI4i6VIIo4SvEZrTuOjT4Ef1ljEOqyx8TsOIlDO+50C5ZKQ7uejTYOvRwfQiBvJApG5L5B0x15Ys9/Kn2/1i+Id8h7MJ7mez9PTzgnHdtUybjxGYFBYCmcojMFaiY9GcGYPYbqL9hZln6LsswScTrtVlaoNTBrPqPKsjyuub48RY6J1ZA3W2Gm7jICba19nfe6+kZ9FFmsUUA1oaIEu4CC5jkjzYWleLFqOUXA1tPFznQB7j3TzcICRdK4upEM9ol14R4oWIw7k6pZR10PdAHV9gi3BFKgpCMaCFKixhBBvMKrWUzc1TV3TVBVtWxPaFuNHWF9hmjHGjzFtNa1LDSH9Dp0LMrrcrDHRmnOOonQ4F39bX1e09RbNpKH2Gi3DOZetptQZxtqp8Gty2xJmczLRANYueHzOlQrqo1grYTYPSAqYmbsJEojX6ZAmAbNAZDK3wVmDs4aFHpxcOEz12j8iQr+w9AvL6hAePTFgd7nTB5ZOpQ6qzkISDx+UNrk626D4tonrWI3FWouzNwrobU6c5hIbmrahbRq8b/B1TdtMaKoRTTXB+xojNsY1iCDGROtWwFqThDrOQYjMHJfdPJ8PaQN8CLRe8RoDZuK8VaC3sHwgv9VuDlUgROR7gH9CzEL1L1X1o7ve7wEfB94LXAV+QFVfEZHvBj5KvJesgb+iqr9+mG3NZDL3CQcccmqMUE4tunk36+3Tg9/mxNO5xK7SxXHj0JaZiogFfhr4w8A7gQ+JyDt3HfYXgWuq+hzwU8DfS/uvAH9UVb8d+CHg5w+rnZlMJpPZm8PMQ/A+4CVVfVljncFfBL531zHfC3wsPf9l4LtERFT1/6rq62n/i8AgWRuZTCaTuUccpkA8Brw69/q1tG/PY1S1BdbhhjoefwL4gqpWu79ARH5YRF4QkRcuX758YA3PZDKZzH1eD0JE3kV0O/3IXu+r6s+q6vOq+vyZM2fubeMymUzmmHOYAnEBeGLu9eNp357HiIgDVoiT1YjI48AngT+nqt84xHZmMplMZg8OUyA+B7xdRJ4WkRL4U8Cv7jrmV4mT0AAfBH5dVVVEVoH/DHxEVf/3IbYxk8lkMjfh0AQizSl8GPgvwFeBX1LVF0XkJ0Xkj6XD/hVwSkReAv4y8JG0/8PAc8DfFJEvpu3sYbU1k8lkMjciqnr7ox4Ann/+eX3hhReOuhmZTCbzQCEin1fV5/d877gIhIhcBr6ZXp4mrqV4GHmY+w4Pd/9z3x9e7qb/T6nqnlE+x0Yg5hGRF26miMedh7nv8HD3P/f94ew7HF7/7+sw10wmk8kcHVkgMplMJrMnx1UgfvaoG3CEPMx9h4e7/7nvDy+H0v9jOQeRyWQymbvnuFoQmUwmk7lLskBkMplMZk+OlUCIyPeIyNdE5CUR+cjtP3G8EJFXRORLaeX5sV41KCI/JyKXROTLc/tOish/E5Gvp8cTR9nGw+Qm/f8JEbkwl33gjxxlGw8LEXlCRP6HiHxFRF4Ukb+U9h/763+Lvh/KtT82cxCpQNFvA99NTC3+OeBDqvqVI23YPUREXgGeV9Vjv2BIRP4AsAV8XFW/Le37+8Caqn403SCcUNUfP8p2HhY36f9PAFuq+g+Osm2HjYicB86r6hdEZAn4PPB9wJ/nmF//W/T9+zmEa3+cLIj9FCjKHBNU9X8Ca7t2zxeg+hjxP86x5Cb9fyhQ1TdU9Qvp+SYx19tjPATX/xZ9PxSOk0Dsp0DRcUeB/yoinxeRHz7qxhwB51T1jfT8InDuKBtzRHxYRP5fckEdOxfLbkTkbcB3AL/BQ3b9d/UdDuHaHyeByMD7VfX3EOuA/2hyQzyUaPSdHg//6f75Z8CzwHuAN4B/eLTNOVxEZBH498CPqerG/HvH/frv0fdDufbHSSD2U6DoWKOqF9LjJWKxpfcdbYvuOW8mH23nq710xO25p6jqm6rqVTUA/4JjfP1FpCAOkJ9Q1V9Jux+K679X3w/r2h8ngdhPgaJji4gspEkrRGQB+EPAl2/9qWPHfAGqHwL+4xG25Z7TDY6JP84xvf4iIsRaMl9V1X8099axv/436/thXftjE8UEkEK7/jFggZ9T1b99xE26Z4jIM0SrAcAB/+Y4919EfgH4ADHN8ZvA3wL+A/BLwJPE1O/fr6rHciL3Jv3/ANHFoMArwI/M+eSPDSLyfuB/AV8CQtr914i++GN9/W/R9w9xCNf+WAlEJpPJZA6O4+RiymQymcwBkgUik8lkMnuSBSKTyWQye5IFIpPJZDJ7kgUik8lkMnuSBSKTuQ8QkQ+IyH866nZkMvNkgchkMpnMnmSByGTuABH5syLy2ZRz/2dExIrIloj8VMrP/2siciYd+x4R+UxKoPbJLoGaiDwnIv9dRH5TRL4gIs+m0y+KyC+LyG+JyCfSqtlM5sjIApHJ7BMReQfwA8B3qup7AA/8GWABeEFV3wV8iriqGeDjwI+r6ruJK1+7/Z8AflpVfzfw+4jJ1SBm5vwx4J3AM8B3HnqnMplb4I66AZnMA8R3Ae8FPpdu7gfEhHAB+LfpmH8N/IqIrACrqvqptP9jwL9L+bIeU9VPAqjqBCCd77Oq+lp6/UXgbcCnD79bmczeZIHIZPaPAB9T1b+6Y6fI39h13FvNX1PNPffk/5+ZIya7mDKZ/fNrwAdF5CxMayA/Rfx/9MF0zJ8GPq2q68A1Efn9af8PAp9KVcBeE5HvS+foicjwnvYik9kn+Q4lk9knqvoVEfnrxKp9BmiAHwW2gfel9y4R5ykgppz+50kAXgb+Qtr/g8DPiMhPpnP8yXvYjUxm3+RsrpnMXSIiW6q6eNTtyGQOmuxiymQymcyeZAsik8lkMnuSLYhMJpPJ7EkWiEwmk8nsSRaITCaTyexJFohMJpPJ7EkWiEwmk8nsyf8H1LS4wvOt/VgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=results, x='epoch', y='trunc_train_loss', label='trunc train loss')\n",
    "sns.lineplot(data=results, x='epoch', y='naive_train_loss', label='naive train loss')\n",
    "sns.lineplot(data=results, x='epoch', y='trunc_val_loss', color='red', label='trunc val loss')\n",
    "ax = sns.lineplot(data=results, x='epoch', y='naive_val_loss', color='red', label='naive val loss')\n",
    "ax.set(xlabel='epoch', ylabel='CE Loss')\n",
    "plt.show()\n",
    "\n",
    "sns.lineplot(data=results, x='epoch', y='trunc_train_acc', label='trunc train acc')\n",
    "sns.lineplot(data=results, x='epoch', y='naive_train_acc', label='naive train acc')\n",
    "sns.lineplot(data=results, x='epoch', y='trunc_val_acc', label='trunc val acc')\n",
    "ax = sns.lineplot(data=results, x='epoch', y='naive_val_acc', label='naive val acc')\n",
    "ax.set(xlabel='epoch', ylabel='Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
