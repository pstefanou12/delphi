{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../..')\n",
    "sys.path.append('/opt/anaconda3/lib/python3.7/site-packages')\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "from cox.readers import CollectionReader\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "from torch import sigmoid as sig\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.distributions import Gumbel, Uniform\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.transforms import SigmoidTransform\n",
    "from torch.distributions.transformed_distribution import TransformedDistribution\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "from abc import ABC\n",
    "import os\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUNCATED_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionTruncated/'\n",
    "STANDARD_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionStandard/'\n",
    "\n",
    "TRUNCATED_EVAL_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionTruncatedTest/'\n",
    "STANDARD_EVAL_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionStandardTest/'\n",
    "\n",
    "GUMBEL_CE_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionGumbelCE'\n",
    "\n",
    "LOGS_SCHEMA = {\n",
    "    'epoch':int,\n",
    "    'val_prec1':float,\n",
    "    'val_loss':float,\n",
    "    'train_prec1':float,\n",
    "    'train_loss':float,\n",
    "    'time':float\n",
    "}\n",
    "\n",
    "EVAL_LOGS_SCHEMA = {\n",
    "    'test_prec1':float,\n",
    "    'test_loss':float,\n",
    "    'time':float\n",
    "}\n",
    "\n",
    "# scheduler constants\n",
    "CYCLIC='cyclic'\n",
    "COSINE='cosine'\n",
    "LINEAR='linear'\n",
    "\n",
    "LOGS_TABLE = 'logs'\n",
    "EVAL_LOGS_TABLE = 'eval'\n",
    "\n",
    "CKPT_NAME = 'checkpoint.pt'\n",
    "BEST_APPEND = '.best'\n",
    "CKPT_NAME_LATEST = CKPT_NAME + '.latest'\n",
    "CKPT_NAME_BEST = CKPT_NAME + BEST_APPEND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Procedure Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer_and_schedule(args, model, params):\n",
    "    param_list = model.parameters() if params is None else params\n",
    "\n",
    "    optimizer = SGD(param_list, args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "    # Make schedule\n",
    "    schedule = None\n",
    "    if args.custom_lr_multiplier == CYCLIC:\n",
    "        eps = args.epochs\n",
    "        lr_func = lambda t: np.interp([t], [0, eps*4//15, eps], [0, 1, 0])[0]\n",
    "        schedule = lr_scheduler.LambdaLR(optimizer, lr_func)\n",
    "    elif args.custom_lr_multiplier == COSINE:\n",
    "        eps = args.epochs\n",
    "        schedule = lr_scheduler.CosineAnnealingLR(optimizer, eps)\n",
    "    elif args.custom_lr_multiplier:\n",
    "        cs = args.custom_lr_multiplier\n",
    "        periods = eval(cs) if type(cs) is str else cs\n",
    "        if args.lr_interpolation == LINEAR:\n",
    "            lr_func = lambda t: np.interp([t], *zip(*periods))[0]\n",
    "        else:\n",
    "            def lr_func(ep):\n",
    "                for (milestone, lr) in reversed(periods):\n",
    "                    if ep >= milestone: return lr\n",
    "                return 1.0\n",
    "        schedule = lr_scheduler.LambdaLR(optimizer, lr_func)\n",
    "    elif args.step_lr:\n",
    "        schedule = lr_scheduler.StepLR(optimizer, step_size=args.step_lr, gamma=args.step_lr_gamma)\n",
    "        \n",
    "    return optimizer, schedule\n",
    "\n",
    "\n",
    "def eval_model(args, model, loader, store):\n",
    "    \"\"\"\n",
    "    Evaluate a model for standard (and optionally adversarial) accuracy.\n",
    "    Args:\n",
    "        args (object) : A list of arguments---should be a python object\n",
    "            implementing ``getattr()`` and ``setattr()``.\n",
    "        model (AttackerModel) : model to evaluate\n",
    "        loader (iterable) : a dataloader serving `(input, label)` batches from\n",
    "            the validation set\n",
    "        store (cox.Store) : store for saving results in (via tensorboardX)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if store is not None:\n",
    "        store.add_table(EVAL_LOGS_TABLE, EVAL_LOGS_SCHEMA)\n",
    "    writer = store.tensorboard if store else None\n",
    "\n",
    "    # put model on device\n",
    "    model.to(args.device)\n",
    "\n",
    "    assert not hasattr(model, \"module\"), \"model is already in DataParallel.\"\n",
    "    if next(model.parameters()).is_cuda and False:\n",
    "        model = ch.nn.DataParallel(model)\n",
    "\n",
    "    test_prec1, test_loss, score = model_loop(args, 'val', loader,\n",
    "                                        model, None, 0, writer, args.device)\n",
    "\n",
    "    log_info = {\n",
    "        'test_prec1': test_prec1,\n",
    "        'test_loss': test_loss,\n",
    "        'time': time.time() - start_time\n",
    "    }\n",
    "\n",
    "    # Log info into the logs table\n",
    "    if store:\n",
    "        store[EVAL_LOGS_TABLE].append_row(log_info)\n",
    "        store.close()\n",
    "\n",
    "    return log_info\n",
    "\n",
    "\n",
    "def train_model(args, model, loaders, *, device=\"cpu\", dp_device_ids=None,\n",
    "                store=None, update_params=None, disable_no_grad=False):\n",
    "    # clear jupyter/ipython output before each training run\n",
    "    if store is not None:\n",
    "        store.add_table(LOGS_TABLE, LOGS_SCHEMA)\n",
    "    writer = store.tensorboard if store else None\n",
    "\n",
    "    # data loaders\n",
    "    train_loader, val_loader = loaders\n",
    "    optimizer, schedule = make_optimizer_and_schedule(args, model, checkpoint, update_params)\n",
    "\n",
    "    # put the model into parallel mode\n",
    "    assert not has_attr(model, \"module\"), \"model is already in DataParallel.\"\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    best_prec1, start_epoch = (0, 0)\n",
    "\n",
    "    # keep track of the start time\n",
    "    start_time = time.time()\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        train_prec1, train_loss, score = model_loop(args, 'train', train_loader, model, optimizer, epoch+1, writer, device=device)\n",
    "\n",
    "        # check score tolerance\n",
    "        if args.score and ch.all(ch.where(ch.abs(score) < args.tol, ch.ones(1), ch.zeros(1)).bool()):\n",
    "            break\n",
    "\n",
    "        last_epoch = (epoch == (args.epochs - 1))\n",
    "\n",
    "        # if neural network passed through framework, use log performance\n",
    "        if args.should_save_ckpt:\n",
    "            # evaluate on validation set\n",
    "            sd_info = {\n",
    "                'model':model.state_dict(),\n",
    "                'optimizer':optimizer.state_dict(),\n",
    "                'schedule':(schedule and schedule.state_dict()),\n",
    "                'epoch': epoch+1,\n",
    "            }\n",
    "\n",
    "            def save_checkpoint(filename):\n",
    "                ckpt_save_path = os.path.join(args.out_dir if not store else \\\n",
    "                                              store.path, filename)\n",
    "                ch.save(sd_info, ckpt_save_path, pickle_module=dill)\n",
    "\n",
    "            save_its = args.save_ckpt_iters\n",
    "            should_save_ckpt = (epoch % save_its == 0) and (save_its > 0)\n",
    "            should_log = (epoch % args.log_iters == 0)\n",
    "\n",
    "            if should_log or last_epoch or should_save_ckpt:\n",
    "                # log + get best\n",
    "                ctx = ch.enable_grad() if disable_no_grad else ch.no_grad()\n",
    "                with ctx:\n",
    "                    val_prec1, val_loss, score = model_loop(args, 'val', val_loader, model,\n",
    "                            None, epoch + 1, writer, device=device)\n",
    "\n",
    "                # remember best prec@1 and save checkpoint\n",
    "                is_best = val_prec1 > best_prec1\n",
    "                best_prec1 = max(val_prec1, best_prec1)\n",
    "                sd_info['prec1'] = val_prec1\n",
    "\n",
    "                # TODO: add custom logging hook\n",
    "\n",
    "                # log every checkpoint\n",
    "                log_info = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'val_prec1': val_prec1,\n",
    "                    'val_loss': val_loss,\n",
    "                    'train_prec1': train_prec1,\n",
    "                    'train_loss': train_loss,\n",
    "                    'time': time.time() - start_time\n",
    "                }\n",
    "\n",
    "                # Log info into the logs table\n",
    "                if store: store[LOGS_TABLE].append_row(log_info)\n",
    "                # If we are at a saving epoch (or the last epoch), save a checkpoint\n",
    "                if should_save_ckpt or last_epoch: save_checkpoint(ckpt_at_epoch(epoch))\n",
    "\n",
    "                # Update the latest and best checkpoints (overrides old one)\n",
    "                save_checkpoint(CKPT_NAME_LATEST)\n",
    "                if is_best: save_checkpoint(CKPT_NAME_BEST)\n",
    "        \n",
    "        # update lr\n",
    "        if schedule: schedule.step()\n",
    "\n",
    "        tqdm._instances.clear()\n",
    "\n",
    "    # TODO: add end training hook\n",
    "\n",
    "    # model results\n",
    "    if isinstance(score, Tensor):\n",
    "        print(\"avg score: \\n {}\".format([round(x, 4) for x in score.tolist()]))\n",
    "    if train_loss != 0:\n",
    "        print(\"avg loss: {}\".format(train_loss))\n",
    "    if train_prec1 != 0:\n",
    "        print(\"avg top 1: {}\".format(train_prec1))\n",
    "\n",
    "    # close store at end of training\n",
    "    if store is not None:\n",
    "        store.close()\n",
    "    return model\n",
    "            \n",
    "            \n",
    "def model_loop(args, loop_type, loader, model, optimizer, epoch, writer, device):\n",
    "    # check loop type \n",
    "    if not loop_type in ['train', 'val']: \n",
    "        err_msg = \"loop type must be in {0} must be 'train' or 'val\".format(loop_type)\n",
    "        raise ValueError(err_msg)\n",
    "    is_train = (loop_type == 'train')\n",
    "    \n",
    "    loop_msg = 'Train' if is_train else 'Val'\n",
    "\n",
    "    # algorithm metrics\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    score = AverageMeter()\n",
    "    \n",
    "    # check for custom criterion\n",
    "    has_custom_criterion = has_attr(args, 'custom_criterion')\n",
    "    criterion = args.custom_criterion if has_custom_criterion else ch.nn.CrossEntropyLoss()\n",
    "\n",
    "    iterator = tqdm(enumerate(loader), total=len(loader))\n",
    "    for i, batch in iterator:\n",
    "        inp, target, output = None, None, None\n",
    "        loss = 0.0\n",
    "\n",
    "        inp, target = batch\n",
    "        inp, target = inp.to(device), target.to(device)\n",
    "        output = model(inp)\n",
    "        # attacker model returns both output anf final input\n",
    "        if isinstance(output, tuple):\n",
    "            output, final_inp = output\n",
    "        # lambda parameter used for regression with unknown noise variance\n",
    "        try:\n",
    "            loss = criterion(output, target, model.lambda_)\n",
    "        except Exception as e:\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # regularizer option \n",
    "        reg_term = 0.0\n",
    "        if has_attr(args, \"regularizer\") and isinstance(model, ch.nn.Module):\n",
    "            reg_term = args.regularizer(model, inp, target)\n",
    "        loss = loss + reg_term\n",
    "        \n",
    "        # perform backprop and take optimizer step\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if len(loss.size()) > 0: loss = loss.mean()\n",
    "\n",
    "        model_logits = output[0] if isinstance(output, tuple) else output\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        top1_acc = float('nan')\n",
    "        top5_acc = float('nan')\n",
    "        try:\n",
    "            losses.update(loss.item(), inp.size(0))\n",
    "            # calculate score\n",
    "            if args.score:  # known variance\n",
    "                if args.bias:\n",
    "                    score.update(ch.cat([model.weight.grad.T, model.bias.grad.unsqueeze(0)]).flatten(), inp.size(0))\n",
    "                else:\n",
    "                    score.update(ch.cat([model.weight.grad.T]).flatten(), inp.size(0))\n",
    "\n",
    "            if model_logits is not None:\n",
    "                # accuracy\n",
    "                maxk = min(5, model_logits.shape[-1])\n",
    "                if has_attr(args, \"custom_accuracy\"):\n",
    "                    prec1, prec5 = args.custom_accuracy(model_logits, target)\n",
    "                else:\n",
    "                    prec1, prec5 = accuracy(model_logits, target, topk=(1, maxk))\n",
    "                    prec1, prec5 = prec1[0], prec5[0]\n",
    "\n",
    "                top1.update(prec1, inp.size(0))\n",
    "                top5.update(prec5, inp.size(0))\n",
    "                top1_acc = top1.avg\n",
    "                top5_acc = top5.avg\n",
    "\n",
    "                # ITERATOR\n",
    "                desc = ('Epoch:{0} | Loss {loss.avg:.4f} | '\n",
    "                        '{1}1 {top1_acc:.3f} | {1}5 {top5_acc:.3f} | '\n",
    "                        'Reg term: {reg} ||'.format(epoch, loop_msg,\n",
    "                                                    loss=losses, top1_acc=top1_acc, top5_acc=top5_acc, reg=reg_term))\n",
    "            else:\n",
    "                # ITERATOR\n",
    "                if args.score:\n",
    "                    desc = ('Epoch:{0} | Score: {score} \\n | Loss {loss.avg:.4f} ||'.format(\n",
    "                        epoch, loop_msg, score=[round(x, 4) for x in score.avg.tolist()], loss=losses))\n",
    "                else:\n",
    "                    desc = ('Epoch:{0} | Loss {loss.avg:.4f} ||'.format(\n",
    "                        epoch, loop_msg, score=[round(x, 4) for x in score.avg.tolist()], loss=losses))\n",
    "\n",
    "        except Exception as e:\n",
    "            warnings.warn('Failed to calculate the accuracy.')\n",
    "            # ITERATOR\n",
    "            if args.score:\n",
    "                desc = ('Epoch:{0} |  Score: {score} \\n | Loss {loss.avg:.4f} ||'.format(\n",
    "                    epoch, loop_msg, score=[round(x, 4) for x in score.avg.tolist()], loss=losses))\n",
    "            else:\n",
    "                desc = ('Epoch:{0} | Loss {loss.avg:.4f} ||'.format(epoch, loop_msg, loss=losses))\n",
    "        \n",
    "        iterator.set_description(desc)\n",
    "    \n",
    "        # USER-DEFINED HOOK\n",
    "        if has_attr(args, 'iteration_hook'):\n",
    "            args.iteration_hook(model, i, loop_type, inp, target)\n",
    "\n",
    "    if writer is not None:\n",
    "        descs = ['loss', 'top1', 'top5']\n",
    "        vals = [losses, top1, top5]\n",
    "        for d, v in zip(descs, vals):\n",
    "            writer.add_scalar('_'.join([loop_type, d]), v.avg,\n",
    "                              epoch)\n",
    "\n",
    "    # LOSS AND ACCURACY\n",
    "    return top1.avg, losses.avg, score.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membership oracles\n",
    "class oracle(ABC):\n",
    "    \"\"\"\n",
    "    Oracle for data sets.\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Membership oracle.\n",
    "        Args: \n",
    "            x: samples to check membership\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class DNN_Lower(oracle): \n",
    "    \"\"\"\n",
    "    Lower bound truncation on the DNN logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, lower): \n",
    "        self.lower = lower\n",
    "        \n",
    "    def __call__(self, x): \n",
    "        return (x > self.lower).float()\n",
    "    \n",
    "class DNN_Logit_Ball(oracle): \n",
    "    \"\"\"\n",
    "    Truncation ball placed on DNN logits.\n",
    "    INTUITION: logits that are neither very large nor very small insinuate\n",
    "    that the classification is not \n",
    "    \"\"\"\n",
    "    def __init__(self, lower, upper): \n",
    "        self.lower = lower \n",
    "        self.upper = upper\n",
    "        \n",
    "    def __call__(self, x): \n",
    "        return ((x < self.lower) | (x > self.upper)).float()\n",
    "        \n",
    "\n",
    "class Identity(oracle): \n",
    "    def __call__(self, x): \n",
    "        return ch.ones(x.size())\n",
    "    \n",
    "def gen_data(): \n",
    "    \"\"\"\n",
    "    Generate dataset for truncated multinomial logistic \n",
    "    regression model. Returns ground_truth and train, validation, and test loaders.\n",
    "    \"\"\"\n",
    "    # distributions\n",
    "    gumbel = Gumbel(0, 1)\n",
    "    U = Uniform(args.lower, args.upper) # distribution to generate ground-truth parameters\n",
    "    U_ = Uniform(-5, 5) # distribution to generate samples\n",
    "    \n",
    "    # no grad required for dataset\n",
    "    with ch.no_grad():\n",
    "        # generate synthetic data until survival probability of more than 40%\n",
    "        alpha = None\n",
    "        while alpha is None or alpha < args.ALPHA_THRESH:\n",
    "            # generate ground-truth from uniform distribution\n",
    "            ground_truth = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "            ground_truth.weight = nn.Parameter(U.sample(ch.Size([args.K, args.IN_FEATURES])))\n",
    "            if ground_truth.bias is not None: \n",
    "                ground_truth.bias = nn.Parameter(U.sample(ch.Size([args.K,])))\n",
    "            # independent variable \n",
    "            X = U_.sample(ch.Size([args.samples, args.IN_FEATURES]))\n",
    "            # determine base model logits \n",
    "            z = ground_truth(X)\n",
    "            # add noise to the logits\n",
    "            noised = z + gumbel.sample(z.size())\n",
    "            # apply softmax to unnormalized likelihoods\n",
    "            y = ch.argmax(noised, dim=1)\n",
    "\n",
    "            # TRUNCATE\n",
    "            trunc = args.phi(z)\n",
    "            indices = ch.all(trunc.bool(), dim=1).float().nonzero(as_tuple=False).flatten()\n",
    "            x_trunc, y_trunc = X[indices], y[indices]\n",
    "            alpha = x_trunc.size(0) / X.size(0)\n",
    "\n",
    "            # all synthetic data \n",
    "            ds = TensorDataset(x_trunc, y_trunc)\n",
    "            # split ds into training and validation data sets - 80% training, 20% validation\n",
    "            train_length = int(len(ds)*.8)\n",
    "            val_length = len(ds) - train_length\n",
    "            train_ds, val_ds = ch.utils.data.random_split(ds, [train_length, val_length])\n",
    "            # train and validation loaders\n",
    "            train_loader = DataLoader(train_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "            val_loader = DataLoader(val_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "\n",
    "            # test dataset\n",
    "            x_test = X[~indices]\n",
    "            y_test = y[~indices]\n",
    "            test_ds = TensorDataset(x_test, y_test)\n",
    "            test_loader = DataLoader(test_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "            \n",
    "    return ground_truth, (train_loader, val_loader), test_loader\n",
    "\n",
    "def plot():\n",
    "    # TRUNCATED CE LOSS DATA\n",
    "    trunc_reader = CollectionReader(TRUNCATED_STORE_PATH)\n",
    "    trunc_logs = trunc_reader.df(LOGS_TABLE)\n",
    "    trunc_reader.close() # close reader\n",
    "\n",
    "    # STANDARD CE LOSS DATA\n",
    "    standard_reader = CollectionReader(STANDARD_STORE_PATH)\n",
    "    standard_logs = standard_reader.df(LOGS_TABLE)\n",
    "    standard_reader.close() # close reader\n",
    "\n",
    "    # TEST SET RESULTS \n",
    "    trunc_test_reader = CollectionReader(TRUNCATED_EVAL_STORE_PATH)\n",
    "    trunc_test_results = trunc_test_reader.df(EVAL_LOGS_TABLE)\n",
    "    trunc_test_reader.close() # close reader\n",
    "\n",
    "\n",
    "\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='train_loss', label='Train Loss')\n",
    "    sns.lineplot(data=standard_logs, x='epoch', y='train_loss', label='Naive Train Loss')\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='val_loss', color='red', label='Trunc Val Loss')\n",
    "    ax = sns.lineplot(data=standard_logs, x='epoch', y='val_loss', color='red', label='Naive Val Loss')\n",
    "    ax.set(xlabel='epoch', ylabel='CE Loss')\n",
    "    plt.show()\n",
    "\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='train_prec1', label='Trunc Train Acc')\n",
    "    sns.lineplot(data=standard_logs, x='epoch', y='train_prec1', label='Naive Train Acc')\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='val_prec1', label='Trunc Val Acc')\n",
    "    ax = sns.lineplot(data=standard_logs, x='epoch', y='val_prec1', label='Naive Val Acc')\n",
    "    ax.set(xlabel='epoch', ylabel='Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    # TEST SET RESULTS \n",
    "    try: \n",
    "        standard_test_reader = CollectionReader(STANDARD_EVAL_STORE_PATH)\n",
    "        standard_test_results = standard_test_reader.df(EVAL_LOGS_TABLE)\n",
    "        standard_test_reader.close() # close reader\n",
    "\n",
    "        print(\"Standard Test Accuracy: {}\".format(standard_test_results['test_prec1']))\n",
    "        print(\"Truncated Test Accuracy: {}\".format(trunc_test_results['test_prec1']))\n",
    "    except: \n",
    "        print(\"No Test Results to Report\")\n",
    "        \n",
    "        \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def has_attr(obj, k):\n",
    "    \"\"\"Checks both that obj.k exists and is not equal to None\"\"\"\n",
    "    try:\n",
    "        return (getattr(obj, k) is not None)\n",
    "    except KeyError as e:\n",
    "        return False\n",
    "    except AttributeError as e:\n",
    "        return False\n",
    "    \n",
    "def accuracy(output, target, topk=(1,), exact=False):\n",
    "    \"\"\"\n",
    "        Computes the top-k accuracy for the specified values of k\n",
    "\n",
    "        Args:\n",
    "            output (ch.Tensor) : model output (N, classes) or (N, attributes) \n",
    "                for sigmoid/multitask binary classification\n",
    "            target (ch.Tensor) : correct labels (N,) [multiclass] or (N,\n",
    "                attributes) [multitask binary]\n",
    "            topk (tuple) : for each item \"k\" in this tuple, this method\n",
    "                will return the top-k accuracy\n",
    "            exact (bool) : whether to return aggregate statistics (if\n",
    "                False) or per-example correctness (if True)\n",
    "\n",
    "        Returns:\n",
    "            A list of top-k accuracies.\n",
    "    \"\"\"\n",
    "    with ch.no_grad():\n",
    "        # Binary Classification\n",
    "        if len(target.shape) > 1:\n",
    "            assert output.shape == target.shape, \\\n",
    "                \"Detected binary classification but output shape != target shape\"\n",
    "            return [ch.round(ch.sigmoid(output)).eq(ch.round(target)).float().mean()], [-1.0] \n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        res_exact = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float()\n",
    "            ck_sum = correct_k.sum(0, keepdim=True)\n",
    "            res.append(ck_sum.mul_(100.0 / batch_size))\n",
    "            res_exact.append(correct_k)\n",
    "\n",
    "        if not exact:\n",
    "            return res\n",
    "        else:\n",
    "            return res_exact\n",
    "        \n",
    "def ckpt_at_epoch(num):\n",
    "    return '%s_%s' % (num, CKPT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE Latent Variable Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedBCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        loss = ch.nn.BCEWithLogitsLoss()\n",
    "        return loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "\n",
    "        # logistic distribution\n",
    "        base_distribution = Uniform(0, 1)\n",
    "        transforms_ = [SigmoidTransform().inv]\n",
    "        logistic = TransformedDistribution(base_distribution, transforms_)\n",
    "\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)\n",
    "        # add noise\n",
    "        noised = stacked + logistic.sample(stacked.size())\n",
    "        # filter\n",
    "        filtered = ch.stack([args.phi(batch) for batch in noised]).float()\n",
    "        out = (noised * filtered).sum(dim=0) / (filtered.sum(dim=0) + 1e-5)\n",
    "        grad = ch.where(ch.abs(out) > 1e-5, sig(out), targ) - targ\n",
    "        return grad / pred.size(0), -grad / pred.size(0)\n",
    "\n",
    "class GumbelCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        ce_loss = ch.nn.CrossEntropyLoss()\n",
    "        return ce_loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "        # gumbel distribution\n",
    "        gumbel = Gumbel(0, 1)\n",
    "        # make num_samples copies of pred logits\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)        \n",
    "        # add gumbel noise to logits\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        noised = stacked + rand_noise \n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # remove the logits from the trials, where the kth logit is not the largest value\n",
    "        good_mask = noised_labs.eq(targ)[..., None]\n",
    "        inner_exp = 1 - ch.exp(-rand_noise)\n",
    "        avg = (inner_exp * good_mask).sum(0) / (good_mask.sum(0) + 1e-5) / pred.size(0)\n",
    "        return -avg , None\n",
    "    \n",
    "class TruncatedGumbelCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        ce_loss = ch.nn.CrossEntropyLoss()\n",
    "        return ce_loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "        # initialize gumbel distribution\n",
    "        gumbel = Gumbel(0, 1)\n",
    "        # make num_samples copies of pred logits\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)   \n",
    "        # add gumbel noise to logits\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        noised = stacked + rand_noise \n",
    "        # truncate - if one of the noisy logits does not fall within the truncation set, remove it\n",
    "        filtered = ch.all(args.phi(noised).bool(), dim=2).float().unsqueeze(2)\n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # mask takes care of invalid logits and truncation set\n",
    "        mask = noised_labs.eq(targ)[..., None] * filtered\n",
    "        inner_exp = 1 - ch.exp(-rand_noise)\n",
    "\n",
    "        avg = (((inner_exp * mask).sum(0) / (mask.sum(0) + 1e-5)) - ((inner_exp * filtered).sum(0) / (filtered.sum(0) + 1e-5))) \n",
    "        return -avg / pred.size(0), None, None\n",
    "\n",
    "# gradients\n",
    "trunc_bce = TruncatedBCE.apply\n",
    "gumbel_ce = GumbelCE.apply\n",
    "trunc_ce = TruncatedGumbelCE.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"epochs\": 25,\n",
       "  \"num_workers\": 0,\n",
       "  \"batch_size\": 100,\n",
       "  \"bias\": true,\n",
       "  \"num_samples\": 1000,\n",
       "  \"clamp\": true,\n",
       "  \"radius\": 5.0,\n",
       "  \"lr\": 0.1,\n",
       "  \"shuffle\": true,\n",
       "  \"samples\": 10000,\n",
       "  \"in_features\": 2,\n",
       "  \"k\": 2,\n",
       "  \"lower\": -1,\n",
       "  \"upper\": 1,\n",
       "  \"trials\": 1,\n",
       "  \"log_iters\": 1,\n",
       "  \"should_save_ckpt\": true,\n",
       "  \"save_ckpt_iters\": -1,\n",
       "  \"validation_split\": 0.8,\n",
       "  \"momentum\": 0.0,\n",
       "  \"weight_decay\": 0.0,\n",
       "  \"custom_lr_multiplier\": \"cosine\",\n",
       "  \"device\": \"cpu\",\n",
       "  \"alpha_thresh\": 0.2\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# procedure hyperparameters\n",
    "args = Parameters({ \n",
    "    'epochs': 25,\n",
    "    'num_workers': 0, \n",
    "    'batch_size': 100,\n",
    "    'bias': True,\n",
    "    'num_samples': 1000,\n",
    "    'clamp': True, \n",
    "    'radius': 5.0, \n",
    "    'lr': 1e-1,\n",
    "    'shuffle': False, \n",
    "    'samples': 10000,  # number of samples to generate for ground truth\n",
    "    'in_features': 2, # number of in-features to multi-log-reg\n",
    "    'k': 2, # number of classes\n",
    "    'lower': -1, # lower bound for generating ground truth weights\n",
    "    'upper': 1,  # upper bound for generating ground truth weights\n",
    "    'trials': 1,\n",
    "    'log_iters': 1,    \n",
    "    'should_save_ckpt': True,\n",
    "    'save_ckpt_iters': -1,\n",
    "    'validation_split': .8,\n",
    "    'momentum': 0.0,\n",
    "    'weight_decay': 0.0,\n",
    "    'custom_lr_multiplier': COSINE, \n",
    "    'shuffle': True,\n",
    "    'device': 'cpu',\n",
    "    'alpha_thresh': .2,\n",
    "})\n",
    "\n",
    "if ch.cuda.is_available(): \n",
    "    args.__setattr__('device', 'cuda')\n",
    "else: \n",
    "    args.__setattr__('device', 'cpu')\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Multinomial Logistic Regression Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi = DNN_Lower(ch.full(ch.Size([args.K,]), -2, dtype=ch.float32))\n",
    "# phi = DNN_Lower(Tensor([-2, -3, -2, -3, -4, -5, -6, -7, -6, -5]))\n",
    "phi = Identity()\n",
    "# phi = DNN_Logit_Ball(ch.full(ch.Size([args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([args.K,]), 2, dtype=ch.float32))\n",
    "args.__setattr__('phi', phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /Users/patroklos/MultinomialLogisticRegressionTruncated/cf48d55f-3442-4535-a2f4-beb64e49ced4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506e9132be114ca5967ed71a1d2e9b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7186e23cc31b418ca10358433c0fcb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088b56f4ba214e43b2f09a9d38d7fab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82720ece44345c28d40bc3044c1ce93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d0ff72a34542b9ba5d0a7f1218e19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacfeab33aa34c02b07f5019378e6edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ceaa9a2f2a849b3b63bf415380db709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294f43663dae41138acddd9fb0aef70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14638e9ce50948baa6d3e46c0cc4dc16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6814fd34f8428cbf97f4c31eae2c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae12168fe59a44218629a550b35e4815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d50c05685e41ce8e87be0c533ebda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b417851c9d94016abb5ff068fd676e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227e703dc08b413aa116c2be6e83f818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f293a196a73e44fd833bae2d223326f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea324400270446c19cd69815d2aaa186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43180ed602041ad89e5272faab716f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9324301ef4ef451e92892814350e573f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adafc1a89034ebca45a1ef63db16918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f222ea0fc5bb423aa07b0d81815e528c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d1b2e476b4483d85c7a78825242c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdaa218622974c51b690114e989e6211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c5b3e1c02c48789ad976d3b87de1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca31009db9548b0afa060dcc6b59d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770d6255cf3c464bbf192077c2120c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d0e6afdc364355a003423a234f18fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1805c864a9dd4483ba71e025cc1566c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d697f9735b4a749824f360818b8f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f0709526f6409eac1b2d5fa8bfa9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a7210dbc0f4079b010ee94c33549ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813484a43ba3495b83b5bf7d3503be59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bbad58ec4f44b99214f9f2c950323c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a31fabed2d4879adf77a6fe2f11d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745ea4a14fb34272a7cb95abdd9a5f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e6cdd480754c2dbbba603decf8891c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecebedcface745389faa9b3b6b3e1457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef25cf133db41c5a4667e62ea9b6d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070a2850f25c4bc0a51809159e5d3905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ae9a2dd0394d70975e73a8e43045a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df81691f2b14664bdb6f824a1daeb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2f3ac5c3fe4ccdaecd7cf59b74c5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9801ae3ab7c4f03a032e19ffbbd12fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dab23bf5f2049e4bc46be18458164a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0cb1e1327d4fa48edd311ea77fbd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51625783fb4c41d4bd1b9622d0ff3b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b83a599bb04523bda8658c61cb9fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d1baa753aa494b836f20589b8c5748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fcb6918e494cad862f4a45a4d39c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf7b6d31ee1443181133fd9fdd19700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157eb4f31a384ad1a36892f019df5126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss: 0.31987392865121367\n",
      "avg top 1: 86.0875015258789\n",
      "Logging in: /Users/patroklos/MultinomialLogisticRegressionStandard/176ccc18-1e4c-47b4-90be-ec83b9404625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04356ca5243457e9ebd7d7a536038e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab055872c864b89b39aacb0ea33db70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f84dadedc44d7292262bbf6c7b814f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b4d4ef0c2448809bef579a2f3fa78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd9148d3f1d4b85a938cc2d4db7ce58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d903be227ae4715be8d78a00e910e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bc79f9fa814add92343fee4ea625df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444cbdd931544700bf815078f563c79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21539b223074de89b9b33c1ae7a24c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c56de8b4d9849e4bd3f9e3c78207978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76dc8b5f5c19497486e888a9948c6d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0276da425d43fa8deb1739081a50f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf47384f9dd04c8eaf1d8b93fe297ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c516e05da55746be8b496c5bffaf0f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637b27a4f55f48c3a18f9e63777a8575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca4a4732ed14457a69df6216e45fb9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f12184ec36f4ad9b95931cad4f01506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32329c67af5347ea9f53e5a387adf671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bdc80a418145f99d1e56b92911b96a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df5fa1d396b4df2980c8a0424ae7661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bc96d2c6c14db08e5d85615425defa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a62cf5a5ff47388d589d3a99191254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fc6e8ba38e4437b07e0b2deac28489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97758c3deef431f98ad41fa52109143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226fdcd8db1045ab8160e42e557f1e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad706cb7b0c410f8dadf4ed586b39eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b960eea8821d4bedb17fd08640241b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c28e7a7f1b6474c91e60b2f98def679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb09c1f14bd4978a45f8b3060523665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7095d5b3c414a87a69cdff92b9da2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b0a907056f4412bf29ad9aec7d5b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800b2542bd8f480e94609915ae02bdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0771a8c570f84e0f887d0cb8adea45e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26569c6afb241d19ccf65abe285e33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc07e4b0dc844689a122d0d28f75d609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52652f136634c47bd5bdf2069cf730e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677891fcb7814812af5f2f481d16d6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f92fbc066a4155a254c29bba29c9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcf455b2a77412db02e702aa9eef3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a4b75d09464241b5bdb309d8f28c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bf9d6145d64bbcab8510a61bedd11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cb0b3b59904764972d428f7e360586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06abd6aa70864585a5e60e609823354b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cbb4f1e8884e698ae6d8a5e797767a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5607d44376b24e2eb2e678d3c9fa8b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2840f730bcd4bc8aa60b961522a8119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b38fcd87964fe4a106e753fda0441d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad15c11395b4ebe8e08301e307b909d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4db507fd16498491deccc737e6a755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04f9ec8b630494f84bd360ef0850d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss: 0.3198739230632782\n",
      "avg top 1: 86.07499694824219\n",
      "Logging in: /Users/patroklos/MultinomialLogisticRegressionTruncatedTest/b6c7971a-1869-4637-8d34-aecf22f76853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17d8f729ef946739e85c1d0d6ad2f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /Users/patroklos/MultinomialLogisticRegressionGumbelCE/6a3c9a27-08f9-428b-95db-073bffe38bf4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b9b398406a490b81ed7d3afae95748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fd09d3f3b64ebe8efbd356c920f06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e412ca034364834993664d06b2e3fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeea5d6de3f14b51a9fe0f4a81efdcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09dac28642fb4e72ab32dcea9f047af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c90c36891c47adb4868fcc7694de96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bf739434d54e61984be8c000832b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42336e1c70934cc5b558516dfbe0e7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74568fb0047840d9b96c1b36e700091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dabac154d3640e1a5dc15c960c097fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79294f3666f44feb8d04d261b370815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3a74e620d9445e8d047718d2802fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd28897277d744ab930fa43568778ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810fdf29b8414cd482edcefe1739f77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c95bdadf5ff488aa5a7e48826b80b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1acb1df8de4d9d9630ad3263ceddcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecf332eb97c44b48152674a220e691c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5181663fd944fe9c7ef16d9f047cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee702cc5a78749ef9e9b5431ba7f31e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b71a2f19ca4975b7d0795427221ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3d56f721d747f7a444614f9f583e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a89b1a21f0841a5a161efa7da699804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aea0a8bf334b00a182c9ad26747764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3a853db7714f0b9aef6c174355118a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aecae64536124fc3933b4e9eb92cf280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913968579ee849388e7f03891c7bd02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8af32e849f4c6dab34ffc3e1bd1214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989d1570b32f4ae9a5c5f082986dc343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b361462e777645fa93dac7b0abd54a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d0ed21fd79423ebbd25bbd713b3cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea34acf9d544701b1bb6a50d03e51f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4a06346adb4bacb7fd8f5f3d5517db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce97869dfb074aca9943bd0ce3bb04ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6dcd9755614be1af01ddbd7373d7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4deb5d956c44902ab7135be007ae297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f283f67130fe4afea1e7473e29aa60c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4c1189a49b4c01b4d5818d049695da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd5d590e8a14dd59c2f9ef122a5f714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1531c547fa7c48bc9adf64a0d7c4a3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96852ec361bf43d0a52bc22162b25a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe4a62a23f24d16928c56facefc807e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393ca37fa96849e09461d2e20ef39c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d973e845e0d4a57bdf914228ad4407e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a17f2d1a594b398f5826ba6f77b18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc206002716a4c7fbd7e86c63a04c0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43aec604edd443f8e45b51eb14743c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8ca9b8fbef4443abd33233fabc9c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3705272613a142e98b9272ea39cfd9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e3318586d24eaea5e93443d210d41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fab3b59ce6842f09d156c8dffa152be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg loss: 0.31987386364489795\n",
      "avg top 1: 86.0625\n",
      "Logging in: /Users/patroklos/MultinomialLogisticRegressionStandardTest/41920a56-e277-4bb2-9390-1c5b63a1b2a9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb343edf89e04c55a300e3ea9b78b597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perform number of trials experiments\n",
    "for i in range(args.trials):\n",
    "    # generate data for exp\n",
    "    ground_truth, loaders, test_loader = gen_data()\n",
    "\n",
    "    # new classifier models at the beginning of each trial\n",
    "    trunc_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "\n",
    "    # truncated store\n",
    "    out_store = Store(TRUNCATED_STORE_PATH)\n",
    "    args.__setattr__('custom_criterion', trunc_ce)  # truncated ce loss\n",
    "    train_model(args, trunc_multi_log_reg, loaders, store=out_store, device=args.device)\n",
    "\n",
    "    # new classifier models at the beginning of each trial\n",
    "    standard_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "\n",
    "    # naive ce loss\n",
    "    out_store = Store(STANDARD_STORE_PATH)\n",
    "    args.__setattr__('custom_criterion', None) # default ce loss\n",
    "    train_model(args, standard_multi_log_reg, loaders, store=out_store, device=args.device)\n",
    "\n",
    "    # truncated multinomial logistic regression eval\n",
    "    out_store = Store(TRUNCATED_EVAL_STORE_PATH)\n",
    "    eval_model(args, trunc_multi_log_reg, test_loader, out_store)\n",
    "    \n",
    "    # Gumbel CE store path \n",
    "    out_store = Store(GUMBEL_CE_STORE_PATH)\n",
    "    args.__setattr__('custom_criterion', gumbel_ce)\n",
    "    gumbel_ce_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "    train_model(args, gumbel_ce_multi_log_reg, loaders, store=out_store, device=args.device)\n",
    "\n",
    "    # standard multinomial logistic regression eval - if there is a test set\n",
    "    if len(test_loader.dataset):\n",
    "        out_store = Store(STANDARD_EVAL_STORE_PATH)\n",
    "        eval_model(args, standard_multi_log_reg, test_loader, out_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity and L2 Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cosine trunc weight: {}\".format(ch.nn.functional.cosine_similarity(trunc_multi_log_reg.weight, ground_truth.weight)))\n",
    "print(\"cosine trunc bias: {}\".format(ch.nn.functional.cosine_similarity(trunc_multi_log_reg.bias.unsqueeze(0), ground_truth.bias.unsqueeze(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cosine standard weight: {}\".format(ch.nn.functional.cosine_similarity(standard_multi_log_reg.weight, ground_truth.weight)))\n",
    "print(\"cosine standard bias: {}\".format(ch.nn.functional.cosine_similarity(standard_multi_log_reg.bias.unsqueeze(0), ground_truth.bias.unsqueeze(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cosine gumbel ce weight: {}\".format(ch.nn.functional.cosine_similarity(gumbel_ce_multi_log_reg.weight, ground_truth.weight)))\n",
    "print(\"cosine gumbel ce bias: {}\".format(ch.nn.functional.cosine_similarity(gumbel_ce_multi_log_reg.bias.unsqueeze(0), ground_truth.bias.unsqueeze(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2])\n",
      "Correlation between real and estimated gradient:  tensor(0.9973)\n",
      "Correlation between real and truncated gradient:  tensor(0.9980)\n",
      "Correlation between trunc bce and real ce gradient:  tensor(-9.4713e-09)\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.transforms import SigmoidTransform\n",
    "from torch.distributions.transformed_distribution import TransformedDistribution\n",
    "\n",
    "gumbel = Gumbel(0, 1)\n",
    "\n",
    "# logistic distribution\n",
    "base_distribution = Uniform(0, 1)\n",
    "transforms_ = [SigmoidTransform().inv]\n",
    "logistic = TransformedDistribution(base_distribution, transforms_)\n",
    "\n",
    "phi = Identity()\n",
    "\n",
    "\n",
    "m = ch.nn.Linear(10, 2)\n",
    "x = ch.rand(1000, 10)\n",
    "w = ch.randn(10, 2)\n",
    "y = (x @ w + gumbel.sample([1000, 2])).argmax(1)\n",
    "\n",
    "m_ = ch.nn.Linear(10, 1)\n",
    "x_ = ch.rand(1000, 10)\n",
    "w_ = ch.randn(10, 1)\n",
    "y_ = (x_ @ w_ + logistic.sample([1000, 1])).argmax(1).float()\n",
    "\n",
    "out = m(x)\n",
    "loss_ = GumbelCE.apply(out, y)\n",
    "g, = ch.autograd.grad(loss_, [out])\n",
    "\n",
    "gt_loss = nn.CrossEntropyLoss()(out, y)\n",
    "gt_g, = ch.autograd.grad(gt_loss, [out])\n",
    "\n",
    "trunc_loss = trunc_ce(out, y)\n",
    "gt_trunc, = ch.autograd.grad(trunc_loss, [out])\n",
    "\n",
    "out_ = m_(x_)\n",
    "trunc_bce_loss = trunc_bce(out_, y_.unsqueeze(1))\n",
    "g_bce, = ch.autograd.grad(trunc_bce_loss, [out_])\n",
    "\n",
    "print('Correlation between real and estimated gradient: ',\n",
    "        (gt_g * g).sum() / (gt_g.norm() * g.norm()))\n",
    "\n",
    "print('Correlation between real and truncated gradient: ',\n",
    "        (gt_g * gt_trunc).sum() / (gt_g.norm() * gt_trunc.norm()))\n",
    "\n",
    "print('Correlation between trunc bce and real ce gradient: ', \n",
    "     (g_bce * gt_g).sum() / (g_bce.norm() * gt_g.norm()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0006],\n",
       "        [0.0005],\n",
       "        [0.0005],\n",
       "        [0.0004],\n",
       "        [0.0005],\n",
       "        [0.0005]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_bce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0004,  0.0004],\n",
       "        [-0.0005,  0.0005],\n",
       "        [-0.0004,  0.0004],\n",
       "        ...,\n",
       "        [-0.0004,  0.0004],\n",
       "        [-0.0004,  0.0004],\n",
       "        [-0.0005,  0.0005]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
