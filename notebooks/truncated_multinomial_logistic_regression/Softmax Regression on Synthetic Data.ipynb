{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../..')\n",
    "sys.path.append('/opt/anaconda3/lib/python3.7/site-packages')\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "from cox.readers import CollectionReader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "from torch import sigmoid as sig\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.distributions import Gumbel, Uniform\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.transforms import SigmoidTransform\n",
    "from torch.distributions.transformed_distribution import TransformedDistribution\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "from abc import ABC\n",
    "import IPython\n",
    "import os\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUNCATED_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionTruncated/'\n",
    "STANDARD_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionStandard/'\n",
    "\n",
    "TRUNCATED_EVAL_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionTruncatedTest/'\n",
    "STANDARD_EVAL_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionStandardTest/'\n",
    "\n",
    "GUMBEL_CE_STORE_PATH = '/Users/patroklos/MultinomialLogisticRegressionGumbelCE'\n",
    "\n",
    "LOGS_SCHEMA = {\n",
    "    'epoch':int,\n",
    "    'val_prec1':float,\n",
    "    'val_loss':float,\n",
    "    'train_prec1':float,\n",
    "    'train_loss':float,\n",
    "    'time':float\n",
    "}\n",
    "\n",
    "EVAL_LOGS_SCHEMA = {\n",
    "    'test_prec1':float,\n",
    "    'test_loss':float,\n",
    "    'time':float\n",
    "}\n",
    "\n",
    "GROUND_TRUTH_SCHEMA = { \n",
    "    'cos_sim': float, \n",
    "    'l2': float,\n",
    "    'epoch': int,\n",
    "}\n",
    "\n",
    "# scheduler constants\n",
    "CYCLIC='cyclic'\n",
    "COSINE='cosine'\n",
    "LINEAR='linear'\n",
    "\n",
    "LOGS_TABLE = 'logs'\n",
    "EVAL_LOGS_TABLE = 'eval'\n",
    "GROUND_TRUTH_TABLE ='ground_truth'\n",
    "\n",
    "CKPT_NAME = 'checkpoint.pt'\n",
    "BEST_APPEND = '.best'\n",
    "CKPT_NAME_LATEST = CKPT_NAME + '.latest'\n",
    "CKPT_NAME_BEST = CKPT_NAME + BEST_APPEND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Procedure Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer_and_schedule(args, model, params):\n",
    "    param_list = model.parameters() if params is None else params\n",
    "\n",
    "    optimizer = SGD(param_list, args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "    # Make schedule\n",
    "    schedule = None\n",
    "    if args.custom_lr_multiplier == CYCLIC:\n",
    "        eps = args.epochs\n",
    "        lr_func = lambda t: np.interp([t], [0, eps*4//15, eps], [0, 1, 0])[0]\n",
    "        schedule = lr_scheduler.LambdaLR(optimizer, lr_func)\n",
    "    elif args.custom_lr_multiplier == COSINE:\n",
    "        eps = args.epochs\n",
    "        schedule = lr_scheduler.CosineAnnealingLR(optimizer, eps)\n",
    "    elif args.custom_lr_multiplier:\n",
    "        cs = args.custom_lr_multiplier\n",
    "        periods = eval(cs) if type(cs) is str else cs\n",
    "        if args.lr_interpolation == LINEAR:\n",
    "            lr_func = lambda t: np.interp([t], *zip(*periods))[0]\n",
    "        else:\n",
    "            def lr_func(ep):\n",
    "                for (milestone, lr) in reversed(periods):\n",
    "                    if ep >= milestone: return lr\n",
    "                return 1.0\n",
    "        schedule = lr_scheduler.LambdaLR(optimizer, lr_func)\n",
    "    elif args.step_lr:\n",
    "        schedule = lr_scheduler.StepLR(optimizer, step_size=args.step_lr, gamma=args.step_lr_gamma)\n",
    "        \n",
    "    return optimizer, schedule\n",
    "\n",
    "\n",
    "def eval_model(args, model, loader, store):\n",
    "    \"\"\"\n",
    "    Evaluate a model for standard (and optionally adversarial) accuracy.\n",
    "    Args:\n",
    "        args (object) : A list of arguments---should be a python object\n",
    "            implementing ``getattr()`` and ``setattr()``.\n",
    "        model (AttackerModel) : model to evaluate\n",
    "        loader (iterable) : a dataloader serving `(input, label)` batches from\n",
    "            the validation set\n",
    "        store (cox.Store) : store for saving results in (via tensorboardX)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if store is not None:\n",
    "        store.add_table(EVAL_LOGS_TABLE, EVAL_LOGS_SCHEMA)\n",
    "    writer = store.tensorboard if store else None\n",
    "\n",
    "    # put model on device\n",
    "    model.to(args.device)\n",
    "\n",
    "    assert not hasattr(model, \"module\"), \"model is already in DataParallel.\"\n",
    "    if next(model.parameters()).is_cuda and False:\n",
    "        model = ch.nn.DataParallel(model)\n",
    "\n",
    "    test_prec1, test_loss, score = model_loop(args, 'val', loader,\n",
    "                                        model, None, 0, writer, args.device)\n",
    "\n",
    "    log_info = {\n",
    "        'test_prec1': test_prec1,\n",
    "        'test_loss': test_loss,\n",
    "        'time': time.time() - start_time\n",
    "    }\n",
    "\n",
    "    # Log info into the logs table\n",
    "    if store:\n",
    "        store[EVAL_LOGS_TABLE].append_row(log_info)\n",
    "        store.close()\n",
    "\n",
    "    return log_info\n",
    "\n",
    "\n",
    "def train_model(args, model, loaders, *, ground_truth=None, device=\"cpu\", dp_device_ids=None,\n",
    "                store=None, update_params=None, disable_no_grad=False):\n",
    "    # clear jupyter/ipython output before each training run\n",
    "    if store is not None:\n",
    "        store.add_table(LOGS_TABLE, LOGS_SCHEMA)\n",
    "        # ground-truth comparison table\n",
    "        if ground_truth is not None: \n",
    "            store.add_table(GROUND_TRUTH_TABLE, GROUND_TRUTH_SCHEMA)\n",
    "    writer = store.tensorboard if store else None\n",
    "\n",
    "    # data loaders\n",
    "    train_loader, val_loader = loaders\n",
    "    optimizer, schedule = make_optimizer_and_schedule(args, model, update_params)\n",
    "\n",
    "    # put the model into parallel mode\n",
    "    assert not has_attr(model, \"module\"), \"model is already in DataParallel.\"\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    best_prec1, start_epoch = (0, 0)\n",
    "\n",
    "    # keep track of the start time\n",
    "    start_time = time.time()\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        train_prec1, train_loss, score = model_loop(args, 'train', train_loader, model, optimizer, epoch+1, writer, device=device)\n",
    "\n",
    "        # check score tolerance\n",
    "        if args.score and ch.all(ch.where(ch.abs(score) < args.tol, ch.ones(1), ch.zeros(1)).bool()):\n",
    "            break\n",
    "\n",
    "        last_epoch = (epoch == (args.epochs - 1))\n",
    "\n",
    "        # if neural network passed through framework, use log performance\n",
    "        if args.should_save_ckpt:\n",
    "            save_its = args.save_ckpt_iters\n",
    "            should_save_ckpt = (epoch % save_its == 0) and (save_its > 0)\n",
    "            should_log = (epoch % args.log_iters == 0)\n",
    "\n",
    "            if should_log or last_epoch or should_save_ckpt:\n",
    "                # log + get best\n",
    "                ctx = ch.enable_grad() if disable_no_grad else ch.no_grad()\n",
    "                with ctx:\n",
    "                    val_prec1, val_loss, score = model_loop(args, 'val', val_loader, model,\n",
    "                            None, epoch + 1, writer, device=device)\n",
    "\n",
    "                # remember best prec@1 and save checkpoint\n",
    "                is_best = val_prec1 > best_prec1\n",
    "                best_prec1 = max(val_prec1, best_prec1)\n",
    "\n",
    "                # TODO: add custom logging hook\n",
    "\n",
    "                # log every checkpoint\n",
    "                log_info = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'val_prec1': val_prec1,\n",
    "                    'val_loss': val_loss,\n",
    "                    'train_prec1': train_prec1,\n",
    "                    'train_loss': train_loss,\n",
    "                    'time': time.time() - start_time\n",
    "                }\n",
    "\n",
    "                # Log info into the logs table\n",
    "                if store: store[LOGS_TABLE].append_row(log_info)\n",
    "        \n",
    "        # update lr\n",
    "        if schedule: schedule.step()\n",
    "\n",
    "        tqdm._instances.clear()\n",
    "        \n",
    "        if ground_truth is not None and is_train: \n",
    "            # ground_truth and current model parameters\n",
    "            gt_params = ch.cat([ground_truth.weight.flatten(), ground_truth.bias]).unsqueeze(1)\n",
    "            trunc_params = ch.cat([model.weight.flatten(), model.bias]).unsqueeze(1)\n",
    "            # cosine similarity and l2 distance\n",
    "            cos_sim = float(ch.nn.functional.cosine_similarity(gt_params, trunc_params, dim=0))\n",
    "            l2_dist = float(ch.nn.MSELoss()(gt_params, trunc_params))\n",
    "            \n",
    "            ground_truth_info = { \n",
    "                'epoch': epoch + 1, \n",
    "                'cos_sim': cos_sim, \n",
    "                'l2': l2_dist,\n",
    "            }\n",
    "            \n",
    "            store[GROUND_TRUTH_TABLE].append_row(ground_truth_info)\n",
    "            \n",
    "\n",
    "    # TODO: add end training hook\n",
    "\n",
    "    # close store at end of training\n",
    "    if store is not None:\n",
    "        store.close()\n",
    "    return model\n",
    "            \n",
    "            \n",
    "def model_loop(args, loop_type, loader, model, optimizer, epoch, writer, device):\n",
    "    # check loop type \n",
    "    if not loop_type in ['train', 'val']: \n",
    "        err_msg = \"loop type must be in {0} must be 'train' or 'val\".format(loop_type)\n",
    "        raise ValueError(err_msg)\n",
    "    is_train = (loop_type == 'train')\n",
    "    \n",
    "    loop_msg = 'Train' if is_train else 'Val'\n",
    "\n",
    "    # algorithm metrics\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    score = AverageMeter()\n",
    "    \n",
    "    # check for custom criterion\n",
    "    has_custom_criterion = has_attr(args, 'custom_criterion')\n",
    "    criterion = args.custom_criterion if has_custom_criterion else ch.nn.CrossEntropyLoss()\n",
    "\n",
    "    iterator = tqdm(enumerate(loader), total=len(loader), leave=False)\n",
    "    for i, batch in iterator:\n",
    "        inp, target, output = None, None, None\n",
    "        loss = 0.0\n",
    "\n",
    "        inp, target = batch\n",
    "        inp, target = inp.to(device), target.to(device)\n",
    "        output = model(inp)\n",
    "        # attacker model returns both output anf final input\n",
    "        if isinstance(output, tuple):\n",
    "            output, final_inp = output\n",
    "        # lambda parameter used for regression with unknown noise variance\n",
    "        try:\n",
    "            loss = criterion(output, target, model.lambda_)\n",
    "        except Exception as e:\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # regularizer option \n",
    "        reg_term = 0.0\n",
    "        if has_attr(args, \"regularizer\") and isinstance(model, ch.nn.Module):\n",
    "            reg_term = args.regularizer(model, inp, target)\n",
    "        loss = loss + reg_term\n",
    "        \n",
    "        # perform backprop and take optimizer step\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if len(loss.size()) > 0: loss = loss.mean()\n",
    "\n",
    "        model_logits = output[0] if isinstance(output, tuple) else output\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        top1_acc = float('nan')\n",
    "        top5_acc = float('nan')\n",
    "        try:\n",
    "            losses.update(loss.item(), inp.size(0))\n",
    "            # calculate score\n",
    "            if args.bias:\n",
    "                score.update(ch.cat([model.weight.grad.T, model.bias.grad.unsqueeze(0)]).flatten(), inp.size(0))\n",
    "            else:\n",
    "                score.update(ch.cat([model.weight.grad.T]).flatten(), inp.size(0))\n",
    "\n",
    "            if model_logits is not None:\n",
    "                # accuracy\n",
    "                maxk = min(5, model_logits.shape[-1])\n",
    "                if has_attr(args, \"custom_accuracy\"):\n",
    "                    prec1, prec5 = args.custom_accuracy(model_logits, target)\n",
    "                else:\n",
    "                    prec1, prec5 = accuracy(model_logits, target, topk=(1, maxk))\n",
    "                    prec1, prec5 = prec1[0], prec5[0]\n",
    "\n",
    "                top1.update(prec1, inp.size(0))\n",
    "                top5.update(prec5, inp.size(0))\n",
    "                top1_acc = top1.avg\n",
    "                top5_acc = top5.avg\n",
    "\n",
    "                # ITERATOR\n",
    "                desc = ('Epoch:{0} | Score: {score} \\n | Loss {loss.avg:.4f} | '\n",
    "                        '{1}1 {top1_acc:.3f} | {1}5 {top5_acc:.3f} | '\n",
    "                        'Reg term: {reg} ||'.format(epoch, loop_msg, score=[round(x, 4) for x in score.avg.tolist()],\n",
    "                                                    loss=losses, top1_acc=top1_acc, top5_acc=top5_acc, reg=reg_term))\n",
    "        except Exception as e:\n",
    "            warnings.warn('Failed to calculate the accuracy.')\n",
    "            # ITERATOR\n",
    "            desc = ('Epoch:{0} |  Score: {score} \\n | Loss {loss.avg:.4f} ||'.format(\n",
    "                epoch, loop_msg, score=[round(x, 4) for x in score.avg.tolist()], loss=losses))\n",
    "        \n",
    "        iterator.set_description(desc)\n",
    "    \n",
    "        # USER-DEFINED HOOK\n",
    "        if has_attr(args, 'iteration_hook'):\n",
    "            args.iteration_hook(model, i, loop_type, inp, target)\n",
    "\n",
    "    if writer is not None:\n",
    "        descs = ['loss', 'top1', 'top5']\n",
    "        vals = [losses, top1, top5]\n",
    "        for d, v in zip(descs, vals):\n",
    "            writer.add_scalar('_'.join([loop_type, d]), v.avg,\n",
    "                              epoch)\n",
    "\n",
    "    # LOSS AND ACCURACY\n",
    "    return top1.avg, losses.avg, score.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membership oracles\n",
    "class oracle(ABC):\n",
    "    \"\"\"\n",
    "    Oracle for data sets.\n",
    "    \"\"\"\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Membership oracle.\n",
    "        Args: \n",
    "            x: samples to check membership\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class DNN_Lower(oracle): \n",
    "    \"\"\"\n",
    "    Lower bound truncation on the DNN logits.\n",
    "    \"\"\"\n",
    "    def __init__(self, lower): \n",
    "        self.lower = lower\n",
    "        \n",
    "    def __call__(self, x): \n",
    "        return (x > self.lower).float()\n",
    "    \n",
    "class DNN_Logit_Ball(oracle): \n",
    "    \"\"\"\n",
    "    Truncation ball placed on DNN logits.\n",
    "    INTUITION: logits that are neither very large nor very small insinuate\n",
    "    that the classification is not \n",
    "    \"\"\"\n",
    "    def __init__(self, lower, upper): \n",
    "        self.lower = lower \n",
    "        self.upper = upper\n",
    "        \n",
    "    def __call__(self, x): \n",
    "        return ((x < self.lower) | (x > self.upper)).float()\n",
    "        \n",
    "\n",
    "class Identity(oracle): \n",
    "    \"\"\"\n",
    "    Identity membership oracle for DNNs. All logits are accepted within the truncation set.\n",
    "    \"\"\"\n",
    "    def __call__(self, x): \n",
    "        return ch.ones(x.size())\n",
    "    \n",
    "def gen_data(): \n",
    "    \"\"\"\n",
    "    Generate dataset for truncated multinomial logistic \n",
    "    regression model. Returns ground_truth and train, validation, and test loaders.\n",
    "    \"\"\"\n",
    "    # distributions\n",
    "    gumbel = Gumbel(0, 1)\n",
    "    U = Uniform(args.lower, args.upper) # distribution to generate ground-truth parameters\n",
    "    U_ = Uniform(-5, 5) # distribution to generate samples\n",
    "    \n",
    "    # no grad required for dataset\n",
    "    with ch.no_grad():\n",
    "        # generate synthetic data until survival probability of more than 40%\n",
    "        alpha = None\n",
    "        while alpha is None or alpha < args.ALPHA_THRESH:\n",
    "            # generate ground-truth from uniform distribution\n",
    "            ground_truth = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "            ground_truth.weight = nn.Parameter(U.sample(ch.Size([args.K, args.IN_FEATURES])))\n",
    "            if ground_truth.bias is not None: \n",
    "                ground_truth.bias = nn.Parameter(U.sample(ch.Size([args.K,])))\n",
    "            # independent variable \n",
    "            X = U_.sample(ch.Size([args.samples, args.IN_FEATURES]))\n",
    "            # determine base model logits \n",
    "            z = ground_truth(X)\n",
    "            # add noise to the logits\n",
    "            noised = z + gumbel.sample(z.size())\n",
    "            # apply softmax to unnormalized likelihoods\n",
    "            y = ch.argmax(noised, dim=1)\n",
    "\n",
    "            # TRUNCATE\n",
    "            trunc = args.phi(z)\n",
    "            indices = ch.all(trunc.bool(), dim=1).float().nonzero(as_tuple=False).flatten()\n",
    "            x_trunc, y_trunc = X[indices], y[indices]\n",
    "            alpha = x_trunc.size(0) / X.size(0)\n",
    "\n",
    "            # all synthetic data \n",
    "            ds = TensorDataset(x_trunc, y_trunc)\n",
    "            # split ds into training and validation data sets - 80% training, 20% validation\n",
    "            train_length = int(len(ds)*.8)\n",
    "            val_length = len(ds) - train_length\n",
    "            train_ds, val_ds = ch.utils.data.random_split(ds, [train_length, val_length])\n",
    "            # train and validation loaders\n",
    "            train_loader = DataLoader(train_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "            val_loader = DataLoader(val_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "\n",
    "            # test dataset\n",
    "            x_test = X[~indices]\n",
    "            y_test = y[~indices]\n",
    "            test_ds = TensorDataset(x_test, y_test)\n",
    "            test_loader = DataLoader(test_ds, num_workers=args.num_workers, batch_size=args.batch_size)\n",
    "            \n",
    "    return ground_truth, (train_loader, val_loader), test_loader\n",
    "\n",
    "def plot():\n",
    "    # TRUNCATED CE LOSS DATA\n",
    "    trunc_reader = CollectionReader(TRUNCATED_STORE_PATH)\n",
    "    trunc_logs = trunc_reader.df(LOGS_TABLE)\n",
    "    trunc_comp = trunc_reader.df(GROUND_TRUTH_TABLE)\n",
    "    trunc_reader.close() # close reader\n",
    "\n",
    "    # STANDARD CE LOSS DATA\n",
    "    standard_reader = CollectionReader(STANDARD_STORE_PATH)\n",
    "    standard_logs = standard_reader.df(LOGS_TABLE)\n",
    "    standard_comp = standard_reader.df(GROUND_TRUTH_TABLE)\n",
    "    standard_reader.close() # close reader\n",
    "\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='train_loss', label='Train Loss')\n",
    "    sns.lineplot(data=standard_logs, x='epoch', y='train_loss', label='Naive Train Loss')\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='val_loss', color='red', label='Trunc Val Loss')\n",
    "    ax = sns.lineplot(data=standard_logs, x='epoch', y='val_loss', color='red', label='Naive Val Loss')\n",
    "    ax.set(xlabel='Epoch', ylabel='CE Loss')\n",
    "    plt.show()\n",
    "\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='train_prec1', label='Trunc Train Acc')\n",
    "    sns.lineplot(data=standard_logs, x='epoch', y='train_prec1', label='Naive Train Acc')\n",
    "    sns.lineplot(data=trunc_logs, x='epoch', y='val_prec1', label='Trunc Val Acc')\n",
    "    ax = sns.lineplot(data=standard_logs, x='epoch', y='val_prec1', label='Naive Val Acc')\n",
    "    ax.set(xlabel='Epoch', ylabel='Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    sns.lineplot(data=standard_comp, x='epoch', y='cos_sim', label='Naive Cosine Similarity')\n",
    "    ax = sns.lineplot(data=trunc_comp, x='epoch', y='cos_sim', label='Truncated Cosine Similarity')\n",
    "    ax.set(xlabel='Epoch', ylabel='Cosine Similarity')\n",
    "    plt.show()\n",
    "    \n",
    "    sns.lineplot(data=standard_comp, x='epoch', y='l2', label='Naive L2')\n",
    "    ax = sns.lineplot(data=trunc_comp, x='epoch', y='l2', label='Truncated L2')\n",
    "    ax.set(xlabel='Epoch', ylabel='L2 Distance')\n",
    "    plt.show()\n",
    "    \n",
    "    try: \n",
    "        # STANDARD TEST SET RESULTS \n",
    "        standard_test_reader = CollectionReader(STANDARD_EVAL_STORE_PATH)\n",
    "        standard_test_results = standard_test_reader.df(EVAL_LOGS_TABLE)\n",
    "        standard_test_reader.close() # close reader\n",
    "        \n",
    "        # TRUNCATED TEST SET RESULTS \n",
    "        trunc_test_reader = CollectionReader(TRUNCATED_EVAL_STORE_PATH)\n",
    "        trunc_test_results = trunc_test_reader.df(EVAL_LOGS_TABLE)\n",
    "        trunc_test_reader.close() # close reader\n",
    "\n",
    "        print(\"Standard Test Accuracy: {}\".format(standard_test_results['test_prec1']))\n",
    "        print(\"Truncated Test Accuracy: {}\".format(trunc_test_results['test_prec1']))\n",
    "    except: \n",
    "        print(\"No Test Results to Report\")\n",
    "        \n",
    "        \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def has_attr(obj, k):\n",
    "    \"\"\"Checks both that obj.k exists and is not equal to None\"\"\"\n",
    "    try:\n",
    "        return (getattr(obj, k) is not None)\n",
    "    except KeyError as e:\n",
    "        return False\n",
    "    except AttributeError as e:\n",
    "        return False\n",
    "    \n",
    "def accuracy(output, target, topk=(1,), exact=False):\n",
    "    \"\"\"\n",
    "        Computes the top-k accuracy for the specified values of k\n",
    "\n",
    "        Args:\n",
    "            output (ch.Tensor) : model output (N, classes) or (N, attributes) \n",
    "                for sigmoid/multitask binary classification\n",
    "            target (ch.Tensor) : correct labels (N,) [multiclass] or (N,\n",
    "                attributes) [multitask binary]\n",
    "            topk (tuple) : for each item \"k\" in this tuple, this method\n",
    "                will return the top-k accuracy\n",
    "            exact (bool) : whether to return aggregate statistics (if\n",
    "                False) or per-example correctness (if True)\n",
    "\n",
    "        Returns:\n",
    "            A list of top-k accuracies.\n",
    "    \"\"\"\n",
    "    with ch.no_grad():\n",
    "        # Binary Classification\n",
    "        if len(target.shape) > 1:\n",
    "            assert output.shape == target.shape, \\\n",
    "                \"Detected binary classification but output shape != target shape\"\n",
    "            return [ch.round(ch.sigmoid(output)).eq(ch.round(target)).float().mean()], [-1.0] \n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        res_exact = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float()\n",
    "            ck_sum = correct_k.sum(0, keepdim=True)\n",
    "            res.append(ck_sum.mul_(100.0 / batch_size))\n",
    "            res_exact.append(correct_k)\n",
    "\n",
    "        if not exact:\n",
    "            return res\n",
    "        else:\n",
    "            return res_exact\n",
    "        \n",
    "def ckpt_at_epoch(num):\n",
    "    return '%s_%s' % (num, CKPT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedBCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        loss = ch.nn.BCEWithLogitsLoss()\n",
    "        return loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "\n",
    "        # logistic distribution\n",
    "        base_distribution = Uniform(0, 1)\n",
    "        transforms_ = [SigmoidTransform().inv]\n",
    "        logistic = TransformedDistribution(base_distribution, transforms_)\n",
    "\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)\n",
    "        # add noise\n",
    "        noised = stacked + logistic.sample(stacked.size())\n",
    "        # filter\n",
    "        filtered = ch.stack([args.phi(batch) for batch in noised]).float()\n",
    "        out = (noised * filtered).sum(dim=0) / (filtered.sum(dim=0) + 1e-5)\n",
    "        grad = ch.where(ch.abs(out) > 1e-5, sig(out), targ) - targ\n",
    "        return grad / pred.size(0), -grad / pred.size(0)\n",
    "\n",
    "class GumbelCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        ce_loss = ch.nn.CrossEntropyLoss()\n",
    "        return ce_loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "        # gumbel distribution\n",
    "        gumbel = Gumbel(0, 1)\n",
    "        # make num_samples copies of pred logits\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)        \n",
    "        # add gumbel noise to logits\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        noised = stacked + rand_noise \n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # remove the logits from the trials, where the kth logit is not the largest value\n",
    "        good_mask = noised_labs.eq(targ)[..., None]\n",
    "        inner_exp = 1 - ch.exp(-rand_noise)\n",
    "        avg = (inner_exp * good_mask).sum(0) / (good_mask.sum(0) + 1e-5) / pred.size(0)\n",
    "        return -avg , None\n",
    "    \n",
    "class TruncatedGumbelCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        ce_loss = ch.nn.CrossEntropyLoss()\n",
    "        return ce_loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "        # initialize gumbel distribution\n",
    "        gumbel = Gumbel(0, 1)\n",
    "        # make num_samples copies of pred logits\n",
    "        stacked = pred[None, ...].repeat(args.num_samples, 1, 1)   \n",
    "        # add gumbel noise to logits\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        noised = stacked + rand_noise \n",
    "        # truncate - if one of the noisy logits does not fall within the truncation set, remove it\n",
    "        filtered = ch.all(args.phi(noised).bool(), dim=2).float().unsqueeze(2)\n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # mask takes care of invalid logits and truncation set\n",
    "        mask = noised_labs.eq(targ)[..., None] * filtered\n",
    "        inner_exp = 1 - ch.exp(-rand_noise)\n",
    "\n",
    "        avg = (((inner_exp * mask).sum(0) / (mask.sum(0) + 1e-5)) - ((inner_exp * filtered).sum(0) / (filtered.sum(0) + 1e-5))) \n",
    "        return -avg / pred.size(0), None, None\n",
    "\n",
    "# gradients\n",
    "trunc_bce = TruncatedBCE.apply\n",
    "gumbel_ce = GumbelCE.apply\n",
    "trunc_ce = TruncatedGumbelCE.apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default Experiment Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"epochs\": 1,\n",
       "  \"num_workers\": 0,\n",
       "  \"batch_size\": 100,\n",
       "  \"bias\": true,\n",
       "  \"num_samples\": 1000,\n",
       "  \"clamp\": true,\n",
       "  \"radius\": 5.0,\n",
       "  \"lr\": 0.1,\n",
       "  \"shuffle\": true,\n",
       "  \"samples\": 10000,\n",
       "  \"in_features\": 2,\n",
       "  \"k\": 2,\n",
       "  \"lower\": -1,\n",
       "  \"upper\": 1,\n",
       "  \"trials\": 1,\n",
       "  \"log_iters\": 1,\n",
       "  \"should_save_ckpt\": true,\n",
       "  \"save_ckpt_iters\": -1,\n",
       "  \"validation_split\": 0.8,\n",
       "  \"momentum\": 0.0,\n",
       "  \"weight_decay\": 0.0,\n",
       "  \"custom_lr_multiplier\": \"cosine\",\n",
       "  \"device\": \"cpu\",\n",
       "  \"alpha_thresh\": 0.2\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# procedure hyperparameters\n",
    "args = Parameters({ \n",
    "    'epochs': 1,\n",
    "    'num_workers': 0, \n",
    "    'batch_size': 100,\n",
    "    'bias': True,\n",
    "    'num_samples': 1000,\n",
    "    'clamp': True, \n",
    "    'radius': 5.0, \n",
    "    'lr': 1e-1,\n",
    "    'shuffle': False, \n",
    "    'samples': 10000,  # number of samples to generate for ground truth\n",
    "    'in_features': 2, # number of in-features to multi-log-reg\n",
    "    'k': 2, # number of classes\n",
    "    'lower': -1, # lower bound for generating ground truth weights\n",
    "    'upper': 1,  # upper bound for generating ground truth weights\n",
    "    'trials': 1,\n",
    "    'log_iters': 1,    \n",
    "    'should_save_ckpt': True,\n",
    "    'save_ckpt_iters': -1,\n",
    "    'validation_split': .8,\n",
    "    'momentum': 0.0,\n",
    "    'weight_decay': 0.0,\n",
    "    'custom_lr_multiplier': COSINE, \n",
    "    'shuffle': True,\n",
    "    'device': 'cpu',\n",
    "    'alpha_thresh': .2,\n",
    "})\n",
    "\n",
    "if ch.cuda.is_available(): \n",
    "    args.__setattr__('device', 'cuda')\n",
    "else: \n",
    "    args.__setattr__('device', 'cpu')\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Multinomial Logistic Regression Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phi = DNN_Lower(ch.full(ch.Size([args.K,]), -2, dtype=ch.float32))\n",
    "# phi = DNN_Lower(Tensor([-2, -3, -2, -3, -4, -5, -6, -7, -6, -5]))\n",
    "phi = Identity()\n",
    "# phi = DNN_Logit_Ball(ch.full(ch.Size([args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([args.K,]), 2, dtype=ch.float32))\n",
    "args.__setattr__('phi', phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform number of trials experiments\n",
    "for i in range(args.trials):\n",
    "    # generate data for exp\n",
    "    ground_truth, loaders, test_loader = gen_data()\n",
    "\n",
    "    # new classifier models at the beginning of each trial\n",
    "    trunc_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "\n",
    "    # truncated store\n",
    "    out_store = Store(TRUNCATED_STORE_PATH)\n",
    "    args.__setattr__('custom_criterion', trunc_ce)  # truncated ce loss\n",
    "    train_model(args, trunc_multi_log_reg, loaders, ground_truth=ground_truth, store=out_store, device=args.device)\n",
    "    # clear output\n",
    "    IPython.display.clear_output(wait=False)\n",
    "\n",
    "    # new classifier models at the beginning of each trial\n",
    "    standard_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "\n",
    "    # naive ce loss\n",
    "    out_store = Store(STANDARD_STORE_PATH)\n",
    "    args.__setattr__('custom_criterion', None) # default ce loss\n",
    "    train_model(args, standard_multi_log_reg, loaders, ground_truth=ground_truth, store=out_store, device=args.device)\n",
    "    # clear output   \n",
    "    IPython.display.clear_output(wait=False)\n",
    "    \n",
    "    # Gumbel CE store path \n",
    "    out_store = Store(GUMBEL_CE_STORE_PATH)\n",
    "    args.__setattr__('custom_criterion', gumbel_ce)\n",
    "    gumbel_ce_multi_log_reg = nn.Linear(in_features=args.IN_FEATURES, out_features=args.K, bias=args.bias)\n",
    "    train_model(args, gumbel_ce_multi_log_reg, loaders, ground_truth=ground_truth, store=out_store, device=args.device)\n",
    "    # clear output\n",
    "    IPython.display.clear_output(wait=False)\n",
    "\n",
    "    # standard multinomial logistic regression eval - if there is a test set\n",
    "    if len(test_loader.dataset) > 0:\n",
    "        # truncated multinomial logistic regression eval\n",
    "        out_store = Store(TRUNCATED_EVAL_STORE_PATH)\n",
    "        eval_model(args, trunc_multi_log_reg, test_loader, out_store)\n",
    "        # clear output\n",
    "        IPython.display.clear_output(wait=False)\n",
    "        \n",
    "        # standard multinomial logistic regression eval\n",
    "        out_store = Store(STANDARD_EVAL_STORE_PATH)\n",
    "        eval_model(args, standard_multi_log_reg, test_loader, out_store)\n",
    "        # clear output\n",
    "        IPython.display.clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 53.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 44.03it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 117.30it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 106.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Test Accuracy: 0    85.089996\n",
      "0    91.180000\n",
      "Name: test_prec1, dtype: float64\n",
      "Truncated Test Accuracy: 0    84.870003\n",
      "0    91.419998\n",
      "Name: test_prec1, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# plot results\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity and L2 Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cosine trunc weight: {}\".format(ch.nn.functional.cosine_similarity(trunc_multi_log_reg.weight, ground_truth.weight)))\n",
    "print(\"cosine trunc bias: {}\".format(ch.nn.functional.cosine_similarity(trunc_multi_log_reg.bias.unsqueeze(0), ground_truth.bias.unsqueeze(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cosine standard weight: {}\".format(ch.nn.functional.cosine_similarity(standard_multi_log_reg.weight, ground_truth.weight)))\n",
    "print(\"cosine standard bias: {}\".format(ch.nn.functional.cosine_similarity(standard_multi_log_reg.bias.unsqueeze(0), ground_truth.bias.unsqueeze(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"cosine gumbel ce weight: {}\".format(ch.nn.functional.cosine_similarity(gumbel_ce_multi_log_reg.weight, ground_truth.weight)))\n",
    "print(\"cosine gumbel ce bias: {}\".format(ch.nn.functional.cosine_similarity(gumbel_ce_multi_log_reg.bias.unsqueeze(0), ground_truth.bias.unsqueeze(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2])\n",
      "Correlation between real and estimated gradient:  tensor(0.9973)\n",
      "Correlation between real and truncated gradient:  tensor(0.9980)\n",
      "Correlation between trunc bce and real ce gradient:  tensor(-9.4713e-09)\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.transforms import SigmoidTransform\n",
    "from torch.distributions.transformed_distribution import TransformedDistribution\n",
    "\n",
    "gumbel = Gumbel(0, 1)\n",
    "\n",
    "# logistic distribution\n",
    "base_distribution = Uniform(0, 1)\n",
    "transforms_ = [SigmoidTransform().inv]\n",
    "logistic = TransformedDistribution(base_distribution, transforms_)\n",
    "\n",
    "phi = Identity()\n",
    "\n",
    "\n",
    "m = ch.nn.Linear(10, 2)\n",
    "x = ch.rand(1000, 10)\n",
    "w = ch.randn(10, 2)\n",
    "y = (x @ w + gumbel.sample([1000, 2])).argmax(1)\n",
    "\n",
    "m_ = ch.nn.Linear(10, 1)\n",
    "x_ = ch.rand(1000, 10)\n",
    "w_ = ch.randn(10, 1)\n",
    "y_ = (x_ @ w_ + logistic.sample([1000, 1])).argmax(1).float()\n",
    "\n",
    "out = m(x)\n",
    "loss_ = GumbelCE.apply(out, y)\n",
    "g, = ch.autograd.grad(loss_, [out])\n",
    "\n",
    "gt_loss = nn.CrossEntropyLoss()(out, y)\n",
    "gt_g, = ch.autograd.grad(gt_loss, [out])\n",
    "\n",
    "trunc_loss = trunc_ce(out, y)\n",
    "gt_trunc, = ch.autograd.grad(trunc_loss, [out])\n",
    "\n",
    "out_ = m_(x_)\n",
    "trunc_bce_loss = trunc_bce(out_, y_.unsqueeze(1))\n",
    "g_bce, = ch.autograd.grad(trunc_bce_loss, [out_])\n",
    "\n",
    "print('Correlation between real and estimated gradient: ',\n",
    "        (gt_g * g).sum() / (gt_g.norm() * g.norm()))\n",
    "\n",
    "print('Correlation between real and truncated gradient: ',\n",
    "        (gt_g * gt_trunc).sum() / (gt_g.norm() * gt_trunc.norm()))\n",
    "\n",
    "print('Correlation between trunc bce and real ce gradient: ', \n",
    "     (g_bce * gt_g).sum() / (g_bce.norm() * gt_g.norm()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0004,  0.0004],\n",
       "        [-0.0005,  0.0005],\n",
       "        [-0.0004,  0.0004],\n",
       "        ...,\n",
       "        [-0.0004,  0.0004],\n",
       "        [-0.0004,  0.0004],\n",
       "        [-0.0005,  0.0005]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")\n",
    "IPython.display.clear_output(wait=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_params = ch.cat([ground_truth.weight.flatten(), ground_truth.bias]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_params = ch.cat([trunc_multi_log_reg.weight.flatten(), trunc_multi_log_reg.bias]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2656], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_params = ch.cat([ground_truth.weight.flatten(), ground_truth.bias]).unsqueeze(1)\n",
    "trunc_params = ch.cat([trunc_multi_log_reg.weight.flatten(), trunc_multi_log_reg.bias]).unsqueeze(1)\n",
    "ch.nn.functional.cosine_similarity(gt_params, trunc_params, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0924])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = ch.randn(100, 1)\n",
    "input2 = ch.randn(100, 1)\n",
    "ch.nn.functional.cosine_similarity(input1, input2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5575, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ch.nn.MSELoss()(gt_params, trunc_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 17.99it/s]\n"
     ]
    }
   ],
   "source": [
    "r = CollectionReader(TRUNCATED_STORE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>l2</th>\n",
       "      <th>epoch</th>\n",
       "      <th>exp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.616993</td>\n",
       "      <td>0.248012</td>\n",
       "      <td>1</td>\n",
       "      <td>96c2e9b6-c9f7-41a2-a2c5-1de45fb3c71b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964328</td>\n",
       "      <td>0.039874</td>\n",
       "      <td>1</td>\n",
       "      <td>5414cef6-f7f0-4be9-bb2d-75a5c0de9bd9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cos_sim        l2  epoch                                exp_id\n",
       "0  0.616993  0.248012      1  96c2e9b6-c9f7-41a2-a2c5-1de45fb3c71b\n",
       "0  0.964328  0.039874      1  5414cef6-f7f0-4be9-bb2d-75a5c0de9bd9"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.df(GROUND_TRUTH_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
