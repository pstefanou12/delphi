{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "KeyboardInterrupt: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8be5ca0b9232>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: KeyboardInterrupt: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script for running random.\n",
    "\"\"\"\n",
    "\n",
    "def main(args):\n",
    "    # MSE Loss\n",
    "    mse_loss = ch.nn.MSELoss()\n",
    "\n",
    "    # distribution for generating ground truth\n",
    "    U = Uniform(args.lower, args.upper)\n",
    "    U_ = Uniform(args.x_lower, args.x_upper)\n",
    "\n",
    "    # # set experiment manual seed \n",
    "    # ch.manual_seed(0)\n",
    "    for i in range(args.trials):\n",
    "        # create store and add table\n",
    "        store = Store(args.out_dir)\n",
    "        store.add_table(TABLE_NAME, { \n",
    "            'ols_r2': float,\n",
    "            'ols_param_mse': float,\n",
    "            'ols_var_mse': float,\n",
    "            'known_emp_r2': float,\n",
    "            'known_emp_param_mse': float,\n",
    "            'known_emp_time': int,\n",
    "            'known_r2': float,\n",
    "            'known_param_mse': float,\n",
    "            'known_time': int,\n",
    "            'unknown_r2': float, \n",
    "            'unknown_param_mse': float,\n",
    "            'unknown_var_mse': float,\n",
    "            'unknown_time': int,\n",
    "            'trunc_reg_r2': float,\n",
    "            'trunc_reg_param_mse': float, \n",
    "            'trunc_reg_var_mse': float,\n",
    "            'trunc_reg_time': int,\n",
    "            'alpha': float, \n",
    "            'num_samples': int,\n",
    "            'noise_scale': float, \n",
    "        })\n",
    "\n",
    "        # generate ground truth\n",
    "        ground_truth = ch.nn.Linear(in_features=args.dims, out_features=1, bias=args.bias)\n",
    "        ground_truth.weight = ch.nn.Parameter(U.sample(ch.Size([1, args.dims]))) \n",
    "        # bias term \n",
    "        if args.bias: \n",
    "            ground_truth.bias = ch.nn.Parameter(U.sample(ch.Size([1, 1])))\n",
    "\n",
    "        # create base classifier\n",
    "        with ch.no_grad():\n",
    "            # generate data\n",
    "            X = U_.sample(ch.Size([args.samples, args.dims]))                # \n",
    "            y = ground_truth(X)\n",
    "            # standardize input features\n",
    "            X_ = (X - X.mean(0)[None,...]) / ch.sqrt(X.var(0))\n",
    "\n",
    "        # increase variance up to 20\n",
    "        for var in range(1, args.var_ + 1):\n",
    "            noise_var = Tensor([var])[...,None]\n",
    "            # remove synthetic data from the computation graph\n",
    "            with ch.no_grad():\n",
    "                # add noise to ground-truth pedictions\n",
    "                noised = y + ch.sqrt(noise_var) * ch.randn(X.size(0), 1)\n",
    "                # standardize noised ground truth output features\n",
    "                noised_ = (y - y.mean(0)[None,...]) / ch.sqrt(y.var(0))\n",
    "                # truncate based off of the standardized data\n",
    "                indices = args.phi(noised_).nonzero(as_tuple=False).flatten()\n",
    "                y_trunc, x_trunc = noised_[indices], X_[indices]\n",
    "                alpha = Tensor([y_trunc.size(0) / args.samples])\n",
    "                print(\"alpha: \", alpha)\n",
    "\n",
    "            print(\"x trunc: \", x_trunc)\n",
    "            print(\"y trunc: \", y_trunc)\n",
    "\n",
    "            # standardize ground-truth parameters\n",
    "            gt_ols = LinearRegression().fit(X_, noised_)\n",
    "            gt_params = ch.cat([Tensor(gt_ols.coef_).T, Tensor(gt_ols.intercept_)[..., None]])\n",
    "            print(\"gt params: \", gt_params)\n",
    "\n",
    "            # empirical linear regression\n",
    "            ols = LinearRegression() \n",
    "            ols.fit(x_trunc, y_trunc)\n",
    "            ols_var = ch.var(Tensor(ols.predict(x_trunc)) - y_trunc, dim=0)[..., None]\n",
    "            ols_params = ch.cat([Tensor(ols.coef_).T, Tensor(ols.intercept_)[..., None]])\n",
    "            # check r2 for entire dataset\n",
    "            ols_pred = ols.predict(X_)\n",
    "            print(\"ols params: \", ols_params)\n",
    "\n",
    "            # ols results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'ols_r2': r2_score(y.flatten(), ols_pred.flatten()), \n",
    "                'ols_param_mse': mse_loss(Tensor(ols_params), Tensor(gt_params)),\n",
    "                'ols_var_mse': mse_loss(ols_var, noise_var), \n",
    "                })\n",
    "\n",
    "            # truncated linear regression with known noise variance using empirical noise variance\n",
    "            trunc_reg = TruncatedLinearRegression(phi=args.phi, alpha=alpha, args=args, bias=args.bias, var=ols_var)\n",
    "            st = datetime.datetime.now()\n",
    "            known_emp_results = trunc_reg.fit(x_trunc, y_trunc)\n",
    "            known_emp_params = ch.cat([known_emp_results.weight.detach().cpu().T, known_emp_results.bias.detach().cpu()[..., None]])\n",
    "            # check r2 for entire dataset\n",
    "            known_emp_pred = known_emp_results(X_).detach().cpu()\n",
    "            print(\"known emp params: \", known_emp_params)\n",
    "\n",
    "            # known emp results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'known_emp_r2': r2_score(noised_.flatten(), known_emp_pred.flatten()), \n",
    "                'known_emp_param_mse': mse_loss(known_emp_params, gt_params),\n",
    "                'known_emp_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "                })\n",
    "\n",
    "            # truncated linear regression with known noise variance using actual noise variance\n",
    "            trunc_reg = TruncatedLinearRegression(phi=args.phi, alpha=alpha, args=args, bias=args.bias, var=Tensor([var])[...,None])\n",
    "            st = datetime.datetime.now()\n",
    "            known_results = trunc_reg.fit(x_trunc, y_trunc)\n",
    "            known_params = ch.cat([known_results.weight.detach().cpu().T, known_results.bias.detach().cpu()[..., None]])\n",
    "            known_time = int((datetime.datetime.now() - st).total_seconds())\n",
    "            # check r2 for entire dataset\n",
    "            known_pred = known_results(X_).detach().cpu()\n",
    "\n",
    "            print(\"known params: \", known_params)\n",
    "\n",
    "            # known results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'known_r2': r2_score(noised_.flatten(), known_pred.flatten()), \n",
    "                'known_param_mse': mse_loss(known_params, gt_params),\n",
    "                'known_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "                })\n",
    "\n",
    "            # truncated linear regression with unknown noise variance\n",
    "            trunc_reg = TruncatedLinearRegression(phi=args.phi, alpha=alpha, args=args, bias=args.bias)\n",
    "            st = datetime.datetime.now()\n",
    "            unknown_results = trunc_reg.fit(x_trunc, y_trunc)\n",
    "            var_ = unknown_results.lambda_.inverse().detach()\n",
    "            unknown_params = ch.cat([(unknown_results.weight.detach() * var_).cpu().T, (unknown_results.bias.detach() * var_).cpu()])\n",
    "            # check r2 for entire dataset\n",
    "            unknown_pred = unknown_results(X_).detach().cpu()\n",
    "\n",
    "            print(\"unknown params\", unknown_params)\n",
    "            print(\"var_: \", var_)\n",
    "\n",
    "            # unknown results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'unknown_r2': r2_score(noised_.flatten(), unknown_pred.flatten()), \n",
    "                'unknown_param_mse': mse_loss(unknown_params, gt_params),\n",
    "                'unknown_var_mse': mse_loss(var_, noise_var),\n",
    "                'unknown_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "                })\n",
    "\n",
    "#             # spawn subprocess to run truncreg experiment\n",
    "#             concat = ch.cat([X_, noised_], dim=1).numpy()\n",
    "#             \"\"\"\n",
    "#             DATA FORMAT:\n",
    "#                 -First n-1 columns are independent variables\n",
    "#                 -nth column is dependent variable\n",
    "#             \"\"\"\n",
    "#             concat_df = pd.DataFrame(concat)\n",
    "#             concat_df.to_csv(args.out_dir + '/' + TMP_FILE) # save data to csv\n",
    "#             \"\"\"\n",
    "#             Arguments\n",
    "#             - c - truncation point (float)\n",
    "#             - dir - left or right -> type of truncation (str)\n",
    "#             \"\"\"\n",
    "#             cmd = [COMMAND, PATH2SCRIPT] + [str(args.C), str(args.dims), 'left', args.out_dir]\n",
    "\n",
    "#             # check_output will run the command and store the result\n",
    "#             st = datetime.datetime.now()\n",
    "#             result = subprocess.check_output(cmd, universal_newlines=True)\n",
    "#             trunc_res = Tensor(pd.read_csv(args.out_dir + '/' + RESULT_FILE)['x'].to_numpy())\n",
    "#             trunc_reg_params = ch.cat([trunc_res[1:-1].flatten(), trunc_res[0][None,...]])[..., None]\n",
    "\n",
    "#             print(\"trunc reg params: \", trunc_reg_params)\n",
    "#             print(\"first term: \", trunc_reg_params[:-1][None,...].mm(X_))\n",
    "#             print(\"second term: \", trunc_reg_params[-1][None,...])\n",
    "#             trunc_reg_pred = trunc_reg_params[:-1][None,...].mm(X_) + trunc_reg_params[-1][None,...]\n",
    "\n",
    "#             # truncreg results\n",
    "#             store[TABLE_NAME].update_row({\n",
    "#                 'trunc_reg_r2': r2_score(noised_.flatten(), trunc_reg_pred.flatten()), \n",
    "#                 'trunc_reg_param_mse': mse_loss(trunc_reg_params, gt_params),\n",
    "#                 'trunc_reg_var_mse': mse_loss(trunc_res[-1].pow(2)[None,...], noise_var),\n",
    "#                 'trunc_reg_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "#                 })\n",
    "\n",
    "            # add additional metadata to store\n",
    "            store[TABLE_NAME].update_row({ \n",
    "                'alpha': float(alpha.flatten()),\n",
    "                'num_samples': x_trunc.size(0),\n",
    "                'noise_scale': float(var), \n",
    "            })\n",
    "\n",
    "            # append row to table\n",
    "            store[TABLE_NAME].flush_row()\n",
    "\n",
    "        # close current store\n",
    "        store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Parameters({\n",
    "  \"dims\": 2,\n",
    "  \"bias\": true,\n",
    "  \"out_dir\": \"/home/pstefanou/Regression/Synthetic\",\n",
    "  \"samples\": 10000,\n",
    "  \"c\": 0,\n",
    "  \"batch_size\": 10,\n",
    "  \"lr\": 0.1,\n",
    "  \"var_lr\": 0.01,\n",
    "  \"var_\": 1,\n",
    "  \"trials\": 1,\n",
    "  \"norm\": false,\n",
    "  \"workers\": 8,\n",
    "  \"step_lr\": 100000000,\n",
    "  \"step_lr_gamma\": 1.0,\n",
    "  \"x_lower\": -100,\n",
    "  \"x_upper\": 100,\n",
    "  \"lower\": -1,\n",
    "  \"upper\": 1,\n",
    "  \"device\": \"cpu\",\n",
    "  \"version\": \"ce83bf962d3c1c857d1e29d464f149b2358cedd4\"\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "args.__setattr__('workers', 8)\n",
    "# args.__setattr__('custom_lr_multiplier', consts.COSINE)\n",
    "args.__setattr__('step_lr', 100000000)\n",
    "args.__setattr__('step_lr_gamma', 1.0)\n",
    "# independent variable bounds\n",
    "args.__setattr__('x_lower', -100)\n",
    "args.__setattr__('x_upper', 100)\n",
    "# parameter bounds\n",
    "args.__setattr__('lower', -1)\n",
    "args.__setattr__('upper', 1)\n",
    "args.__setattr__('device', 'cuda' if ch.cuda.is_available() else 'cpu')\n",
    "# normalize gradient\n",
    "args.__setattr__('norm', False)\n",
    "\n",
    "# setup store with metadata\n",
    "store = Store(args.out_dir)\n",
    "setup_store_with_metadata(args, store)\n",
    "store.close()\n",
    "\n",
    "print('args: ', args)\n",
    "\n",
    "args.__setattr__('phi', Left(Tensor([args.C])))\n",
    "\n",
    "# run experiment\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
