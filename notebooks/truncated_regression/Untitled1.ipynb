{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "from torch import Tensor\n",
    "from torch.distributions import Uniform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import datetime\n",
    "\n",
    "import sys \n",
    "sys.path.append('../..')\n",
    "from delphi.stats.linear_regression import TruncatedLinearRegression\n",
    "from delphi.oracle import Left\n",
    "from delphi.utils import constants as consts\n",
    "from delphi.utils.helpers import setup_store_with_metadata\n",
    "\n",
    "\n",
    "# CONSTANTS \n",
    "TABLE_NAME = 'results'\n",
    "\n",
    "# commands and arguments\n",
    "COMMAND = 'Rscript'\n",
    "PATH2SCRIPT = '/home/gridsan/stefanou/delphi/truncreg.R'\n",
    "TMP_FILE = 'tmp.csv'\n",
    "RESULT_FILE = 'result.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script for running random.\n",
    "\"\"\"\n",
    "\n",
    "def main(args):\n",
    "    # MSE Loss\n",
    "    mse_loss = ch.nn.MSELoss()\n",
    "\n",
    "    # distribution for generating ground truth\n",
    "    U = Uniform(args.lower, args.upper)\n",
    "    U_ = Uniform(args.x_lower, args.x_upper)\n",
    "\n",
    "    # # set experiment manual seed \n",
    "    # ch.manual_seed(0)\n",
    "    for i in range(args.trials):\n",
    "        # create store and add table\n",
    "        store = Store(args.out_dir)\n",
    "        store.add_table(TABLE_NAME, { \n",
    "            'ols_r2': float,\n",
    "            'ols_param_mse': float,\n",
    "            'ols_var_mse': float,\n",
    "            'known_emp_r2': float,\n",
    "            'known_emp_param_mse': float,\n",
    "            'known_emp_time': int,\n",
    "            'known_r2': float,\n",
    "            'known_param_mse': float,\n",
    "            'known_time': int,\n",
    "            'unknown_r2': float, \n",
    "            'unknown_param_mse': float,\n",
    "            'unknown_var_mse': float,\n",
    "            'unknown_time': int,\n",
    "            'trunc_reg_r2': float,\n",
    "            'trunc_reg_param_mse': float, \n",
    "            'trunc_reg_var_mse': float,\n",
    "            'trunc_reg_time': int,\n",
    "            'alpha': float, \n",
    "            'num_samples': int,\n",
    "            'noise_scale': float, \n",
    "        })\n",
    "\n",
    "        # generate ground truth\n",
    "        ground_truth = ch.nn.Linear(in_features=args.dims, out_features=1, bias=args.bias)\n",
    "        ground_truth.weight = ch.nn.Parameter(U.sample(ch.Size([1, args.dims]))) \n",
    "        # bias term \n",
    "        if args.bias: \n",
    "            ground_truth.bias = ch.nn.Parameter(U.sample(ch.Size([1, 1])))\n",
    "\n",
    "        # create base classifier\n",
    "        with ch.no_grad():\n",
    "            # generate data\n",
    "            X = U_.sample(ch.Size([args.samples, args.dims]))                # \n",
    "            y = ground_truth(X)\n",
    "            # standardize input features\n",
    "            X_ = (X - X.mean(0)[None,...]) / ch.sqrt(X.var(0))\n",
    "\n",
    "        # increase variance up to 20\n",
    "        for var in range(1, args.var_ + 1):\n",
    "            noise_var = Tensor([var])[...,None]\n",
    "            # remove synthetic data from the computation graph\n",
    "            with ch.no_grad():\n",
    "                # add noise to ground-truth pedictions\n",
    "                noised = y + ch.sqrt(noise_var) * ch.randn(X.size(0), 1)\n",
    "                # standardize noised ground truth output features\n",
    "                noised_ = (y - y.mean(0)[None,...]) / ch.sqrt(y.var(0))\n",
    "                # truncate based off of the standardized data\n",
    "                indices = args.phi(noised_).nonzero(as_tuple=False).flatten()\n",
    "                y_trunc, x_trunc = noised_[indices], X_[indices]\n",
    "                alpha = Tensor([y_trunc.size(0) / args.samples])\n",
    "                print(\"alpha: \", alpha)\n",
    "\n",
    "            print(\"x trunc: \", x_trunc)\n",
    "            print(\"y trunc: \", y_trunc)\n",
    "\n",
    "            # standardize ground-truth parameters\n",
    "            gt_ols = LinearRegression().fit(X_, noised_)\n",
    "            gt_params = ch.cat([Tensor(gt_ols.coef_).T, Tensor(gt_ols.intercept_)[..., None]])\n",
    "            print(\"gt params: \", gt_params)\n",
    "\n",
    "            # empirical linear regression\n",
    "            ols = LinearRegression() \n",
    "            ols.fit(x_trunc, y_trunc)\n",
    "            ols_var = ch.var(Tensor(ols.predict(x_trunc)) - y_trunc, dim=0)[..., None]\n",
    "            ols_params = ch.cat([Tensor(ols.coef_).T, Tensor(ols.intercept_)[..., None]])\n",
    "            # check r2 for entire dataset\n",
    "            ols_pred = ols.predict(X_)\n",
    "            print(\"ols params: \", ols_params)\n",
    "\n",
    "            # ols results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'ols_r2': r2_score(y.flatten(), ols_pred.flatten()), \n",
    "                'ols_param_mse': mse_loss(Tensor(ols_params), Tensor(gt_params)),\n",
    "                'ols_var_mse': mse_loss(ols_var, noise_var), \n",
    "                })\n",
    "\n",
    "            # truncated linear regression with known noise variance using empirical noise variance\n",
    "            trunc_reg = TruncatedLinearRegression(phi=args.phi, alpha=alpha, args=args, bias=args.bias, var=ols_var)\n",
    "            st = datetime.datetime.now()\n",
    "            known_emp_results = trunc_reg.fit(x_trunc, y_trunc)\n",
    "            known_emp_params = ch.cat([known_emp_results.weight.detach().cpu().T, known_emp_results.bias.detach().cpu()[..., None]])\n",
    "            # check r2 for entire dataset\n",
    "            known_emp_pred = known_emp_results(X_).detach().cpu()\n",
    "            print(\"known emp params: \", known_emp_params)\n",
    "\n",
    "            # known emp results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'known_emp_r2': r2_score(noised_.flatten(), known_emp_pred.flatten()), \n",
    "                'known_emp_param_mse': mse_loss(known_emp_params, gt_params),\n",
    "                'known_emp_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "                })\n",
    "\n",
    "            # truncated linear regression with known noise variance using actual noise variance\n",
    "            trunc_reg = TruncatedLinearRegression(phi=args.phi, alpha=alpha, args=args, bias=args.bias, var=Tensor([var])[...,None])\n",
    "            st = datetime.datetime.now()\n",
    "            known_results = trunc_reg.fit(x_trunc, y_trunc)\n",
    "            known_params = ch.cat([known_results.weight.detach().cpu().T, known_results.bias.detach().cpu()[..., None]])\n",
    "            known_time = int((datetime.datetime.now() - st).total_seconds())\n",
    "            # check r2 for entire dataset\n",
    "            known_pred = known_results(X_).detach().cpu()\n",
    "\n",
    "            print(\"known params: \", known_params)\n",
    "\n",
    "            # known results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'known_r2': r2_score(noised_.flatten(), known_pred.flatten()), \n",
    "                'known_param_mse': mse_loss(known_params, gt_params),\n",
    "                'known_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "                })\n",
    "\n",
    "            # truncated linear regression with unknown noise variance\n",
    "            trunc_reg = TruncatedLinearRegression(phi=args.phi, alpha=alpha, args=args, bias=args.bias)\n",
    "            st = datetime.datetime.now()\n",
    "            unknown_results = trunc_reg.fit(x_trunc, y_trunc)\n",
    "            var_ = unknown_results.lambda_.inverse().detach()\n",
    "            unknown_params = ch.cat([(unknown_results.weight.detach() * var_).cpu().T, (unknown_results.bias.detach() * var_).cpu()])\n",
    "            # check r2 for entire dataset\n",
    "            unknown_pred = unknown_results(X_).detach().cpu()\n",
    "\n",
    "            print(\"unknown params\", unknown_params)\n",
    "            print(\"var_: \", var_)\n",
    "\n",
    "            # unknown results\n",
    "            store[TABLE_NAME].update_row({\n",
    "                'unknown_r2': r2_score(noised_.flatten(), unknown_pred.flatten()), \n",
    "                'unknown_param_mse': mse_loss(unknown_params, gt_params),\n",
    "                'unknown_var_mse': mse_loss(var_, noise_var),\n",
    "                'unknown_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "                })\n",
    "\n",
    "#             # spawn subprocess to run truncreg experiment\n",
    "#             concat = ch.cat([X_, noised_], dim=1).numpy()\n",
    "#             \"\"\"\n",
    "#             DATA FORMAT:\n",
    "#                 -First n-1 columns are independent variables\n",
    "#                 -nth column is dependent variable\n",
    "#             \"\"\"\n",
    "#             concat_df = pd.DataFrame(concat)\n",
    "#             concat_df.to_csv(args.out_dir + '/' + TMP_FILE) # save data to csv\n",
    "#             \"\"\"\n",
    "#             Arguments\n",
    "#             - c - truncation point (float)\n",
    "#             - dir - left or right -> type of truncation (str)\n",
    "#             \"\"\"\n",
    "#             cmd = [COMMAND, PATH2SCRIPT] + [str(args.C), str(args.dims), 'left', args.out_dir]\n",
    "\n",
    "#             # check_output will run the command and store the result\n",
    "#             st = datetime.datetime.now()\n",
    "#             result = subprocess.check_output(cmd, universal_newlines=True)\n",
    "#             trunc_res = Tensor(pd.read_csv(args.out_dir + '/' + RESULT_FILE)['x'].to_numpy())\n",
    "#             trunc_reg_params = ch.cat([trunc_res[1:-1].flatten(), trunc_res[0][None,...]])[..., None]\n",
    "\n",
    "#             print(\"trunc reg params: \", trunc_reg_params)\n",
    "#             print(\"first term: \", trunc_reg_params[:-1][None,...].mm(X_))\n",
    "#             print(\"second term: \", trunc_reg_params[-1][None,...])\n",
    "#             trunc_reg_pred = trunc_reg_params[:-1][None,...].mm(X_) + trunc_reg_params[-1][None,...]\n",
    "\n",
    "#             # truncreg results\n",
    "#             store[TABLE_NAME].update_row({\n",
    "#                 'trunc_reg_r2': r2_score(noised_.flatten(), trunc_reg_pred.flatten()), \n",
    "#                 'trunc_reg_param_mse': mse_loss(trunc_reg_params, gt_params),\n",
    "#                 'trunc_reg_var_mse': mse_loss(trunc_res[-1].pow(2)[None,...], noise_var),\n",
    "#                 'trunc_reg_time': int((datetime.datetime.now() - st).total_seconds()), \n",
    "#                 })\n",
    "\n",
    "            # add additional metadata to store\n",
    "            store[TABLE_NAME].update_row({ \n",
    "                'alpha': float(alpha.flatten()),\n",
    "                'num_samples': x_trunc.size(0),\n",
    "                'noise_scale': float(var), \n",
    "            })\n",
    "\n",
    "            # append row to table\n",
    "            store[TABLE_NAME].flush_row()\n",
    "\n",
    "        # close current store\n",
    "        store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in: /home/pstefanou/Regression/Synthetic/aa915f76-fbb4-4c2b-9dc2-2281a562cd1e\n",
      "args:  {\n",
      "  \"dims\": 2,\n",
      "  \"bias\": true,\n",
      "  \"out_dir\": \"/home/pstefanou/Regression/Synthetic\",\n",
      "  \"samples\": 10000,\n",
      "  \"c\": 0,\n",
      "  \"batch_size\": 10,\n",
      "  \"lr\": 0.1,\n",
      "  \"var_lr\": 0.01,\n",
      "  \"var_\": 1,\n",
      "  \"trials\": 1,\n",
      "  \"norm\": false,\n",
      "  \"workers\": 8,\n",
      "  \"step_lr\": 100000000,\n",
      "  \"step_lr_gamma\": 1.0,\n",
      "  \"x_lower\": -100,\n",
      "  \"x_upper\": 100,\n",
      "  \"lower\": -1,\n",
      "  \"upper\": 1,\n",
      "  \"device\": \"cuda\",\n",
      "  \"version\": \"b182ac21c5c9c50e1dc4d9bb932de812d0795eac\"\n",
      "}\n",
      "Logging in: /home/pstefanou/Regression/Synthetic/374fe02e-5068-4840-a18a-b51247f56f66\n",
      "alpha:  tensor([0.5039])\n",
      "x trunc:  tensor([[ 1.1372, -1.1844],\n",
      "        [-0.9090, -0.1554],\n",
      "        [ 0.7516, -1.5321],\n",
      "        ...,\n",
      "        [-1.6485, -0.2335],\n",
      "        [ 0.0595, -0.3804],\n",
      "        [ 0.4809, -0.8031]])\n",
      "y trunc:  tensor([[1.2070],\n",
      "        [0.1370],\n",
      "        [1.5468],\n",
      "        ...,\n",
      "        [0.2001],\n",
      "        [0.3814],\n",
      "        [0.8125]])\n",
      "gt params:  tensor([[ 2.0194e-02],\n",
      "        [-9.9968e-01],\n",
      "        [-2.6528e-08]])\n",
      "ols params:  tensor([[ 2.0194e-02],\n",
      "        [-9.9968e-01],\n",
      "        [ 2.3842e-07]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known emp params:  tensor([[ 2.0194e-02],\n",
      "        [-9.9968e-01],\n",
      "        [ 2.8902e-07]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known params:  tensor([[ 0.0178],\n",
      "        [-2.5939],\n",
      "        [-2.4876]])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4011b87bcf9943a99b024f726dfb17f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x2 and 1x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6abb70077e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# run experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-db79e2468d4e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mtrunc_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0munknown_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrunc_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mvar_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munknown_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0munknown_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0munknown_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/stats/linear_regression.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iteration_hook'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# run PGD for parameter estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lin_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/train.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(args, model, loaders, checkpoint, parallel, dp_device_ids, store, table, update_params, disable_no_grad)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;31m# do training loops until performing enough gradient steps or epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mtrain_prec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# check for logging/checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/train.py\u001b[0m in \u001b[0;36mmodel_loop\u001b[0;34m(args, loop_type, loader, model, optimizer, epoch, steps, writer, device)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0;31m# attacker model returns both output anf final input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/utils/helpers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x2 and 1x2)"
     ]
    }
   ],
   "source": [
    "args = Parameters({\n",
    "  \"dims\": 2,\n",
    "  \"bias\": True,\n",
    "  \"out_dir\": \"/home/pstefanou/Regression/Synthetic\",\n",
    "  \"samples\": 10000,\n",
    "  \"c\": 0,\n",
    "  \"batch_size\": 10,\n",
    "  \"lr\": 0.1,\n",
    "  \"var_lr\": 0.01,\n",
    "  \"var_\": 1,\n",
    "  \"trials\": 1,\n",
    "  \"norm\": False,\n",
    "  \"workers\": 8,\n",
    "  \"step_lr\": 100000000,\n",
    "  \"step_lr_gamma\": 1.0,\n",
    "  \"x_lower\": -100,\n",
    "  \"x_upper\": 100,\n",
    "  \"lower\": -1,\n",
    "  \"upper\": 1,\n",
    "  \"device\": \"cpu\",\n",
    "  \"version\": \"ce83bf962d3c1c857d1e29d464f149b2358cedd4\"\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "args.__setattr__('workers', 8)\n",
    "# args.__setattr__('custom_lr_multiplier', consts.COSINE)\n",
    "args.__setattr__('step_lr', 100000000)\n",
    "args.__setattr__('step_lr_gamma', 1.0)\n",
    "# independent variable bounds\n",
    "args.__setattr__('x_lower', -100)\n",
    "args.__setattr__('x_upper', 100)\n",
    "# parameter bounds\n",
    "args.__setattr__('lower', -1)\n",
    "args.__setattr__('upper', 1)\n",
    "args.__setattr__('device', 'cuda' if ch.cuda.is_available() else 'cpu')\n",
    "# normalize gradient\n",
    "args.__setattr__('norm', False)\n",
    "\n",
    "# setup store with metadata\n",
    "store = Store(args.out_dir)\n",
    "setup_store_with_metadata(args, store)\n",
    "store.close()\n",
    "\n",
    "print('args: ', args)\n",
    "\n",
    "args.__setattr__('phi', Left(Tensor([args.C])))\n",
    "\n",
    "# run experiment\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
