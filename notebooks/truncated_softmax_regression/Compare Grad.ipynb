{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda tensors...\n"
     ]
    }
   ],
   "source": [
    "#### MAY NEED TO REMOVE --> THESE IMPORTS ARE JUST FOR MY DEPENDENCIES ON MY LOCAL DEVICE\n",
    "import sys \n",
    "sys.path.append('../..')\n",
    "######\n",
    "\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "from cox.readers import CollectionReader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "from torch import sigmoid as sig\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.distributions import Gumbel, Uniform\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.transforms import SigmoidTransform\n",
    "from torch.distributions.transformed_distribution import TransformedDistribution\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "from abc import ABC\n",
    "import IPython\n",
    "import os\n",
    "import dill\n",
    "import config\n",
    "\n",
    "from delphi import train\n",
    "from delphi import oracle\n",
    "from delphi import grad\n",
    "import delphi.utils.constants as consts\n",
    "# set environment variable so that stores can create output files\n",
    "\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "if ch.cuda.is_available(): \n",
    "    ch.set_default_tensor_type(ch.cuda.FloatTensor)\n",
    "    print(\"cuda tensors...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"in_features\": 2,\n",
       "  \"k\": 2,\n",
       "  \"param_lower\": -1,\n",
       "  \"param_upper\": 1,\n",
       "  \"x_lower\": -5,\n",
       "  \"x_upper\": 5,\n",
       "  \"samples\": 10000,\n",
       "  \"num_samples\": 1000\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.args = Parameters({\n",
    "    'in_features': 2, \n",
    "    'k': 2,\n",
    "    'param_lower': -1, \n",
    "    'param_upper': 1, \n",
    "    'x_lower': -5, \n",
    "    'x_upper': 5,\n",
    "    'samples': 10000,\n",
    "    'num_samples': 1000,\n",
    "})\n",
    "config.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracles\n",
    "id_ = oracle.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumbel = Gumbel(0, 1)\n",
    "\n",
    "# logistic distribution\n",
    "base_distribution = Uniform(0, 1)\n",
    "transforms_ = [SigmoidTransform().inv]\n",
    "logistic = TransformedDistribution(base_distribution, transforms_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_bce = grad.LogisticBCE.apply\n",
    "from torch.nn import BCEWithLogitsLoss; bce_logit = BCEWithLogitsLoss()\n",
    "trunc_ce = grad.TruncatedCE.apply\n",
    "trunc_bce = grad.TruncatedBCE.apply\n",
    "gumbel_ce = grad.GumbelCE.apply\n",
    "from torch.nn import CrossEntropyLoss; ce_loss = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_similarity(args, grad_1, grad_2, d_n):\n",
    "    \"\"\"\n",
    "    grad_1: first gradient\n",
    "    grad_2: second gradient \n",
    "    d_n: latent variable noise distribution\n",
    "    returns: grad_1 and grad_2 gradients with respect to the noised output\n",
    "    \"\"\"\n",
    "    # generate random uniform weights\n",
    "    ground_truth = nn.Linear(in_features=args.in_features, out_features=args.k, bias=args.bias)\n",
    "    ground_truth.weight = nn.Parameter(Uniform(args.param_lower, args.param_upper).sample(ch.Size([1, args.in_features])))\n",
    "    if ground_truth.bias is not None: \n",
    "        ground_truth.bias = nn.Parameter(Uniform(args.param_lower, args.param_upper).sample(ch.Size([1,])))\n",
    "\n",
    "    # generate data\n",
    "    X = Uniform(-5, 5).sample(ch.Size([args.samples, args.in_features]))\n",
    "    z = ground_truth(X) + d_n.sample(ch.Size([X.size(0), 1]))\n",
    "    y = args.pi(z)\n",
    "\n",
    "    # truncate\n",
    "    indices = ch.all(args.phi(z).bool(), dim=1).nonzero(as_tuple=False).flatten()\n",
    "    x_trunc = X[indices]\n",
    "    y_trunc = y[indices]\n",
    "\n",
    "    print(\"alpha: \", x_trunc.size(0) / X.size(0))\n",
    "\n",
    "    # pass data through model\n",
    "    model = ch.nn.Linear(in_features=args.in_features, out_features=args.k)\n",
    "    pred = model(x_trunc)\n",
    "\n",
    "    g1_loss = grad_1(pred, y_trunc)\n",
    "    g1_g, = ch.autograd.grad(g1_loss, [pred])\n",
    "\n",
    "    g2_loss = grad_2(pred, y_trunc)\n",
    "    g2_g, = ch.autograd.grad(g2_loss, [pred])\n",
    "\n",
    "\n",
    "    print('Cosine Similarity between grad 1 and grad 2: ',\n",
    "            ch.nn.CosineSimilarity(dim=1)(g2_g.T, g1_g.T))\n",
    "    \n",
    "    return g1_g, g2_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projection Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = lambda z: ch.where(z > 0, ch.ones(1), ch.zeros(1))\n",
    "multi = lambda z: z.argmax(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare CE Loss with Truncated CE Loss with Identity Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.0\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9990, 0.9806])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('phi', id_)\n",
    "config.args.__setattr__('pi', multi)\n",
    "config.args.__setattr__('k', 2)\n",
    "g1, g2 = gradient_similarity(config.args, ce_loss, trunc_ce, gumbel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare CE Loss with Truncated CE Loss with Logit Ball Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.5989\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9425, 0.4788])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('pi', multi)\n",
    "config.args.__setattr__('k', 2)\n",
    "config.args.__setattr__('phi', oracle.DNN_Logit_Ball(ch.full(ch.Size([config.args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([config.args.K,]), 2, dtype=ch.float32)) )\n",
    "g1, g2 = gradient_similarity(config.args, ce_loss, trunc_ce, gumbel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare BCE Loss with Truncated BCE Loss and Idenity Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.0\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9998])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('phi', id_)\n",
    "config.args.__setattr__('pi', binary)\n",
    "config.args.__setattr__('k', 1)\n",
    "g1, g2 = gradient_similarity(config.args, bce_logit, trunc_bce, logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare BCE Loss with Truncated BCE Loss with Ball Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.4714\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9279])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('pi', binary)\n",
    "config.args.__setattr__('k', 1)\n",
    "config.args.__setattr__('phi', oracle.DNN_Logit_Ball(ch.full(ch.Size([config.args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([config.args.K,]), 2, dtype=ch.float32)) )\n",
    "g1, g2 = gradient_similarity(config.args, bce_logit, trunc_bce, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
