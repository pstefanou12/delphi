{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MAY NEED TO REMOVE --> THESE IMPORTS ARE JUST FOR MY DEPENDENCIES ON MY LOCAL DEVICE\n",
    "import sys \n",
    "sys.path.append('../..')\n",
    "######\n",
    "\n",
    "from cox.utils import Parameters\n",
    "from cox.store import Store\n",
    "from cox.readers import CollectionReader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch as ch\n",
    "from torch import Tensor\n",
    "from torch import sigmoid as sig\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.distributions import Gumbel, Uniform\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.transforms import SigmoidTransform\n",
    "from torch.distributions.transformed_distribution import TransformedDistribution\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm.autonotebook import tqdm as tqdm\n",
    "from abc import ABC\n",
    "import IPython\n",
    "import os\n",
    "import dill\n",
    "import config\n",
    "\n",
    "from delphi import train\n",
    "from delphi import oracle\n",
    "from delphi import grad\n",
    "import delphi.utils.constants as consts\n",
    "from delphi.utils.helpers import logistic\n",
    "# set environment variable so that stores can create output files\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"in_features\": 2,\n",
       "  \"k\": 2,\n",
       "  \"param_lower\": -1,\n",
       "  \"param_upper\": 1,\n",
       "  \"x_lower\": -5,\n",
       "  \"x_upper\": 5,\n",
       "  \"samples\": 10000,\n",
       "  \"num_samples\": 1000\n",
       "}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.args = Parameters({\n",
    "    'in_features': 2, \n",
    "    'k': 2,\n",
    "    'param_lower': -1, \n",
    "    'param_upper': 1, \n",
    "    'x_lower': -5, \n",
    "    'x_upper': 5,\n",
    "    'samples': 10000,\n",
    "    'num_samples': 1000,\n",
    "})\n",
    "config.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oracles\n",
    "id_ = oracle.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gumbel noise distribution\n",
    "gumbel = Gumbel(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_bce = grad.LogisticBCE.apply\n",
    "from torch.nn import BCEWithLogitsLoss; bce_logit = BCEWithLogitsLoss()\n",
    "trunc_ce = grad.TruncatedCE.apply\n",
    "trunc_bce = grad.TruncatedBCE.apply\n",
    "gumbel_ce = grad.GumbelCE.apply\n",
    "from torch.nn import CrossEntropyLoss; ce_loss = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GumbelBCE(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        loss = CrossEntropyLoss()\n",
    "        return loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "\n",
    "        # Gumbel distribution\n",
    "        gumbel = Gumbel(0, 1)\n",
    "\n",
    "        stacked = pred[None, ...].repeat(config.args.num_samples, 1, 1)\n",
    "        rand_noise = gumbel.sample(stacked.size())\n",
    "        # add noise\n",
    "        noised = stacked + rand_noise\n",
    "        noised_labs = noised.argmax(-1)\n",
    "        # filter\n",
    "        mask = (noised_labs).eq(targ)\n",
    "        diff_rand_noise = rand_noise[:,:,0] - rand_noise[:,:,1]\n",
    "        avg = 1 - 2*((sig(diff_rand_noise)*mask).sum(0) / (mask.sum(0) + 1e-5))\n",
    "        return ch.stack([avg, ch.zeros(avg.size())], dim=1), None\n",
    "\n",
    "gumbel_bce = GumbelBCE.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_similarity(args, grad_1, grad_2, d_n):\n",
    "    \"\"\"\n",
    "    grad_1: first gradient\n",
    "    grad_2: second gradient \n",
    "    d_n: latent variable noise distribution\n",
    "    returns: grad_1 and grad_2 gradients with respect to the noised output\n",
    "    \"\"\"\n",
    "    # generate random uniform weights\n",
    "    ground_truth = nn.Linear(in_features=args.in_features, out_features=args.k, bias=args.bias)\n",
    "    ground_truth.weight = nn.Parameter(Uniform(args.param_lower, args.param_upper).sample(ch.Size([1, args.in_features])))\n",
    "    if ground_truth.bias is not None: \n",
    "        ground_truth.bias = nn.Parameter(Uniform(args.param_lower, args.param_upper).sample(ch.Size([1,])))\n",
    "\n",
    "    # generate data\n",
    "    X = Uniform(-5, 5).sample(ch.Size([args.samples, args.in_features]))\n",
    "    z = ground_truth(X) + d_n.sample(ch.Size([X.size(0), 1]))\n",
    "    y = args.pi(z)\n",
    "\n",
    "    # truncate\n",
    "    indices = ch.all(args.phi(z).bool(), dim=1).nonzero(as_tuple=False).flatten()\n",
    "    x_trunc = X[indices]\n",
    "    y_trunc = y[indices]\n",
    "\n",
    "    print(\"alpha: \", x_trunc.size(0) / X.size(0))\n",
    "\n",
    "    # pass data through model\n",
    "    model = ch.nn.Linear(in_features=args.in_features, out_features=args.k)\n",
    "    pred = model(x_trunc)\n",
    "\n",
    "    g1_loss = grad_1(pred, y_trunc)\n",
    "    g1_g, = ch.autograd.grad(g1_loss, [pred])\n",
    "\n",
    "    g2_loss = grad_2(pred, y_trunc)\n",
    "    g2_g, = ch.autograd.grad(g2_loss, [pred])\n",
    "\n",
    "\n",
    "    print('Cosine Similarity between grad 1 and grad 2: ',\n",
    "            ch.nn.CosineSimilarity(dim=1)(g2_g.T, g1_g.T))\n",
    "    \n",
    "    return g1_g, g2_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.0\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([-0.9831])\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9994])\n"
     ]
    }
   ],
   "source": [
    "def gradient_similarity_gumbel_diff(args, gum_grad, grad_2, d_n):\n",
    "    \"\"\"\n",
    "    gum_grad: gumbel gradient\n",
    "    grad_2: second gradient \n",
    "    d_n: latent variable noise distribution\n",
    "    returns: grad_1 and grad_2 gradients with respect to the noised output\n",
    "    \"\"\"\n",
    "    # generate random uniform weights\n",
    "    ground_truth = nn.Linear(in_features=args.in_features, out_features=args.k, bias=args.bias)\n",
    "    ground_truth.weight = nn.Parameter(Uniform(args.param_lower, args.param_upper).sample(ch.Size([1, args.in_features])))\n",
    "    if ground_truth.bias is not None: \n",
    "        ground_truth.bias = nn.Parameter(Uniform(args.param_lower, args.param_upper).sample(ch.Size([1,])))\n",
    "\n",
    "    # generate data\n",
    "    X = Uniform(-5, 5).sample(ch.Size([args.samples, args.in_features]))\n",
    "    z = ground_truth(X) + d_n.sample(ch.Size([X.size(0), 1]))\n",
    "    y = args.pi(z)\n",
    "\n",
    "    # truncate\n",
    "    indices = ch.all(args.phi(z).bool(), dim=1).nonzero(as_tuple=False).flatten()\n",
    "    x_trunc = X[indices]\n",
    "    y_trunc = y[indices]\n",
    "    print(\"alpha: \", x_trunc.size(0) / X.size(0))\n",
    "\n",
    "    # pass data through model\n",
    "    \n",
    "    model = ch.nn.Linear(in_features=args.in_features, out_features=args.k)\n",
    "    pred = model(x_trunc)\n",
    "    \n",
    "    g1_loss = gum_grad(pred, y_trunc.long().flatten())\n",
    "    g1_g, = ch.autograd.grad(g1_loss, [pred])\n",
    "    \n",
    "    g1_diff = g1_g[:,0] - g1_g[:, 1]\n",
    "    g1 = -g1_g[:,0]\n",
    "\n",
    "    gum_diff = pred[:,0] - pred[:,1]\n",
    "\n",
    "    g2_loss = grad_2(pred, y_trunc)\n",
    "    g2_g, = ch.autograd.grad(g2_loss, [pred])\n",
    "\n",
    "    print('Cosine Similarity between grad 1 and grad 2: ',\n",
    "            ch.nn.CosineSimilarity(dim=0)(g2_g.sum(1).unsqueeze(1), g1_g[:,1].unsqueeze(1)))\n",
    "    \n",
    "    print('Cosine Similarity between grad 1 and grad 2: ',\n",
    "        ch.nn.CosineSimilarity(dim=0)(g2_g.sum(1).unsqueeze(1), g1_g[:,0].unsqueeze(1)))\n",
    "    \n",
    "    \n",
    "    return g2_g.sum(1).mean(0).reshape(1, 1), g2_g \n",
    "\n",
    "\n",
    "config.args.__setattr__('pi', multi)\n",
    "config.args.__setattr__('k', 2)\n",
    "# config.args.__setattr__('phi', oracle.DNN_Logit_Ball(ch.full(ch.Size([config.args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([config.args.K,]), 2, dtype=ch.float32)))\n",
    "config.args.__setattr__('phi', id_)\n",
    "g1, g2 = gradient_similarity_gumbel_diff(config.args, gumbel_ce, gumbel_bce, gumbel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projection Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = lambda z: ch.where(z > 0, ch.ones(1), ch.zeros(1))\n",
    "multi = lambda z: z.argmax(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare CE Loss with Truncated CE Loss with Identity Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.0\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9990, 0.9779])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('phi', id_)\n",
    "config.args.__setattr__('pi', multi)\n",
    "config.args.__setattr__('k', 2)\n",
    "g1, g2 = gradient_similarity(config.args, ce_loss, trunc_ce, gumbel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare CE Loss with Truncated CE Loss with Logit Ball Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.4943\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.7911, 0.6006])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('pi', multi)\n",
    "config.args.__setattr__('k', 2)\n",
    "config.args.__setattr__('phi', oracle.DNN_Logit_Ball(ch.full(ch.Size([config.args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([config.args.K,]), 2, dtype=ch.float32)) )\n",
    "g1, g2 = gradient_similarity(config.args, ce_loss, trunc_ce, gumbel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare BCE Loss with Truncated BCE Loss and Idenity Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.0\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9999])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('phi', id_)\n",
    "config.args.__setattr__('pi', binary)\n",
    "config.args.__setattr__('k', 1)\n",
    "g1, g2 = gradient_similarity(config.args, bce_logit, trunc_bce, logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare BCE Loss with Truncated BCE Loss with Ball Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.5456\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9828])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('pi', binary)\n",
    "config.args.__setattr__('k', 1)\n",
    "config.args.__setattr__('phi', oracle.DNN_Logit_Ball(ch.full(ch.Size([config.args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([config.args.K,]), 2, dtype=ch.float32)) )\n",
    "g1, g2 = gradient_similarity(config.args, bce_logit, trunc_bce, logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the Diff in the CE Loss with BCE Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.3857\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 1 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2636d0cb3d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'phi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNN_Logit_Ball\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_similarity_gumbel_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgumbel_ce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic_bce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-6c00892cac6f>\u001b[0m in \u001b[0;36mgradient_similarity_gumbel_diff\u001b[0;34m(args, gum_grad, grad_2, d_n)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mg1_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgum_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mg1_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg1_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/delphi/delphi/grad.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, pred, targ)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 1 is out of bounds."
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('pi', binary)\n",
    "config.args.__setattr__('k', 1)\n",
    "config.args.__setattr__('phi', oracle.DNN_Logit_Ball(ch.full(ch.Size([config.args.K,]), -2, dtype=ch.float32), ch.full(ch.Size([config.args.K,]), 2, dtype=ch.float32)) )\n",
    "g1, g2 = gradient_similarity_gumbel_diff(config.args, gumbel_ce, logistic_bce, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  1.0\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.9985, 0.0000])\n",
      "cosine diff: tensor(0.9985)\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('pi', multi)\n",
    "config.args.__setattr__('k', 2)\n",
    "config.args.__setattr__('phi', id_)\n",
    "g1, g2 = gradient_similarity(config.args, ce_loss, gumbel_bce, gumbel)\n",
    "\n",
    "print(\"cosine diff:\", ch.nn.CosineSimilarity(dim=0)(g1[:,0] - g1[:,1], g2[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatedBCE_(ch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, pred, targ):\n",
    "        ctx.save_for_backward(pred, targ)\n",
    "        loss = ch.nn.BCEWithLogitsLoss()\n",
    "        return loss(pred, targ)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pred, targ = ctx.saved_tensors\n",
    "\n",
    "        # logistic distribution\n",
    "        base_distribution = Uniform(0, 1)\n",
    "        transforms_ = [SigmoidTransform().inv]\n",
    "        logistic = TransformedDistribution(base_distribution, transforms_)\n",
    "\n",
    "        stacked = pred[None, ...].repeat(config.args.num_samples, 1, 1)\n",
    "        rand_noise = logistic.sample(stacked.size())\n",
    "        # add noise\n",
    "        noised = stacked + rand_noise\n",
    "        noised_labs = noised > 0\n",
    "        filtered = config.args.phi(noised)\n",
    "        # filter\n",
    "        mask = (noised_labs).eq(targ) * filtered\n",
    "        avg = 2 * (((sig(rand_noise)*mask).sum(0) / (mask.sum(0) + 1e-5)) - (sig(rand_noise)*filtered).sum(0) / (filtered.sum(0) + 1e-5))\n",
    "        return -avg, None\n",
    "    \n",
    "trunc_bce_ = TruncatedBCE_.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ball' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d4b8c289bdc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'phi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mball\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbce_logit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrunc_bce_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ball' is not defined"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('phi', ball)\n",
    "config.args.__setattr__('pi', binary)\n",
    "config.args.__setattr__('k', 1)\n",
    "g1, g2 = gradient_similarity(config.args, bce_logit, trunc_bce_, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha:  0.5264\n",
      "Cosine Similarity between grad 1 and grad 2:  tensor([0.8523])\n"
     ]
    }
   ],
   "source": [
    "config.args.__setattr__('pi', binary)\n",
    "config.args.__setattr__('k', 1)\n",
    "config.args.__setattr__('phi', oracle.DNN_Lower(-.1))\n",
    "g1, g2 = gradient_similarity(config.args, bce_logit, trunc_bce, logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
